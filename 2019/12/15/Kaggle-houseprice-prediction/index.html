<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>[NOTE] Kaggle house price prediction - Fusidic&#039;s blog</title><meta description="AbstractsThis is a copycat of Comprehensive data explorationi with Python. Since I had limited time to accomplish AI project. So I preferred learn from other’s notebook. And ‘Comprehensive data expl"><meta property="og:type" content="blog"><meta property="og:title" content="[NOTE] Kaggle house price prediction"><meta property="og:url" content="https://fusidic.github.io/"><meta property="og:site_name" content="Fusidic&#039;s blog"><meta property="og:description" content="AbstractsThis is a copycat of Comprehensive data explorationi with Python. Since I had limited time to accomplish AI project. So I preferred learn from other’s notebook. And ‘Comprehensive data expl"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://i.loli.net/2019/12/15/5Zrsd9BKaeX34NE.png"><meta property="og:image" content="https://i.loli.net/2019/12/15/92WXMLKG5ie6Sxb.png"><meta property="og:image" content="https://i.loli.net/2019/12/15/Ta4OlBYCVQybRZi.png"><meta property="og:image" content="https://i.loli.net/2019/12/15/XHoEKNPvBl8jbVd.png"><meta property="og:image" content="https://i.loli.net/2019/12/15/yk4KzObE7Ts1jwR.png"><meta property="article:published_time" content="2019-12-15T09:22:10.000Z"><meta property="article:modified_time" content="2020-04-06T16:08:06.000Z"><meta property="article:author" content="fusidic"><meta property="article:tag" content="algorithm"><meta property="article:tag" content="python"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://i.loli.net/2019/12/15/5Zrsd9BKaeX34NE.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://fusidic.github.io/2019/12/15/Kaggle-houseprice-prediction/"},"headline":"Fusidic's blog","image":["https://i.loli.net/2019/12/15/5Zrsd9BKaeX34NE.png","https://i.loli.net/2019/12/15/92WXMLKG5ie6Sxb.png","https://i.loli.net/2019/12/15/Ta4OlBYCVQybRZi.png","https://i.loli.net/2019/12/15/XHoEKNPvBl8jbVd.png","https://i.loli.net/2019/12/15/yk4KzObE7Ts1jwR.png"],"datePublished":"2019-12-15T09:22:10.000Z","dateModified":"2020-04-06T16:08:06.000Z","author":{"@type":"Person","name":"fusidic"},"description":"AbstractsThis is a copycat of Comprehensive data explorationi with Python. Since I had limited time to accomplish AI project. So I preferred learn from other’s notebook. And ‘Comprehensive data expl"}</script><link rel="canonical" href="https://fusidic.github.io/2019/12/15/Kaggle-houseprice-prediction/"><link rel="icon" href="/img/favicon.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Fusidic&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/fusidic"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2019-12-15T09:22:10.000Z" title="2019-12-15T09:22:10.000Z">2019-12-15</time><span class="level-item">14 分钟 读完 (大约 2070 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">[NOTE] Kaggle house price prediction</h1><div class="content"><a id="more"></a>

<h2 id="Abstracts"><a href="#Abstracts" class="headerlink" title="Abstracts"></a>Abstracts</h2><p>This is a copycat of <a href="https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python">Comprehensive data explorationi with Python</a>. Since I had limited time to accomplish AI project. So I preferred learn from other’s notebook. And ‘Comprehensive data explorationi with Python’ is apparently the most fit one for me.</p>
<p>According to the article, the first thing we should do is look through the whole <a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data">data set</a>, and find the most important variables which matters when you buy a house.</p>
<p>And then an important problem we must deal with is <strong>Data Cleaning</strong>.</p>
<h2 id="Overviews"><a href="#Overviews" class="headerlink" title="Overviews"></a>Overviews</h2><p>While ‘Type’ and ‘Segment’ is just for possible future reference, the column ‘Expectation’ is important because it will help us develop a ‘sixth sense’. To fill this column, we should read the description of all the variables and, one by one, ask ourselves:</p>
<ul>
<li>Do we think about this variable when we are buying a house? (e.g. When we think about the house of our dreams, do we care about its ‘Masonry veneer type’?).</li>
<li>If so, how important would this variable be? (e.g. What is the impact of having ‘Excellent’ material on the exterior instead of ‘Poor’? And of having ‘Excellent’ instead of ‘Good’?).</li>
<li>Is this information already described in any other variable? (e.g. If ‘LandContour’ gives the flatness of the property, do we really need to know the ‘LandSlope’?).</li>
</ul>
<p>I went through this process and concluded that the following variables can play an important role in this problem:</p>
<ul>
<li>OverallQual 总体质量</li>
<li>YearBuilt.</li>
<li>TotalBsmtSF. 地下室面积</li>
<li>GrLivArea. 地上居住面积</li>
</ul>
<p><em>Hmmm… It seems that ‘SalePrice’ and ‘GrLivArea’ are really old friends, with a *</em>linear relationship.***</p>
<p>In my opinion, this heatmap is the best way to get a quick overview of our ‘plasma soup’ and its relationships. (Thank you @seaborn!)</p>
<p><img src="https://i.loli.net/2019/12/15/5Zrsd9BKaeX34NE.png" alt="correlation.png"></p>
<ul>
<li>TotalBsmtSF and 1stFlrSF</li>
<li>GarageX</li>
</ul>
<p><img src="https://i.loli.net/2019/12/15/92WXMLKG5ie6Sxb.png" alt="saleprice_correlation_matrix.png"></p>
<p>According to our crystal ball, these are the variables most correlated with ‘SalePrice’. My thoughts on this:</p>
<ul>
<li>‘OverallQual’, ‘GrLivArea’ and ‘TotalBsmtSF’ are strongly correlated with ‘SalePrice’. Check!</li>
<li>‘GarageCars’ and ‘GarageArea’ are also some of the most strongly correlated variables. However, as we discussed in the last sub-point, the number of cars that fit into the garage is a consequence of the garage area. ‘GarageCars’ and ‘GarageArea’ are like twin brothers. You’ll never be able to distinguish them. Therefore, we just need one of these variables in our analysis (we can keep ‘GarageCars’ since its correlation with ‘SalePrice’ is higher).</li>
<li>‘TotalBsmtSF’ and ‘1stFloor’ also seem to be twin brothers. We can keep ‘TotalBsmtSF’ just to say that our first guess was right (re-read ‘So… What can we expect?’).</li>
<li>‘FullBath’?? Really?</li>
<li>‘TotRmsAbvGrd’ and ‘GrLivArea’, twin brothers again. Is this dataset from Chernobyl?</li>
<li>Ah… ‘YearBuilt’… It seems that ‘YearBuilt’ is slightly correlated with ‘SalePrice’. Honestly, it scares me to think about ‘YearBuilt’ because I start feeling that we should do a little bit of time-series analysis to get this right. I’ll leave this as a homework for you.</li>
</ul>
<p>Let’s proceed to the scatter plots.</p>
<p><img src="https://i.loli.net/2019/12/15/Ta4OlBYCVQybRZi.png" alt="scatterplot.png"></p>
<h2 id="Missing-data"><a href="#Missing-data" class="headerlink" title="Missing data"></a>Missing data</h2><h3 id="Missing-data-analysis"><a href="#Missing-data-analysis" class="headerlink" title="Missing data analysis"></a>Missing data analysis</h3><p>Using script below, we can easily get the missing data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#missing data</span></span><br><span class="line">total = df_train.isnull().sum().sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">missing_data = pd.concat([total, percent], axis=<span class="number">1</span>, keys=[<span class="string">'Total'</span>, <span class="string">'Percent'</span>])</span><br><span class="line">print(missing_data.head(<span class="number">20</span>))</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th></th>
<th>Total</th>
<th>Percent</th>
</tr>
</thead>
<tbody><tr>
<td>PoolQC</td>
<td>1453</td>
<td>0.995205</td>
</tr>
<tr>
<td>MiscFeature</td>
<td>1406</td>
<td>0.963014</td>
</tr>
<tr>
<td>Alley</td>
<td>1369</td>
<td>0.937671</td>
</tr>
<tr>
<td>Fence</td>
<td>1179</td>
<td>0.807534</td>
</tr>
<tr>
<td>FireplaceQu</td>
<td>690</td>
<td>0.472603</td>
</tr>
<tr>
<td>LotFrontage</td>
<td>259</td>
<td>0.177397</td>
</tr>
<tr>
<td>GarageCond</td>
<td>81</td>
<td>0.055479</td>
</tr>
<tr>
<td>GarageType</td>
<td>81</td>
<td>0.055479</td>
</tr>
<tr>
<td>GarageYrBlt</td>
<td>81</td>
<td>0.055479</td>
</tr>
<tr>
<td>GarageFinish</td>
<td>81</td>
<td>0.055479</td>
</tr>
<tr>
<td>GarageQual</td>
<td>81</td>
<td>0.055479</td>
</tr>
<tr>
<td>BsmtExposure</td>
<td>38</td>
<td>0.026027</td>
</tr>
<tr>
<td>BsmtFinType2</td>
<td>38</td>
<td>0.026027</td>
</tr>
<tr>
<td>BsmtFinType1</td>
<td>37</td>
<td>0.025342</td>
</tr>
<tr>
<td>BsmtCond</td>
<td>37</td>
<td>0.025342</td>
</tr>
<tr>
<td>BsmtQual</td>
<td>37</td>
<td>0.025342</td>
</tr>
<tr>
<td>MasVnrArea</td>
<td>8</td>
<td>0.005479</td>
</tr>
<tr>
<td>MasVnrType</td>
<td>8</td>
<td>0.005479</td>
</tr>
<tr>
<td>Electrical</td>
<td>1</td>
<td>0.000685</td>
</tr>
<tr>
<td>Utilities</td>
<td>0</td>
<td>0.000000</td>
</tr>
</tbody></table>
<p>So how to handle the missing data?</p>
<p>We’ll consider that when more than 15% of the data is missing, we should delete the corresponding variable and pretend it never existed. So we delete ‘PoolQC’, ‘MiscFeature’, ‘Alley’, ‘Fence’, ‘FireplaceQu’ and ‘LotFrontage’.</p>
<p>As for ‘GarageX’, they all have the same number of missing data. Maybe the missing data refers to the same set of observations. Since the most important information regarding garages is expressed by ‘GarageCars’ and considering that we are just talking about 5% of missing data, I’ll delete the mentioned ‘Garage<em>X</em>‘ variables. The same logic applies to ‘Bsmt<em>X</em>‘ variables.</p>
<p>As for  ‘MasVnrArea’(砖石饰面面积) and ‘MasVnrType’(砖石饰面种类), we can consider that these variables have a strong correlation with ‘YearBuilt’ and ‘OverallQual’ which are already considered. So we delete ‘MasVnrArea’ and ‘MasVnrType’.</p>
<h3 id="Delete-missing-variables"><a href="#Delete-missing-variables" class="headerlink" title="Delete missing variables"></a>Delete missing variables</h3><p>We’ll delete all the variables with missing data, except the variable ‘Electrical’. In ‘Electrical’ we’ll just delete the observation with missing data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#dealing with missing data</span></span><br><span class="line">df_train = df_train.drop((missing_data[missing_data[<span class="string">'Total'</span>] &gt; <span class="number">1</span>]).index,<span class="number">1</span>)</span><br><span class="line">df_train = df_train.drop(df_train.loc[df_train[<span class="string">'Electrical'</span>].isnull()].index)</span><br><span class="line">df_train.isnull().sum().max() <span class="comment">#just checking that there's no missing data missing...</span></span><br></pre></td></tr></table></figure>

<p>If the output is ‘0’, it means you have fully delete missing data.</p>
<h2 id="Out-liars"><a href="#Out-liars" class="headerlink" title="Out liars"></a>Out liars</h2><p>The primary concern here is to establish a threshold that defines an observation as an outlier. To do so, we’ll standardize the data. In this context, data standardization means converting data values to have mean of 0 and a standard deviation of 1.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这里主要关注的是建立一个将观察值定义为异常值的阈值。为此，我们将对数据进行标准化。在这种情况下，数据标准化意味着将数据值转换为平均值为0且标准差为1。</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#standardizing data</span></span><br><span class="line">saleprice_scaled = StandardScaler().fit_transform(df_train[<span class="string">'SalePrice'</span>][:,np.newaxis]);</span><br><span class="line">low_range = saleprice_scaled[saleprice_scaled[:,<span class="number">0</span>].argsort()][:<span class="number">10</span>]</span><br><span class="line">high_range= saleprice_scaled[saleprice_scaled[:,<span class="number">0</span>].argsort()][<span class="number">-10</span>:]</span><br><span class="line">print(<span class="string">'outer range (low) of the distribution:'</span>)</span><br><span class="line">print(low_range)</span><br><span class="line">print(<span class="string">'\nouter range (high) of the distribution:'</span>)</span><br><span class="line">print(high_range)</span><br></pre></td></tr></table></figure>

<p>这一步的目的应该是为了找出数据中的离群值，这里需要关注的是两个大于7的变量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#bivariate analysis saleprice/grlivarea</span></span><br><span class="line">var = <span class="string">'GrLivArea'</span></span><br><span class="line">data = pd.concat([df_train[<span class="string">'SalePrice'</span>], df_train[var]], axis=<span class="number">1</span>)</span><br><span class="line">data.plot.scatter(x=var, y=<span class="string">'SalePrice'</span>, ylim=(<span class="number">0</span>,<span class="number">800000</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">#deleting points</span></span><br><span class="line">df_train.sort_values(by = <span class="string">'GrLivArea'</span>, ascending = <span class="literal">False</span>)[:<span class="number">2</span>]</span><br><span class="line">df_train = df_train.drop(df_train[df_train[<span class="string">'Id'</span>] == <span class="number">1299</span>].index)</span><br><span class="line">df_train = df_train.drop(df_train[df_train[<span class="string">'Id'</span>] == <span class="number">524</span>].index)</span><br><span class="line"></span><br><span class="line"><span class="comment">#bivariate analysis saleprice/grlivarea</span></span><br><span class="line">var = <span class="string">'TotalBsmtSF'</span></span><br><span class="line">data = pd.concat([df_train[<span class="string">'SalePrice'</span>], df_train[var]], axis=<span class="number">1</span>)</span><br><span class="line">data.plot.scatter(x=var, y=<span class="string">'SalePrice'</span>, ylim=(<span class="number">0</span>,<span class="number">800000</span>));</span><br></pre></td></tr></table></figure>

<p>将’GrlivArea’中的离群值删除。</p>
<p>之后考察’TotalBsmtSF’中的离群值，但它的离群值表现在可以接受的范围之内。</p>
<h2 id="Getting-hard-core"><a href="#Getting-hard-core" class="headerlink" title="Getting hard core"></a>Getting hard core</h2><p>According to <a href="https://amzn.to/2uC3j9p">Hair et al. (2013)</a>, four assumptions should be tested:</p>
<ul>
<li>Normality: The data should look like a normal distribution.</li>
<li>Homoscedasticity: 这个用英文解释不太好懂，同方性是可取的，我们希望误差项在自变量的所有值上都相同；</li>
<li>Linearity: 正如前文已经做过的，通过散点图的方法来观测两个变量之间是否有线性的相关性，如果相关性不是线性的，那么可以通过一定的数学转换使其线性相关；</li>
<li>Absence of correlated errors:</li>
</ul>
<h3 id="Normality"><a href="#Normality" class="headerlink" title="Normality"></a>Normality</h3><p>The point here is to test ‘SalePrice’ in a very lean way. We’ll do this paying attention to:</p>
<ul>
<li>Histogram - Kurtosis and skewness.</li>
<li>Normal probability plot - Data distribution sould closely follow the diagonal that represents the normal distribution.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#histogram and normal probability plot</span></span><br><span class="line">sns.distplot(df_train[<span class="string">'SalePrice'</span>], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(df_train[<span class="string">'SalePrice'</span>], plot=plt)</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2019/12/15/XHoEKNPvBl8jbVd.png" alt="probablity_plot.png"></p>
<p>对变量取log转换得：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#applying log transformation</span></span><br><span class="line">df_train[<span class="string">'SalePrice'</span>] = np.log(df_train[<span class="string">'SalePrice'</span>])</span><br></pre></td></tr></table></figure>



<p><img src="https://i.loli.net/2019/12/15/yk4KzObE7Ts1jwR.png" alt="Theoretical_quantiles.png"></p>
<p>可以看到，散点更为均匀地分布在了直线的两侧。</p>
<p>以同样的方法对’GrLivArea’与’TotalBsmtSF’进行处理。</p>
<p>其中面临一个很严重的问题是，有些值为0，所以在这些值上，我们无法对它们取log。要在此处应用对数转换，我们将创建一个变量，该变量可以具有或不具有地下室的效果（二进制变量）。然后，我们将对所有非零观测值进行对数转换，而忽略那些值为零的观测值。这样，我们可以转换数据，而不会失去某些变量的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#create column for new variable (one is enough because it's a binary categorical feature)</span></span><br><span class="line"><span class="comment">#if area&gt;0 it gets 1, for area==0 it gets 0</span></span><br><span class="line">df_train[<span class="string">'HasBsmt'</span>] = pd.Series(len(df_train[<span class="string">'TotalBsmtSF'</span>]), index=df_train.index)</span><br><span class="line">df_train[<span class="string">'HasBsmt'</span>] = <span class="number">0</span> </span><br><span class="line">df_train.loc[df_train[<span class="string">'TotalBsmtSF'</span>]&gt;<span class="number">0</span>,<span class="string">'HasBsmt'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">transform data</span><br><span class="line">df_train.loc[df_train[<span class="string">'HasBsmt'</span>]==<span class="number">1</span>,<span class="string">'TotalBsmtSF'</span>] = np.log(df_train[<span class="string">'TotalBsmtSF'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#histogram and normal probability plot</span></span><br><span class="line">sns.distplot(df_train[df_train[<span class="string">'TotalBsmtSF'</span>]&gt;<span class="number">0</span>][<span class="string">'TotalBsmtSF'</span>], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(df_train[df_train[<span class="string">'TotalBsmtSF'</span>]&gt;<span class="number">0</span>][<span class="string">'TotalBsmtSF'</span>], plot=plt)</span><br></pre></td></tr></table></figure>

<h3 id="Main-Variables"><a href="#Main-Variables" class="headerlink" title="Main Variables"></a>Main Variables</h3><table>
<thead>
<tr>
<th align="left">Variable</th>
<th align="left">Segment</th>
<th align="left">Data Type</th>
<th align="left">Comments</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>GrLivArea</strong></td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">生活面积</td>
</tr>
<tr>
<td align="left"><strong>TotalBsmtSF</strong></td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">地下室总面积</td>
</tr>
<tr>
<td align="left"><strong>GarageArea</strong>/<strong>GarageCars</strong></td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">车库</td>
</tr>
<tr>
<td align="left"><strong>YearBuilt</strong></td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">建造年份</td>
</tr>
<tr>
<td align="left"><strong>CentralAir</strong></td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">中央空调</td>
</tr>
<tr>
<td align="left"><strong>OverallQual</strong></td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">总体评价</td>
</tr>
<tr>
<td align="left"><strong>Neighborhood</strong></td>
<td align="left">2</td>
<td align="left">1</td>
<td align="left">地段</td>
</tr>
</tbody></table>
<p>Now we can make sure there 7 variables will participate in our model. And we have cleaned the data set. The final thing left to do is to get the PREDICTION.</p>
<h2 id="Model-Random-forest"><a href="#Model-Random-forest" class="headerlink" title="Model: Random forest"></a>Model: Random forest</h2><p>Why use this? Idk, otherwise the blog didn’t describe the reason clearly.</p>
<p>The code displays below. And I have little trouble understanding the Random Forest Algorithm.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取数据</span></span><br><span class="line">data_train = pd.read_csv(<span class="string">'./train.csv'</span>)</span><br><span class="line">cols = [<span class="string">'OverallQual'</span>,<span class="string">'GrLivArea'</span>, <span class="string">'GarageCars'</span>,<span class="string">'TotalBsmtSF'</span>, <span class="string">'FullBath'</span>, <span class="string">'TotRmsAbvGrd'</span>, <span class="string">'YearBuilt'</span>]</span><br><span class="line">x = data_train[cols].values</span><br><span class="line">y = data_train[<span class="string">'SalePrice'</span>].values</span><br><span class="line">x_scaled = preprocessing.StandardScaler().fit_transform(x)</span><br><span class="line">y_scaled = preprocessing.StandardScaler().fit_transform(y.reshape(<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line">X_train,X_test, y_train, y_test = train_test_split(x_scaled, y_scaled, test_size=<span class="number">0.33</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">clfs = &#123;</span><br><span class="line">        <span class="string">'svm'</span>:svm.SVR(),</span><br><span class="line">        <span class="string">'RandomForestRegressor'</span>:RandomForestRegressor(n_estimators=<span class="number">400</span>),</span><br><span class="line">        <span class="string">'BayesianRidge'</span>:linear_model.BayesianRidge()</span><br><span class="line">       &#125;</span><br><span class="line"><span class="keyword">for</span> clf <span class="keyword">in</span> clfs:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        clfs[clf].fit(X_train, y_train)</span><br><span class="line">        y_pred = clfs[clf].predict(X_test)</span><br><span class="line">        print(clf + <span class="string">" cost:"</span> + str(np.sum(y_pred-y_test)/len(y_pred)) )</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(clf + <span class="string">" Error:"</span>)</span><br><span class="line">        print(str(e))</span><br><span class="line"></span><br><span class="line">cols = [<span class="string">'OverallQual'</span>,<span class="string">'GrLivArea'</span>, <span class="string">'GarageCars'</span>,<span class="string">'TotalBsmtSF'</span>, <span class="string">'FullBath'</span>, <span class="string">'TotRmsAbvGrd'</span>, <span class="string">'YearBuilt'</span>]</span><br><span class="line">x = data_train[cols].values</span><br><span class="line">y = data_train[<span class="string">'SalePrice'</span>].values</span><br><span class="line">X_train,X_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.33</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">clf = RandomForestRegressor(n_estimators=<span class="number">400</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line">print(y_pred)</span><br><span class="line"></span><br><span class="line">rfr = clf</span><br><span class="line">data_test = pd.read_csv(<span class="string">"./test.csv"</span>)</span><br><span class="line">data_test[cols].isnull().sum()</span><br><span class="line">data_test[<span class="string">'GarageCars'</span>].describe()</span><br><span class="line">data_test[<span class="string">'TotalBsmtSF'</span>].describe()</span><br><span class="line"></span><br><span class="line">cols2 = [<span class="string">'OverallQual'</span>,<span class="string">'GrLivArea'</span>, <span class="string">'FullBath'</span>, <span class="string">'TotRmsAbvGrd'</span>, <span class="string">'YearBuilt'</span>]</span><br><span class="line">cars = data_test[<span class="string">'GarageCars'</span>].fillna(<span class="number">1.766118</span>)</span><br><span class="line">bsmt = data_test[<span class="string">'TotalBsmtSF'</span>].fillna(<span class="number">1046.117970</span>)</span><br><span class="line">data_test_x = pd.concat( [data_test[cols2], cars, bsmt] ,axis=<span class="number">1</span>)</span><br><span class="line">data_test_x.isnull().sum()</span><br><span class="line"></span><br><span class="line">x = data_test_x.values</span><br><span class="line">y_te_pred = rfr.predict(x)</span><br><span class="line">print(y_te_pred)</span><br><span class="line"></span><br><span class="line">print(y_te_pred.shape)</span><br><span class="line">print(x.shape)</span><br><span class="line"></span><br><span class="line">prediction = pd.DataFrame(y_te_pred, columns=[<span class="string">'SalePrice'</span>])</span><br><span class="line">result = pd.concat([ data_test[<span class="string">'Id'</span>], prediction], axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># result = result.drop(resultlt.columns[0], 1)</span></span><br><span class="line">result.columns</span><br><span class="line"></span><br><span class="line"><span class="comment"># save the prediction</span></span><br><span class="line">result.to_csv(<span class="string">'./Predictions.csv'</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>



</div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/algorithm/">algorithm</a><a class="link-muted mr-2" rel="tag" href="/tags/python/">python</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/12/18/ClockSynchronize/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">[NOTE] ClockSynchronize</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/11/22/HTTPS/"><span class="level-item">[NOTE] 构建HTTPS</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3 is-sticky"><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="is-flex" href="#Abstracts"><span class="mr-2">1</span><span>Abstracts</span></a></li><li><a class="is-flex" href="#Overviews"><span class="mr-2">2</span><span>Overviews</span></a></li><li><a class="is-flex" href="#Missing-data"><span class="mr-2">3</span><span>Missing data</span></a><ul class="menu-list"><li><a class="is-flex" href="#Missing-data-analysis"><span class="mr-2">3.1</span><span>Missing data analysis</span></a></li><li><a class="is-flex" href="#Delete-missing-variables"><span class="mr-2">3.2</span><span>Delete missing variables</span></a></li></ul></li><li><a class="is-flex" href="#Out-liars"><span class="mr-2">4</span><span>Out liars</span></a></li><li><a class="is-flex" href="#Getting-hard-core"><span class="mr-2">5</span><span>Getting hard core</span></a><ul class="menu-list"><li><a class="is-flex" href="#Normality"><span class="mr-2">5.1</span><span>Normality</span></a></li><li><a class="is-flex" href="#Main-Variables"><span class="mr-2">5.2</span><span>Main Variables</span></a></li></ul></li><li><a class="is-flex" href="#Model-Random-forest"><span class="mr-2">6</span><span>Model: Random forest</span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-09-18T08:51:10.000Z">2020-09-18</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/18/CustomScheduler3/">Schedule Framework 扩展调度器</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Kubernetes/">Kubernetes</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-07-29T13:30:34.206Z">2020-07-29</time></p><p class="title is-6"><a class="link-muted" href="/2020/07/29/Kubernetes-rtfsc1/">[RTFSC]Kubernetes 资源对象与控制器</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/DeepIn/">DeepIn</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-07-10T13:30:36.000Z">2020-07-10</time></p><p class="title is-6"><a class="link-muted" href="/2020/07/10/k8s-RABC/">Kubernetes RABC 权限控制</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Operations/">Operations</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-12T09:07:50.000Z">2020-06-12</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/12/LinuxPerformanceTool/">Linux性能调优</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Operations/">Operations</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-03T13:44:16.000Z">2020-06-03</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/03/LinuxNetworkAnalyze/">Linux 网络分析</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Operations/">Operations</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Fusidic&#039;s blog" height="28"></a><p class="size-small"><span>&copy; 2020 fusidic</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://fusidic.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>