{"pages":[{"title":"about","text":"","link":"/about/index.html"}],"posts":[{"title":"[NOTE] CentOS换源","text":"mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo yum makecache 补充Ubuntu/etc/apt/sources.list 123456789101112131415161718192021222324##中科大源deb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse# 阿里源deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse sudo apt-get update sudo apt-get upgrade 不加-get会有部分更新失败","link":"/2019/07/03/CentOS%E6%8D%A2%E6%BA%90/"},{"title":"[NOTE] ClockSynchronize","text":"Ubuntu Check your current time-zone: cat /etc/timezone Check if your clock is synchronized with the internet: timedatectl 12345678root@openstack1:~/kubernetes# timedatectl Local time: Tue 2019-12-17 10:30:02 UTC Universal time: Tue 2019-12-17 10:30:02 UTC RTC time: Tue 2019-12-17 10:30:02 Time zone: Etc/UTC (UTC, +0000) System clock synchronized: yessystemd-timesyncd.service active: yes RTC in local TZ: no If you haven’t sychronized with internet, the value of System clock synchronize must be no Use sudo systemctl restart systemd-timesyncd.service to activate timesyncd 12345678910root@openstack1:~/kubernetes# systemctl status systemd-timesyncd.service● systemd-timesyncd.service - Network Time Synchronization Loaded: loaded (/lib/systemd/system/systemd-timesyncd.service; enabled; vendo Active: active (running) since Mon 2019-12-16 09:24:02 UTC; 1 day 1h ago Docs: man:systemd-timesyncd.service(8) Main PID: 27584 (systemd-timesyn) Status: \"Synchronized to time server 91.189.94.4:123 (ntp.ubuntu.com).\" Tasks: 2 (limit: 4915) CGroup: /system.slice/systemd-timesyncd.service └─27584 /lib/systemd/systemd-timesyncd The final key to synchronize the clock sudo timedatectl set-ntp true Switch your time-zone timedatectl list-timezones to check all the time-zones. sudo timedatectl set-timezone Asia/Shanghai CentOS Using command line 123456789# installationyum install chrony# enable chronydsystemctl start chronydsystemctl enable chronyd# set timezone to Shanghaitimedatectl set-timezone Asia/Shanghai# launch ittimedatectl set-ntp yes","link":"/2019/12/18/ClockSynchronize/"},{"title":"[NOTE] GitLab","text":"Ubuntu Server + Docker + Gitlab 以及 Git 使用。 因为最近也接触了Docker，所以也算是练手，决定将Gitlab直接部署到docker当中 一、Docker容器安装1sudo apt-get install docker-ce 为了便于使用，修改docker镜像源 12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'{ \"registry-mirrors\": [\"https://0ghk1qyk.mirror.aliyuncs.com\"]}EOFsudo systemctl daemon-reloadsudo systemctl restart docker 二、安装并配置gitlab-server12345678910sudo docker run --detach \\ --hostname gitlab-server \\ --publish 443:443 --publish 80:80 --publish 22:22 \\ --name gitlab \\ --restart always \\ --volume /srv/gitlab/config:/etc/gitlab \\ --volume /srv/gitlab/logs:/var/log/gitlab \\ --volume /srv/gitlab/data:/var/opt/gitlab \\ --env GITLAB_OMNIBUS_CONFIG=\"external_url 'http://192.168.1.253';\" \\ gitlab/gitlab-ee:latest 介绍其中的几个配置项， —publish告诉容器发布数据的端口，以及主机端口与容器端口之间的关系，由于GitLab接受HTTP(80), HTTPS(443)以及SSH(22)端口的消息，所以publish这一行的设置是将主机对应的端口映射到容器的端口上。 如果想要设置非标准的端口(由于端口已被占用)，要将主机端口放在前，容器端口放在后。 在采用这个设置之前，我将SSH设置为了2222，HTTP端口设置为了9090，并且在gitlab.rb文件中修改了相应的端口，但可能是哪个步骤有疏漏，导致GitLab页面一直显示502，这点之后会有所说明 —restart使容器在推出后能立即重启，保证持续提供服务 —volume可以讲容器中的路径挂载到本机中，此处挂载了包括应用数据、日志以及配置文件，这样在维护中会带来一些方便 这些命令在文档中都有介绍，有足够的经验之后，完全可以在需要使用时再去查询。 三、踩坑记录(1)由于最先开始配置GItLab时，并不想去修改默认的ssh端口22，配置如下： 12345678910docker run --detach \\--hostname gitlab-server \\--publish 9090:9090 \\--publish 8022:8022 \\--name gitlab \\--restart always \\--volume /srv/gitlab/config:/etc/gitlab \\--volume /srv/gitlab/logs:/var/log/gitlab \\--volume /srv/gitlab/data:/var/opt/gitlab \\gitlab/gitlab-ee:latest 修改配置文件： 1234vi /srv/gitlab/config/gitlab.rb# docker exec -it gitlab vim /etc/gitlab/gitlab.rb# 此命令等价# 修改external_url 'http://192.168.1.253:9090' 现在看来，这显然是错误的，以我粗浅的认知，我认为应该至少应该是将publish配置为80:8888, 22:8022这样才比较合理，不知我所参考的博客的原作者是怎么成功的，反正我这样是一直显示502，在查看log文件之后 可以明显的看到问题出在连接端口上，此后通过docker命令停止并删除改容器，重新配置一个新的容器。 12sudo docker stop gitlabsudo docker container rm gitlab 在使用默认端口之后，ssh端口会发生端口冲突的情况，可以使用vi /etc/ssh/sshd_config文件中加入Port 26恢复对端口的监听 四、GitLab维护4.1 GitLab升级1234567891011121314sudo docker stop gitlabsudo docker rm gitlabsudo docker pull gitlab/gitlab-ee:latestsudo docker run --detach \\ --hostname gitlab-server \\ --publish 443:443 --publish 80:80 --publish 22:22 \\ --name gitlab \\ --restart always \\ --volume /srv/gitlab/config:/etc/gitlab \\ --volume /srv/gitlab/logs:/var/log/gitlab \\ --volume /srv/gitlab/data:/var/opt/gitlab \\ --env GITLAB_OMNIBUS_CONFIG=\"external_url 'http://192.168.1.253/';\" \\ gitlab/gitlab-ee:latest 可以看到，虽然移除了当前的容器，但是由于镜像依旧在本地磁盘中，且由于挂载的关系，应用数据、日志等都还在。 五、踩坑记录(2)5.1 提交缓存超出(solved)在我将整个博客及其编译环境全部上传gitlab时遇到了这种情况，解决方法是修改工作目录下.git文件夹中的config文件： 12[http]postBuffer = 524288000 5.2 无法使用GitLab内置ssh(In queue)![Screen Shot 2019-07-27 at 11.22.08](/Users/fusidic/Documents/work/hugo/test-pages/static/img/GitLab/Screen Shot 2019-07-27 at 11.22.08.png) 尚未解决，猜想应该与git账户权限有关","link":"/2019/08/03/GitLab/"},{"title":"[Golang] Go Mod Best-Practice(NotReally)","text":"Go在1.11版本后开始支持modules，以go mod来实现包管理，那么该如何使用呢？ Before本文前提你已经有了如下环境： VS Code Golang v1.11 or later 已正确设置GOROOT GOPATH Git Quick Start直接查看官方文档，体验更佳。 1. 搭配LSP食用LSP(Language Server Protocol) 即语言服务器协议，目的是为了让不同的编辑器或集成开发环境方便使用各种程序语言，支持包括语法检查、自动补全、跳转、引用查询等功能。 将这些功能放入独立的进程中，可以同时对不同编辑器生效，避免了资源的浪费，同时也可以将语言服务器部署在服务器上，释放本地因扫描语言而带来的CPU负担。 安装gopls：打开VS Code，command+,打开设置，搜索go.useLanguageServer勾选。 默认情况下，这时Go扩展就会自动提示你安装gopls，或者手动安装 1go get golang.org/x/tools/gopls@latest gopls会安装到GOPATH目录下的bin中，如果存在网络问题，可以将goproxy设置为goproxy.cn，是一个国内的大学生和七牛云合作提供的一个开源CDN，安全性自己判断了: 1export GOPROXY=https://goproxy.cn 导入配置到settings.json中: 123456789101112131415161718192021{ \"go.useLanguageServer\": true, \"go.alternateTools\": { \"go-langserver\": \"gopls\" }, \"go.languageServerExperimentalFeatures\": { \"format\": true, \"autoComplete\": true }, \"[go]\": { \"editor.snippetSuggestions\": \"none\", \"editor.formatOnSave\": true, \"editor.codeActionsOnSave\": { \"source.organizeImports\": true }, }, \"gopls\": { \"usePlaceholders\": true, \"enhancedHover\": true }} 如何打开settings.json? command + , 右上角图标open settings(JSON) (Optional) 开启调试信息，在settings中加入： 12345\"go.languageServerFlags\": [ \"-rpc.trace\", // for more detailed debug logging \"serve\", \"--debug=localhost:6060\", // to investigate memory usage, see profiles], 2. Go Mod简单体会一下Go mod的方便之处，首先打开gomod 123go env -w GO111MODULE=on// orexport GO111MODULE=auto 在GOPATH目录之外的地方创建项目文件，使用VCS(可选) 1234$ mkdir -p /tmp/scratchpad/repo$ cd /tmp/scratchpad/repo$ git init -q$ git remote add origin https://github.com/my/repo 初始化module 123$ go mod init github.com/my/repogo: creating new go.mod: module github.com/my/repo demo: 123456789101112$ cat &lt;&lt;EOF &gt; hello.gopackage mainimport ( \"fmt\" \"rsc.io/quote\")func main() { fmt.Println(quote.Hello())}EOF 之后使用第三方库，都不再需要使用go get了，build的同时会自动将需要的包导入： 1234$ go build -o hello$ ./helloHello, world. go.mod: 12345$ cat go.modmodule github.com/my/reporequire rsc.io/quote v1.5.2 3.日常使用 在你的.go文件中加入需要的声明 使用go build或者go test自动导入依赖，go.mod也会自动更新 当需要的时候，可以用如go get foo@v1.1.3, go get foo@master来选择合适的依赖 Command Usage go list -m all 查看直接或间接依赖库的最终版本 go list -u -m all 查看直接或间接依赖库的可用更新(minor和patch) go get -u ./… or go get -u=path ./… 安装所有直接或间接依赖库的更新(minor和patch) go build ./… or go test ./… build或test模块中的所有包 go mod tidy 从go.mod中清除不再使用的依赖 replace or gohack 使用通过fork、本地复制、解压等方法安装的 go mod vendor Optinal step to create a vendor directory Reference https://github.com/golang/go/wiki/Modules#how-to-install-and-activate-module-support","link":"/2020/03/22/GoModBest-Practice-NotReally/"},{"title":"[Golang] 函数","text":"Go语言中的函数特性： 函数本身可以作为值进行传递 支持匿名函数和闭包(closure) 函数可以满足接口 1.利用函数进行链式处理利用函数实现对list中string类型的“去go”、“去空格”、“专为大写” 123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport ( \"fmt\" \"strings\")func StringProcess(list []string, chain []func(string) string) { // list and StringProcess chain for index, str := range list { result := str for _, proc := range chain { result = proc(result) } list[index] = result }}func removePrefix(str string) string { return strings.TrimPrefix(str, \"go\")}func main() { list := []string{ \"go scanner\", \"go parser\", \"go compiler\", \"go printer\", \"go formater\", } chain := []func(string) string{ removePrefix, strings.TrimSpace, strings.ToUpper, } StringProcess(list, chain) for _, str := range list { fmt.Println(str) }} 函数StringProcess（list []string, chain []func(string string)中分别将string类型与函数类型作为参数，相对C这是船新的操作。 2.匿名函数 func(参数列表) (返回参数列表) { body} 2.1 在定义时调用匿名函数123func(data int) { fmt.Println(data)} (100) 2.2 将匿名函数用作回调函数123456789101112131415package mainimport \"fmt\"func visit(list []int, f func(int2 int)) { for _, v := range list { f(v) }}func main() { visit([]int{1, 2, 3, 4}, func(v int) { fmt.Println(v) })} visit()函数将遍历过程封装，当要获取遍历期间的切片值时，只需要给visit()传入一个回调参数即可。 2.3使用匿名函数实现封装12345678910111213141516171819202122232425262728package mainimport ( \"flag\" \"fmt\")var skillParam = flag.String(\"skill\", \"\", \"skill to perform\")func main() { flag.Parse() var skill = map[string]func(){ \"fire\": func() { fmt.Println(\"chicken fire\") }, \"run\": func() { fmt.Println(\"solier run\") }, \"fly\": func() { fmt.Println(\"angel fly\") }, } if f, ok := skill[*skillParam]; ok { f() } else { fmt.Println(\"skill not found\") }} 这段代码将匿名函数作为map的value，通过命令行参数动态调用匿名函数。 2.4函数作为接口来使用结构体实现接口golang中的其他类型都可以实现接口，函数也可以，下文将分别对比结构体与函数实现接口的过程以接口invoker为例： type Invoker interface { Call(interface{})} 这个接口需要实现Call()方法，调用时会传入一个interface{}类型的变量，这种类型的变量表示任意类型的值。以下为结构体进行接口的实现： 1234567891011121314151617181920package mainimport \"fmt\"type Invoker interface { Call(interface{})}type Struct struct{}func (s *Struct) Call(p interface{}) { fmt.Println(\"from struct\", p)}func main() { var invoker Invoker s := new(Struct) s.Call(\"hello\") invoker = s //将struct s传入invoker的interface invoker.Call(\"hello\")} 输出为： from struct hellofrom struct hello 重点在invoker = s中，由于s为Struct类型的指针，且已经对应实现了Call()方法，即已经实现了Invoker接口类型，当赋值时invoker接收了一个结构体作为值。 函数体实现接口1234567891011121314151617181920212223242526package mainimport \"fmt\"//调用器接口type Invoker interface { Call(interface{})}//函数定义为类型type FuncCaller func(interface{})//实现invoker的func (f FuncCaller) Call(p interface{}) { f(p)}func main() { var invoker Invoker //将匿名函数转为FuncCaller类型，再赋值给接口 invoker = FuncCaller(func(v interface{}) { fmt.Println(\"from function\", v) }) invoker.Call(\"hello\")} func (f FuncCaller) Call(p interface{}) {}中的Call()方法将实现Invoker中的Call()方法(还未传递)，但FuncCaller的Call()方法被调用与func(interface{})无关，还需要通过f(p)手动调用函数本体。 123invoker = FuncCaller(func(v interface{}) { fmt.Println(\"from function\", v)}) 这段将匿名函数转换为FuncCaller类型(函数签名才能转换),此时FuncCaller类型实现了INVOKER的Call()方法，赋值给invoker接口是成功的。函数与结构体实现接口不同： 分别将函数与结构体定义为类型type 接口传入的分别是函数和结构体 中间部分体会需要加深 HTTP包中的例子HTTP包中有包含Handler接口定义，代码如下: 123type Handler interface{ ServeHTTP(ResponseWriter, *Request)} Handler用于定义每个HTTP的请求和响应的处理过程，可以使用处理函数实现接口，如下: 12345type HandlerFunc func(ResponseWriter, *Request)func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r)} 要使用闭包实现默认的HTTP请求处理，可以使用http.HandleFunc()函数，函数定义： 123func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(Pattern, handler)} 而DefaultServeMux是ServeMux结构，拥有HandleFunc()方法，定义如下： 123func (mux *ServeMux) HandlerFunc(pattern string, handler func(ResponseWriter, *Request)) { mux.Handle(pattern, HandlerFunc(handler))} 上面代码将外部传入的函数handler()转为HandlerFunc类型，HandlerFunc类型实现了Handler的ServeHTTP方法，底层可以同时使用各种类型来实现Handler接口进行处理。 2.5函数闭包闭包是引用了“自由变量”的函数，被引用的自由变量和函数一同存在，即使已经离开了自由变量的环境也不会被释放或者删除，在闭包中可以继续使用这个自由变量，简单的说： 函数+引用环境=闭包 函数是编译期静态的概念，闭包是运行期动态的概念。 123456789101112131415161718package mainimport \"fmt\"func char() func(x int32) string { var str string = \"hello, \" return func(x int32) string { str += string(x) return str }}func main() { f := char() fmt.Println(\"1 \", f('a')) fmt.Println(\"2 \", f('b')) fmt.Println(\"3 \", f('c'))} 运行结果: 1 hello, a2 hello, ab3 hello, abc 个人理解，闭包其实就是利用栈的原理，通过实例化内部函数来保存局部变量。 2.6 可变参数func function(static variables, v ...T) (r) {} 123456789101112131415161718192021222324252627282930313233package mainimport ( \"bytes\" \"fmt\")func printTypeValue(slist ...interface{}) string { var b bytes.Buffer for _, s := range slist { str := fmt.Sprintf(\"%v\", s) var typeString string switch s.(type) { case bool: typeString = \"bool\" case string: typeString = \"string\" case int: typeString = \"int\" } b.WriteString(\"value: \") b.WriteString(str) b.WriteString(\" type: \") b.WriteString(typeString) b.WriteString(\"\\n\") } return b.String()}func main() { fmt.Println(printTypeValue(100, \"str\", true))} value: 100 type: intvalue: str type: stringvalue: true type: bool","link":"/2020/02/24/Golang%E5%87%BD%E6%95%B0/"},{"title":"[Golang] 容器","text":"当然了，这里的容器不是CNI之类的运行容器，而是指Golang中存储和组织数据的方式。 1.并发安全的sync.map及其Range()在golang中，常用test := make(map[string]int)的形式使用映射容器map，当然也可以直接在声明时填充内容： 12345m := map[string]int{ \"w\": 1, \"s\": 2, \"a\": 3, } 清空map的唯一方法：重新make一个新的map。但并发的map读写中会出现竞态问题，由sync包提供并发安全的map结构，如下： 1234567891011121314151617181920package mainimport ( \"fmt\" \"sync\")func main() { var scene sync.Map scene.Store(\"greece\", 97) scene.Store(\"london\", 100) scene.Store(\"egypt\", 200) fmt.Println(scene.Load(\"london\")) scene.Delete(\"london\") scene.Range(func(k, v interface{}) bool { fmt.Println(\"iterate:\", k, v) return true })} 代码输出如下： 100 trueiterate: egypt 200iterate: greece 97 在sync.Map中，Store表示存储，Load表示获取，Delete表示删除。比较有趣的是Range的使用，Range配合一个回调函数进行遍历操作，通过回调函数返回内部便利出来的值。Range参数接收到true时，继续迭代遍历，返回false时，终止迭代遍历。Range()方法可以遍历sync.Map，遍历需要提供一个匿名函数，参数为k、v，类型为interface{}，每次Range()在遍历一个元素时，都会调用这个匿名函数把结果返回。当然，sync.Map为了保证并发安全有一些性能损失，因此在非并发情况下，使用map相比使用sync.Map会有更好的性能。","link":"/2020/02/25/Golang%E5%AE%B9%E5%99%A8/"},{"title":"[NOTE] Hugo + Github Pages个人博客搭建","text":"回顾之前的学习经历，学习的知识与技术都不够透彻，解决过的问题再一次出现时往往又会难倒我，也正逢一个新的阶段，于是便决定搭建一个个人博客，对知识进行归类，深化知识脉络。 Go环境配置安装包是从Golang官网( https://golang.org )上下载的go1.12.6.windows-and64.msi安装包，安装比较傻瓜，值得注意的是有关go的几个环境变量： GOROOT为go所安装的具体位置，将之添加到系统环境变量中，windows系统还需要在path中新增$GOROOT/bin GOPATH可以理解为工作目录，默认为$USERNAME/go中，我将之调整到了D://go_work中，备忘 GOPATH目录下按照约定，将 bin文件夹用作存放golang编译的可执行文件 pkg用作存放golang编译时产生的.a文件 src用作存放项目的源码，同时，go run与go install等命令也在该目录中执行 安装golang的目的本来是为了直接编译hugo的源码，但遇到几个问题，git clone https://github.com/gohugoio/hugo.git速度奇慢，使用多个方法都没能解决 ，好不容易将整个源码下好之后，使用go install命令编译安装hugo时，又一次被网络环境给支配了，酸酸乳的没用。 无奈，只好下载适配的zip包解压安装。 hugo安装接前言， step by step 解压文件到指定目录后，将./hugo/bin添加到path中，此时hugo目录中包括bin、resource、sites三个文件夹，没有就补上 hugo new site test-pages，会出现第四个文件夹test-pages 此时还是一张白纸，既然要快速部署，就直接在https://themes.gohugo.io寻找自己喜欢的主题 在test-pages/themes目录下clone对应主题，照抄hugo/test-pages/themes/xxxxx/下的配置文件config.toml，顺便解释下hogo/test_pages目录下的几个文件夹的作用 config.toml为网站的配置文件，config.yaml``config.json也是支持的 ./content/post存放你写的md文件，content文件夹中会生成一个about.md文件，如下 123456789---title: About Hugo // 标题date: 2014-04-09 // 创建日期authorbox: false // sidebar: falsemenu: main // 页面是否加入到侧边栏cover: // 封面图地址tags:[\"Hugo\"] // 标签--- ./archetypes/default.md可以预设文章的模板，在新建的文章中会生效 ./data目录存放数据 ./layouts存放网站模板 ./static目录存放图片，最好已文章名分别存放图片，方便管理 将themes中主题的content文件夹中的内容放至./hugo/content/中，使用hugo server进行预览，在http://localhost:1313/中进行查看 Github Pages部署step by step new repository fusidic.github.io 使用hugo -t mainroad(意味着使用主题mainroad对md文件进行打包到public文件夹中)，再将hugo/test_pages/public中的内容上传 https://fusidic.github.io 上传时遇到了一个404的bug，提示没有index.html，可以等10~60分钟，或在网址后加个?可以解决 使用hugo新增在test_pages目录下，使用hugo new post/xxxx.md新增一个文本到content/post中，md的文件首部是关于 快速部署1234567891011121314151617181920212223242526272829303132#!/bin/bash# 部署到 github pages 脚本# 错误时终止脚本set -e# 删除打包文件夹rm -rf public# 打包。even 是主题hugo -t even # if using a theme, replace with `hugo -t &lt;YOURTHEME&gt;`# 进入打包文件夹cd public# Add changes to git.git initgit add -A# Commit changes.msg=\"building site `date`\"if [ $# -eq 1 ] then msg=\"$1\"figit commit -m \"$msg\"# 推送到github # nusr.github.io 只能使用 master分支git push -f git@github.com:nusr/nusr.github.io.git master# 回到原文件夹cd .. 遇到的一些问题 首先遇到的一个问题，文章的summarize因为没有了富文本的渲染，在首页显得十分丑，官方文档中说得十分详细，奈何没有相关的处理经验根本不知道在讲什么，参照这篇博客终于有了大致的了解，在官方论坛的这篇帖子上同样有人遇到了相同的问题，评论给出的几个解决的方向之后再研究吧… 针对上述问题，中文环境下在config.toml中添加hasCJKLanguage = ture可以使summarize发挥更好的效果，使用&lt;!--more--&gt;可以自定义summarize的截止。 反思之前的学习，对一些技术和知识的掌握始终不彻底，已经做过的一些东西经常会随时间遗忘。现今也算是处在一个新的阶段，有些东西不能再得过且过，于是便萌生了写博客的想法。","link":"/2019/07/03/Hugo-GithubPages%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"title":"[NOTE] 构建HTTPS","text":"@hou说了许久，刚好上次申请的证书快过期了，这次把泛域名开启HTTPS的一些流程及注意事项记录一下。 相关信息 certbot 0.39.0 python 2.7 CentOS 7 urllib3 requests 2.6 1.使用certbot申请证书Certbot利用Let’s encrypt自动申请证书，并可以自动更新证书。 安装Certbot签署通配符证书需要Certbot 0.22以上。如果以前安装过certbot，一般是直接yum update即可。如果是全新安装，则如下：先升级： 1yum update -y 查看系统版本： 1cat /etc/centos-release CentOS Linux release 7.4.1708 (Core) 安装epel源： 1yum install epel-release -y 安装certbot： 1yum install certbot -y 查看certbot版本： 1certbot --version certbot 0.39.0 注意：使用certbot可能会遇到urllib库无法调用的问题，解决方法如下： 1234567pip uninstall urllib3pip uninstall requestspip uninstall chardetyum remove python-requestsyum remove python-urllib3pip install --upgrade --force-reinstall 'requests==2.6.0' urllib3yum install certbot 申请证书nuzar.top与*.nuzar.top换成自己的域名： 1certbot -d nuzar.top -d *.nuzar.top --manual --preferred-challenges dns-01 --server https://acme-v02.api.letsencrypt.org/directory certonly --agree-tos 输入应急邮箱，证书到期前会有邮件提示： 12Enter email address (used for urgent renewal and security notices) (Enter 'c' tocancel): 如果想跳过输入邮箱的步骤，可在申请命令后面加上： 1--register-unsafely-without-email 之后出现如下提示：要公开记录申请该证书的IP地址，是否同意？不同意就无法继续。 12345678-------------------------------------------------------------------------------NOTE: The IP of this machine will be publicly logged as having requested thiscertificate. If you're running certbot in manual mode on a machine that is notyour server, please ensure you're okay with that.Are you OK with your IP being logged?-------------------------------------------------------------------------------(Y)es/(N)o: y 同意之后，出现如下提示，第一个“Press Enter to Continue”处直接回车，第二个“Press Enter to Continue”不要按回车： 12345678910111213141516171819-------------------------------------------------------------------------------Please deploy a DNS TXT record under the name_acme-challenge.co1dawn.com with the following value:iLS0NjcdP3RR1KphB6xbbVnKS_NS2uMW-xdDRzz85OMBefore continuing, verify the record is deployed.-------------------------------------------------------------------------------Press Enter to Continue #此处直接回车-------------------------------------------------------------------------------Please deploy a DNS TXT record under the name_acme-challenge.nuzar.top with the following value:f3V7aw5GPm5yzNsJFanQQaUFMyVQcqriUe3UjIDUHn0Before continuing, verify the record is deployed.-------------------------------------------------------------------------------Press Enter to Continue #此处不要按回车 验证服务器接上步中，需要在域名解析中添加TXT解析，_acme-challenge.nuzar.top，记录值为其提示的value，将其添加成功后，还需要等待一定时间使解析成功。 验证方法包括： 1host -t txt _acme-challenge.nuzar.top 或： 1dig -t txt _acme-challenge.nuzar.top @8.8.8.8 验证成功后，便可以回车了，之后会在目录/etc/letsencrypt/live/nuzar.top/中生成证书。 检查域名是否为泛域名： 1openssl x509 -in /etc/letsencrypt/live/nuzar.top/fullchain.pem -noout -text 2.Nginx使用证书证书存放如果在二级域名的配置中，你也是参照我的文章，那么此时只需要将证书加到对应文件夹root/nginx/conf.crt中。 由于certbot可以自动更新证书，不管是从任何角度，此时都应该保持证书所在位置不变，因此我们可以将/etc/letsencrypt/映射到{pwd}/nginx/conf.crt下，让nginx容器直接读取到证书文件。 这样一来，当90天期限到期时，证书可以直接更新，而不需要再进行一些额外的操作。 如我的文件结构: 12345678910111213141516|-- conf.crt| |-- accounts| |-- archive| |-- keys| |-- live| | |-- nuzar.top| | | |-- cert1.pem| | | |-- chain1.pem| | | |-- fullchain1.pem| | | `-- privkey1.pem|-- conf.d| `-- default.conf|-- html| `-- index.html|-- nginx`-- nginx.conf 这里放在哪其实没有太大关系，接下来在conf.d/default.conf中加入对443端口的监听，并且指明证书的位置(注意我们的nginx是容器环境，在存放证书时要注意是否放在了挂载卷的目录下) HTTPS开启接下来，就要修改Nginx的配置文件： sudo vim /root/nginx/conf.d/default.conf 1234567891011121314151617181920212223242526server { listen 443; listen [::]:443; server_name gitlab.nuzar.top; # enable ssl ssl on; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_ciphers \"EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4\"; # config ssl certificate ssl_certificate conf.crt/live/nuzar.top/fullchain.pem; ssl_certificate_key conf.crt/live/nuzar.top/privkey.pem; location ^~ /.well-known/acme-challenge/ { default_type \"text/plain\"; root /usr/share/nginx/html; } location = /.well-known/acme-challenge/ { return 404; } location / { proxy_pass http://127.0.0.1:6080; }} 此段配置的含义： listen：使Nginx监听443端口，即https默认的端口； server_name：接受gitlab.nuzar.top的请求；(此步骤需要添加域名解析gitlab到主机地址，前文中有提到) ssl_certificate：指定证书地址，注意路径 proxy_pass：将请求转发到http://127.0.0.1:6080 完成此步后，由于前文提到，容器的映射与之前有所不同，所以此时需要将容器删除 docker rm -f CONTAINER_ID，并重新运行一个新的容器 12345678docker run -d -p 80:80 -p 443:443 \\-v $(pwd)/nginx/conf.d:/etc/nginx/conf.d:ro \\-v /etc/letsencrypt:/etc/nginx/conf.crt:ro \\-v $(pwd)/nginx/nginx.conf:/etc/nginx/nginx.conf:ro \\-v $(pwd)/logs/nginx:/var/log/nginx \\-v $(pwd)/nginx/html:/usr/share/nginx/html \\--restart=always --name=gateway --network=host \\nginx 3.证书自动更新Let’s Encrypt 的 HTTPS 证书有效期只有90天，需要在即将到期时手动更新，这里借助 Systemd.timer 以及 Certbot 自动创建的 Systemd 服务进行自动更新（renew or renewal） 查看 certbot 自动更新是否启用 1$ systemctl is-enabled certbot-renew.timer enabled 启用 certbot 自动更新 1$ systemctl enable certbot-renew.timer 查看 certbot 自动更新是否运行 1$ systemctl list-timers 启动 certbot 自动更新 1$ systemctl start certbot-renew 利用脚本自动同步证书到Nginx的 /nginx/conf.crt路径下 待完成，可以手动哦 4. 更新 2020/03/31 update： 上述无法生效的情况下，可以选择使用手动更新：certbot renew，会在/etc/letsencrypt/archieve下生成新的证书（原证书依然在），同时/etc/letsencrypt/live下有活跃证书，软链接指向前者。 如果在更新中遇到报错的问题： 123456789101112131415161718192021222324252627certbot --nginx certonlyTraceback (most recent call last): File \"/usr/bin/certbot\", line 9, in &lt;module&gt; load_entry_point('certbot==0.24.0', 'console_scripts', 'certbot')() File \"/usr/lib/python2.7/site-packages/pkg_resources.py\", line 378, in load_entry_point return get_distribution(dist).load_entry_point(group, name) File \"/usr/lib/python2.7/site-packages/pkg_resources.py\", line 2566, in load_entry_point return ep.load() File \"/usr/lib/python2.7/site-packages/pkg_resources.py\", line 2260, in load entry = __import__(self.module_name, globals(),globals(), ['__name__']) File \"/usr/lib/python2.7/site-packages/certbot/main.py\", line 17, in &lt;module&gt; from certbot import account File \"/usr/lib/python2.7/site-packages/certbot/account.py\", line 17, in &lt;module&gt; from acme import messages File \"/usr/lib/python2.7/site-packages/acme/messages.py\", line 7, in &lt;module&gt; from acme import challenges File \"/usr/lib/python2.7/site-packages/acme/challenges.py\", line 11, in &lt;module&gt; import requests File \"/usr/lib/python2.7/site-packages/requests/__init__.py\", line 58, in &lt;module&gt; from . import utils File \"/usr/lib/python2.7/site-packages/requests/utils.py\", line 32, in &lt;module&gt; from .exceptions import InvalidURL File \"/usr/lib/python2.7/site-packages/requests/exceptions.py\", line 10, in &lt;module&gt; from .packages.urllib3.exceptions import HTTPError as BaseHTTPError File \"/usr/lib/python2.7/site-packages/requests/packages/__init__.py\", line 95, in load_module raise ImportError(\"No module named '%s'\" % (name,))ImportError: No module named 'requests.packages.urllib3' 这是由于系统更新时，会将request urllib等库更新，导致certbot脚本不可用，重新回退可解： 1pip2.7 install --upgrade --force-reinstall 'requests==2.6.0' urllib3 听说你想请我喝杯奶茶😊？","link":"/2019/11/22/HTTPS/"},{"title":"[NOTE] Kaggle house price prediction","text":"AbstractsThis is a copycat of Comprehensive data explorationi with Python. Since I had limited time to accomplish AI project. So I preferred learn from other’s notebook. And ‘Comprehensive data explorationi with Python’ is apparently the most fit one for me. According to the article, the first thing we should do is look through the whole data set, and find the most important variables which matters when you buy a house. And then an important problem we must deal with is Data Cleaning. OverviewsWhile ‘Type’ and ‘Segment’ is just for possible future reference, the column ‘Expectation’ is important because it will help us develop a ‘sixth sense’. To fill this column, we should read the description of all the variables and, one by one, ask ourselves: Do we think about this variable when we are buying a house? (e.g. When we think about the house of our dreams, do we care about its ‘Masonry veneer type’?). If so, how important would this variable be? (e.g. What is the impact of having ‘Excellent’ material on the exterior instead of ‘Poor’? And of having ‘Excellent’ instead of ‘Good’?). Is this information already described in any other variable? (e.g. If ‘LandContour’ gives the flatness of the property, do we really need to know the ‘LandSlope’?). I went through this process and concluded that the following variables can play an important role in this problem: OverallQual 总体质量 YearBuilt. TotalBsmtSF. 地下室面积 GrLivArea. 地上居住面积 Hmmm… It seems that ‘SalePrice’ and ‘GrLivArea’ are really old friends, with a *linear relationship.*** In my opinion, this heatmap is the best way to get a quick overview of our ‘plasma soup’ and its relationships. (Thank you @seaborn!) TotalBsmtSF and 1stFlrSF GarageX According to our crystal ball, these are the variables most correlated with ‘SalePrice’. My thoughts on this: ‘OverallQual’, ‘GrLivArea’ and ‘TotalBsmtSF’ are strongly correlated with ‘SalePrice’. Check! ‘GarageCars’ and ‘GarageArea’ are also some of the most strongly correlated variables. However, as we discussed in the last sub-point, the number of cars that fit into the garage is a consequence of the garage area. ‘GarageCars’ and ‘GarageArea’ are like twin brothers. You’ll never be able to distinguish them. Therefore, we just need one of these variables in our analysis (we can keep ‘GarageCars’ since its correlation with ‘SalePrice’ is higher). ‘TotalBsmtSF’ and ‘1stFloor’ also seem to be twin brothers. We can keep ‘TotalBsmtSF’ just to say that our first guess was right (re-read ‘So… What can we expect?’). ‘FullBath’?? Really? ‘TotRmsAbvGrd’ and ‘GrLivArea’, twin brothers again. Is this dataset from Chernobyl? Ah… ‘YearBuilt’… It seems that ‘YearBuilt’ is slightly correlated with ‘SalePrice’. Honestly, it scares me to think about ‘YearBuilt’ because I start feeling that we should do a little bit of time-series analysis to get this right. I’ll leave this as a homework for you. Let’s proceed to the scatter plots. Missing dataMissing data analysisUsing script below, we can easily get the missing data. 12345#missing datatotal = df_train.isnull().sum().sort_values(ascending=False)percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])print(missing_data.head(20)) Total Percent PoolQC 1453 0.995205 MiscFeature 1406 0.963014 Alley 1369 0.937671 Fence 1179 0.807534 FireplaceQu 690 0.472603 LotFrontage 259 0.177397 GarageCond 81 0.055479 GarageType 81 0.055479 GarageYrBlt 81 0.055479 GarageFinish 81 0.055479 GarageQual 81 0.055479 BsmtExposure 38 0.026027 BsmtFinType2 38 0.026027 BsmtFinType1 37 0.025342 BsmtCond 37 0.025342 BsmtQual 37 0.025342 MasVnrArea 8 0.005479 MasVnrType 8 0.005479 Electrical 1 0.000685 Utilities 0 0.000000 So how to handle the missing data? We’ll consider that when more than 15% of the data is missing, we should delete the corresponding variable and pretend it never existed. So we delete ‘PoolQC’, ‘MiscFeature’, ‘Alley’, ‘Fence’, ‘FireplaceQu’ and ‘LotFrontage’. As for ‘GarageX’, they all have the same number of missing data. Maybe the missing data refers to the same set of observations. Since the most important information regarding garages is expressed by ‘GarageCars’ and considering that we are just talking about 5% of missing data, I’ll delete the mentioned ‘GarageX‘ variables. The same logic applies to ‘BsmtX‘ variables. As for ‘MasVnrArea’(砖石饰面面积) and ‘MasVnrType’(砖石饰面种类), we can consider that these variables have a strong correlation with ‘YearBuilt’ and ‘OverallQual’ which are already considered. So we delete ‘MasVnrArea’ and ‘MasVnrType’. Delete missing variablesWe’ll delete all the variables with missing data, except the variable ‘Electrical’. In ‘Electrical’ we’ll just delete the observation with missing data. 1234#dealing with missing datadf_train = df_train.drop((missing_data[missing_data['Total'] &gt; 1]).index,1)df_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)df_train.isnull().sum().max() #just checking that there's no missing data missing... If the output is ‘0’, it means you have fully delete missing data. Out liarsThe primary concern here is to establish a threshold that defines an observation as an outlier. To do so, we’ll standardize the data. In this context, data standardization means converting data values to have mean of 0 and a standard deviation of 1. 1这里主要关注的是建立一个将观察值定义为异常值的阈值。为此，我们将对数据进行标准化。在这种情况下，数据标准化意味着将数据值转换为平均值为0且标准差为1。 12345678#standardizing datasaleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);low_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]high_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]print('outer range (low) of the distribution:')print(low_range)print('\\nouter range (high) of the distribution:')print(high_range) 这一步的目的应该是为了找出数据中的离群值，这里需要关注的是两个大于7的变量。 1234567891011121314#bivariate analysis saleprice/grlivareavar = 'GrLivArea'data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));#deleting pointsdf_train.sort_values(by = 'GrLivArea', ascending = False)[:2]df_train = df_train.drop(df_train[df_train['Id'] == 1299].index)df_train = df_train.drop(df_train[df_train['Id'] == 524].index)#bivariate analysis saleprice/grlivareavar = 'TotalBsmtSF'data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000)); 将’GrlivArea’中的离群值删除。 之后考察’TotalBsmtSF’中的离群值，但它的离群值表现在可以接受的范围之内。 Getting hard coreAccording to Hair et al. (2013), four assumptions should be tested: Normality: The data should look like a normal distribution. Homoscedasticity: 这个用英文解释不太好懂，同方性是可取的，我们希望误差项在自变量的所有值上都相同； Linearity: 正如前文已经做过的，通过散点图的方法来观测两个变量之间是否有线性的相关性，如果相关性不是线性的，那么可以通过一定的数学转换使其线性相关； Absence of correlated errors: NormalityThe point here is to test ‘SalePrice’ in a very lean way. We’ll do this paying attention to: Histogram - Kurtosis and skewness. Normal probability plot - Data distribution sould closely follow the diagonal that represents the normal distribution. 1234#histogram and normal probability plotsns.distplot(df_train['SalePrice'], fit=norm);fig = plt.figure()res = stats.probplot(df_train['SalePrice'], plot=plt) 对变量取log转换得： 12#applying log transformationdf_train['SalePrice'] = np.log(df_train['SalePrice']) 可以看到，散点更为均匀地分布在了直线的两侧。 以同样的方法对’GrLivArea’与’TotalBsmtSF’进行处理。 其中面临一个很严重的问题是，有些值为0，所以在这些值上，我们无法对它们取log。要在此处应用对数转换，我们将创建一个变量，该变量可以具有或不具有地下室的效果（二进制变量）。然后，我们将对所有非零观测值进行对数转换，而忽略那些值为零的观测值。这样，我们可以转换数据，而不会失去某些变量的影响。 12345678910111213#create column for new variable (one is enough because it's a binary categorical feature)#if area&gt;0 it gets 1, for area==0 it gets 0df_train['HasBsmt'] = pd.Series(len(df_train['TotalBsmtSF']), index=df_train.index)df_train['HasBsmt'] = 0 df_train.loc[df_train['TotalBsmtSF']&gt;0,'HasBsmt'] = 1transform datadf_train.loc[df_train['HasBsmt']==1,'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])#histogram and normal probability plotsns.distplot(df_train[df_train['TotalBsmtSF']&gt;0]['TotalBsmtSF'], fit=norm);fig = plt.figure()res = stats.probplot(df_train[df_train['TotalBsmtSF']&gt;0]['TotalBsmtSF'], plot=plt) Main Variables Variable Segment Data Type Comments GrLivArea 1 0 生活面积 TotalBsmtSF 1 0 地下室总面积 GarageArea/GarageCars 1 0 车库 YearBuilt 0 1 建造年份 CentralAir 0 1 中央空调 OverallQual 0 1 总体评价 Neighborhood 2 1 地段 Now we can make sure there 7 variables will participate in our model. And we have cleaned the data set. The final thing left to do is to get the PREDICTION. Model: Random forestWhy use this? Idk, otherwise the blog didn’t describe the reason clearly. The code displays below. And I have little trouble understanding the Random Forest Algorithm. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 获取数据data_train = pd.read_csv('./train.csv')cols = ['OverallQual','GrLivArea', 'GarageCars','TotalBsmtSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt']x = data_train[cols].valuesy = data_train['SalePrice'].valuesx_scaled = preprocessing.StandardScaler().fit_transform(x)y_scaled = preprocessing.StandardScaler().fit_transform(y.reshape(-1,1))X_train,X_test, y_train, y_test = train_test_split(x_scaled, y_scaled, test_size=0.33, random_state=42)clfs = { 'svm':svm.SVR(), 'RandomForestRegressor':RandomForestRegressor(n_estimators=400), 'BayesianRidge':linear_model.BayesianRidge() }for clf in clfs: try: clfs[clf].fit(X_train, y_train) y_pred = clfs[clf].predict(X_test) print(clf + \" cost:\" + str(np.sum(y_pred-y_test)/len(y_pred)) ) except Exception as e: print(clf + \" Error:\") print(str(e))cols = ['OverallQual','GrLivArea', 'GarageCars','TotalBsmtSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt']x = data_train[cols].valuesy = data_train['SalePrice'].valuesX_train,X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)clf = RandomForestRegressor(n_estimators=400)clf.fit(X_train, y_train)y_pred = clf.predict(X_test)print(y_pred)rfr = clfdata_test = pd.read_csv(\"./test.csv\")data_test[cols].isnull().sum()data_test['GarageCars'].describe()data_test['TotalBsmtSF'].describe()cols2 = ['OverallQual','GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt']cars = data_test['GarageCars'].fillna(1.766118)bsmt = data_test['TotalBsmtSF'].fillna(1046.117970)data_test_x = pd.concat( [data_test[cols2], cars, bsmt] ,axis=1)data_test_x.isnull().sum()x = data_test_x.valuesy_te_pred = rfr.predict(x)print(y_te_pred)print(y_te_pred.shape)print(x.shape)prediction = pd.DataFrame(y_te_pred, columns=['SalePrice'])result = pd.concat([ data_test['Id'], prediction], axis=1)# result = result.drop(resultlt.columns[0], 1)result.columns# save the predictionresult.to_csv('./Predictions.csv', index=False)","link":"/2019/12/15/Kaggle-houseprice-prediction/"},{"title":"[Kubernetes] Bootstraping with Kubeadm","text":"Make some records while installing kubernetes. 1.Before you begin 系统环境: Ubuntu 16.04+ Debian 9+ CentOS 7 Red Hat Enterprise Linux (RHEL) 7 Fedora 25+ HypriotOS v1.0.1+ Container Linux (tested with 1800.6.0) RAM &gt;= 2GB 2 CPUs or more 确保集群之间可以互相连通 确保hostname、MAC地址不重复 确保端口为被占用 确保关闭交换分区 确保可以连接到镜像网站(外网) 不要使用nftablesnftables虽好，但不支持，所以还是用iptables Debian or Ubuntu Fedora 1234sudo update-alternatives --set iptables /usr/sbin/iptables-legacysudo update-alternatives --set ip6tables /usr/sbin/ip6tables-legacysudo update-alternatives --set arptables /usr/sbin/arptables-legacysudo update-alternatives --set ebtables /usr/sbin/ebtables-legacy 端口检查 Control-plane node(s) Protocol Direction Port Range Purpose Used By TCP Inbound 6443* Kubernetes API server All TCP Inbound 2379-2380 etcd server client API kube-apiserver, etcd TCP Inbound 10250 Kubelet API Self, Control plane TCP Inbound 10251 kube-scheduler Self TCP Inbound 10252 kube-controller-manager Self Worker node(s) Protocol Direction Port Range Purpose Used By TCP Inbound 10250 Kubelet API Self, Control plane TCP Inbound 30000-32767 NodePort Services** All 时钟同步See this post. 修改hostname123[root@k8s-master ~]$ vim /etc/hostname # 修改hostname[root@k8s-master ~]$ vim /etc/hosts # 将本机IP指向hostname[root@k8s-master ~]$ reboot -h # 重启(可以做完全部前期准备后再重启) 修改后, 两台虚拟机的配置如下: 12345678910111213# in k8s-master[root@k8s-master ~]$ cat /etc/hostname k8s-master[root@k8s-master ~]$ cat /etc/hosts | grep k8s10.33.30.92 k8s-master10.33.30.91 k8s-worker# in k8s-worker[root@k8s-worker ~]$ cat /etc/hostname k8s-worker[root@k8s-worker ~]$ cat /etc/hosts | grep k8s10.33.30.92 k8s-master10.33.30.91 k8s-worker 确认MAC和product_uuid的唯一性 文档链接: Verify the MAC address and product_uuid are unique for every node 12[root@k8s-master ~]$ ifconfig -a # 查看MAC[root@k8s-master ~]$ cat /sys/class/dmi/id/product_uuid # 查看product_uuid 注: 如果你的centos7没有ifconfig命令, 可以执行yum install net-tools进行安装. 配置防火墙 文档链接: Check required ports 由于是本地内网测试环境, 笔者图方便, 直接关闭了防火墙. 若安全要求较高, 可以参考官方文档放行必要端口. 12[root@k8s-master ~]$ systemctl stop firewalld # 关闭服务[root@k8s-master ~]$ systemctl disable firewalld # 禁用服务 禁用SELinux 文档链接: coredns pods have CrashLoopBackOff or Error state 修改/etc/selinux/config, 设置SELINUX=disabled. 重启机器. 12[root@k8s-master ~]$ sestatus # 查看SELinux状态SELinux status: disabled 禁用交换分区 文档链接: Before you begin Swap disabled. You MUST disable swap in order for the kubelet to work properly. 编辑/etc/fstab, 将swap注释掉. 重启机器. 12[root@k8s-master ~]$ vim /etc/fstab #/dev/mapper/cl-swap swap swap defaults 0 0 安装Docker 文档链接: Get Docker Engine - Community for CentOS Docker官方文档对安装步骤描述已经足够详细, 过程并不复杂, 本文便不再赘述. Docker请使用18.09, k8s暂不支持Docker最新版19.x, 安装时请按照文档描述的方式明确指定版本号yum install docker-ce-18.09.9-3.el7 docker-ce-cli-18.09.9-3.el7 containerd.io. 若网络不好, 可换用国内源, 阿里云、中科大等都可. 此处附上阿里云源docker安装文档地址: 容器镜像服务. 安装完毕后, 建议将docker源替换为国内. 推荐阿里云镜像加速, 有阿里云账号即可免费使用.阿里云 -&gt; 容器镜像服务 -&gt; 镜像中心 -&gt; 镜像加速 配置Docker 文档地址: Container runtimes 修改/etc/docker/daemon.json为如下内容: 123456789{ &quot;registry-mirrors&quot;: [&quot;https://xxxxxxxx.mirror.aliyuncs.com&quot;], &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: { &quot;max-size&quot;: &quot;100m&quot; }, &quot;storage-driver&quot;: &quot;overlay2&quot;} 其中https://xxxxxxxx.mirror.aliyuncs.com为阿里云镜像加速地址, xxxxxxxx需要替换为自己账户中的地址. 安装配置完毕后执行: 12[root@k8s-master ~]$ systemctl enable docker[root@k8s-master ~]$ systemctl start docker 2.安装 kubeadm, kubelet, kubectl kubeadm: the command to bootstrap the cluster. kubelet: the component that runs on all of the machines in your cluster and does things like starting pods and containers. kubectl: the command line util to talk to your cluster. version skew 12345678sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https curlcurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -cat &lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.listdeb https://apt.kubernetes.io/ kubernetes-xenial mainEOFsudo apt-get updatesudo apt-get install -y kubelet kubeadm kubectlsudo apt-mark hold kubelet kubeadm kubectl The kubelet is now restarting every few seconds, as it waits in a crashloop for kubeadm to tell it what to do. 3.开始安装 Run kubeadm config images pull prior to kubeadm init to verify connectivity to gcr.io registries. If you meet some trouble here, see the Troubleshooting 1 kubeadm config print init-defaults &gt; init.default.yaml cp init.default.yaml init-config.yaml vim init-config.yaml 相关配置信息，查阅kubeadm documents. 我修改完的文件如下： 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: kubeadm.k8s.io/v1beta2bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: advertiseAddress: 192.168.1.251 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: k8s-master taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta2certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: {}dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcdimageRepository: registry.cn-hangzhou.aliyuncs.com/google_containerskind: ClusterConfigurationkubernetesVersion: v1.17.0networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12scheduler: {} kubeadm config images pull拉取所需要的镜像 kubeadm init 12345678910111213141516171819202122root@openstack1:~/kubernetes# kubeadm init --config=init-config.yaml[init] Using Kubernetes version: v1.17.0[preflight] Running pre-flight checks [WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.17.0. Kubeadm version: 1.16.x······Your Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.1.251:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:0a77d9dc7d5fd833203211767a869324e512222540f9bbf0e70cb4bb87d981c0 之后按照给出的提示，mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $ $(id -u):$(id -g) $HOME/.kube/config kubeadm在Master上也安装了kubelet，在默认情况下Master不参与工作负载，如果你此时想安装一个All-In-One的Kubernetes环境，可以执行下面的命令(删除Node的Label “node-role.kubernetes.io/master”), 让Master成为一个Node：kubectl taint nodes --all node-role.kubernetes.io/master- 4. Installing network add-on必须在安装网络插件之后，pods之间才能互相通信。 The network must be deployed before any applications. Also, CoreDNS will not start up before a network is installed. kubeadm only supports Container Network Interface (CNI) based networks (and does not support kubernet) Weave Net Set /proc/sys/net/bridge/bridge-nf-call-iptables to 1 by running sysctl net.bridge.bridge-nf-call-iptables=1 to pass bridged IPv4 traffic to iptables’ chains. This is a requirement for some CNI plugins to work, for more information please see here. The official Weave Net set-up guide is here. Weave Net works on amd64, arm, arm64 and ppc64le without any extra action required. Weave Net sets hairpin mode by default. This allows Pods to access themselves via their Service IP address if they don’t know their PodIP. 1kubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\" calico 下载描述文件 123[root@k8s-master ~]$ wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml[root@k8s-master ~]$ cat kubeadm-init.yaml | grep serviceSubnet:serviceSubnet: 10.96.0.0/12 打开calico.yaml, 将192.168.0.0/16修改为10.96.0.0/12 需要注意的是, calico.yaml中的IP和kubeadm-init.yaml需要保持一致, 要么初始化前修改kubeadm-init.yaml, 要么初始化后修改calico.yaml. 执行kubectl apply -f calico.yaml初始化网络. 此时查看node信息, master的状态已经是Ready了. 123[root@k8s-master ~]$ kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master Ready master 15m v1.17.0 更多方法 5. Dashboard 文档地址: Web UI (Dashboard) 部署Dashboard 文档地址: Deploying the Dashboard UI 可以通过kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml按照官方模版创建一个dashboard 创建用户 文档地址: Creating sample user 由于安全机制，k8s对用户的访问管理十分严格，此处的目的是为了创建一个用于登录Dashboard的用户，创建文件dashboard-adminuser.yaml内容如下: 123456789101112131415161718apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kube-system 执行命令kubectl apply -f dashboard-adminuser.yaml 访问dashboard 的方式 kubernetes-dashboard 服务暴露了 NodePort，可以使用 http://NodeIP:nodePort 地址访问 dashboard 通过 kubectl proxy 访问 dashboard 通过 API server 访问 dashboard（https 6443端口和http 8080端口方式） 前两种方式可以参考此文，本文主要讲述第三种方式。 在~/.kube/路径下，执行 123grep 'client-certificate-data' ~/.kube/config | head -n 1 | awk '{print $2}' | base64 -d &gt;&gt; kubecfg.crtgrep 'client-key-data' ~/.kube/config | head -n 1 | awk '{print $2}' | base64 -d &gt;&gt; kubecfg.keyopenssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name \"kubernetes-client\" 第三行命令会要求输入密码，记住你此时输入的密码，将会得到一个kubecfg.p12文件，将其拷贝到将要访问dashboard 的主机上(用scp)，在该主机上点击打开证书文件，用刚才的密码解锁，并导入到计算机中。 加下来访问http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ 如果碰到页面显示 1234567891011121314{\"kind\": \"Status\",\"apiVersion\": \"v1\",\"metadata\": {},\"status\": \"Failure\",\"message\": \"pods is forbidden: User \"system:anonymous\" cannot list pods in the namespace \"default\"\",\"reason\": \"Forbidden\",\"details\": {\"kind\": \"pods\"},\"code\": 403} 那么参考这个issue，在之前用来生成dashboard的recommend.yaml中加入 123456789101112131415161718192021222324252627---# ------------------- Gross Hack For anonymous auth through api proxy ------------------- ## Allows users to reach login page and other proxied dashboard URLskind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: kubernetes-dashboard-anonymousrules:- apiGroups: [\"\"] resources: [\"services/proxy\"] resourceNames: [\"https:kubernetes-dashboard:\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]- nonResourceURLs: [\"/ui\", \"/ui/*\", \"/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/*\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard-anonymousroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: kubernetes-dashboard-anonymoussubjects:- kind: User name: system:anonymous 通过命令重新启动dashboard：kubectl replace --force -f recommended.yaml 继续打开页面https://{k8s-master-ip}:6443/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#/login 将会看到下图 ![dashboard]( 此时需要使用Token登录 生成Token执行kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}'), 获取Token. 6. Joining your nodes 其他机器加入cluster: 按照前文步骤，安装kubeadm, kubelet 关闭swap分区 进行2、3、4步操作 运行: `kubeadm join 192.168.1.251:6443 –token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:9c06556766e6dbf15385dc62b99e4f40d15b8412ca5bd853a79cbee1f14724f8` (此处为前文命令提示的，此token非5中token) 如果你没有token，运行kubeadm token list(在master上)，可以查看token 默认token在24小时后到期，如果token已经到期 kubeadm token create得到新token，或使用kubeadm token list查看token 获取ca证书sha256编码hash值 1openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //' Tear downTo undo what kubeadm did, you should first drain the node and make sure that the node is empty before shutting it down. Talking to the control-plane node with the appropriate credentials, run: 12kubectl drain &lt;node name&gt; --delete-local-data --force --ignore-daemonsetskubectl delete node &lt;node name&gt; Then, on the node being removed, reset all kubeadm installed state: 1kubeadm reset The reset process does not reset or clean up iptables rules or IPVS tables. If you wish to reset iptables, you must do so manually: 1iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X If you want to reset the IPVS tables, you must run the following command: 1ipvsadm -C If you wish to start over simply run kubeadm init or kubeadm join with the appropriate arguments. More options and information about the kubeadm reset command 123Failed to create pod sandbox: rpc error: code = Unknown desc = [failed to set up sandbox container \"2fd3d89066e8990021729afcb5b209dc5246ce1cbba6ee16b7242bdbef1dfc66\" network for pod \"calico-kube-controllers-778676476b-rrwsh\": networkPlugin cni failed to set up pod \"calico-kube-controllers-778676476b-rrwsh_kube-system\" network: error getting ClusterInformation: resource does not exist: ClusterInformation(default) with error: clusterinformations.crd.projectcalico.org \"default\" not found, failed to clean up sandbox container \"2fd3d89066e8990021729afcb5b209dc5246ce1cbba6ee16b7242bdbef1dfc66\" network for pod \"calico-kube-controllers-778676476b-rrwsh\": networkPlugin cni failed to teardown pod \"calico-kube-controllers-778676476b-rrwsh_kube-system\" network: error getting ClusterInformation: resource does not exist: ClusterInformation(default) with error: clusterinformations.crd.projectcalico.org \"default\" not found]Back-off restarting failed containerReadiness probe failed: Failed to read status file status.json: open status.json: no such file or directory","link":"/2019/12/23/KubernetesKubeadm/"},{"title":"Linux搭建TimeMachine备份服务器","text":"上了pdd的车，最终还是入手了一台丐版mbp，256G的存储空间使用起来让人心疼，Time Machine本来是一款很不错的备份工具，然而有限的空间经不起它无止境扩大的备份策略的折腾了。备份不做，十恶不赦，好在实验室的服务器最近一直闲置，在网上看了几套方案之后就准备开始了。 开始之前在开始之前，首先最好选择一个合适的账户登录主机，这个账户将在之后被用来进行远程登录获取服务。 安装Netatalk和AvahiNetatalk是一个开源的协议，支持类Unix系统为Mac提供文件服务，安装Netatalk： sudo apt install Netatalk Avahi允许程序在本地网络环境中分发与提供服务，同样通过apt安装Avahi： sudo apt avahi 创建文件 /etc/avahi/services/afpd.service来配置 avahi，写入如下内容： 123456789101112&lt;service-group&gt;&lt;name replace-wildcards=&quot;yes&quot;&gt;%h&lt;/name&gt;&lt;service&gt;&lt;type&gt;_afpovertcp._tcp&lt;/type&gt;&lt;port&gt;548&lt;/port&gt;&lt;/service&gt;&lt;service&gt;&lt;type&gt;_device-info._tcp&lt;/type&gt;&lt;port&gt;0&lt;/port&gt;&lt;txt-record&gt;model=Xserve&lt;/txt-record&gt;&lt;/service&gt;&lt;/service-group&gt; 挂载硬盘参考博客的作者采用了HFS+来对硬盘进行处理(格式化？)，通过apt install hfsplus即可成功安装，博客中由于是安装的精简系统，在使用modprobe hfsplus之后报错，需要打官方补丁才能解决这个坑，而我们不需要。 由于在当初安装192.168.1.253机器的时候，将Samsung 970 evo 1T单独放在一边，未在其中初始化分区，因此这块硬盘上还是windows的分区格式，通过fdisk -l查询到这块硬盘的名称为/dev/nvme0n1，将它格式化为ext4 sudo mkfs.ext4 /dev/nvme0n1 不知道从哪看的规矩，说是挂在硬盘要放在/media下，不过这也无关紧要，mkdir /media/nvme0n1，再将硬盘挂载到该目录上: mount -t hfsplus -o force,rw /dev/nvme0n1 /media/nvme0n1 由于mount命令在重启服务器之后会失效，所以将分区信息写入文件中： sudo vi /etc/fstab 1/dev/nvme0n1 /media/nvme0n1 ext4 defaults 0 2 这句中2代表在系统开机时会对该分区进行快速检测，如果你不希望这么做，可以把它改成0跳过开机检测。 权限问题如果是按照顺序来的话，应该此处不会遇到权限问题，但我当时没有。 比较严谨的方法挂载成功后你的非 root 用户可能是无法写入的，这是由于磁盘内容自有用户造成的，最简单的办法可能就是欺骗文件让它以为你还是原来的用户。mac 中默认用户 UID 是 501，那么我们就把跑 netatalk 的用户id改为 501: 123sudo groupadd admin //创建管理组sudo useradd -d /home/tempuser -m -s /bin/bash -G admin tempuser //创建一个临时用户sudo passwd tempuser //给用户一个密码，别忘记了 做完之后退出当前用户，然后用这个临时用户进去，如果你用的是 ssh，那么就退出来，用 ssh tempuser@xxx.xxx.xxx.xxx 重新登录。登录之后继续： 1sudo usermod --uid 501 yourusername //改你刚才用户的uid 这时候你可能会收到提示说还有进程在占用，不能改。这很好办，根据提示的pid，干掉那个进程即可： sudo kill &lt;pid&gt; 然后重复执行上面的命令，没关系，有多少个占用就干多少个…… 12sudo chown -R 501:yourusername /home/yourusername //上边这行两处都要改成你自己的用户名，这个是改目录所有权的 接下来，你就可以退出然后用你原来的用户登录了，这时候再去挂载的目录看看，已经可写。别忘了删除那个临时用户： 1sudo userdel -r tempuser 比较粗暴的方法之后用哪个用户登录，直接把对应文件夹及子文件的所有者全改了 1chown -R username:usergroup /media/ 简单粗暴，配合更高权限的用户，先解决问题再说，反正只是内网。 配置Netatalk创建Time Machine的备份文件夹： 123mkdir /media/nvme0n1/TimeMachinesudo vi /etc/netatalk/AppleVolumes.default 大写G直接跳到文件末尾，加上： 123456# The line below sets some DEFAULT, starting with Netatalk 2.1.:DEFAULT: options:upriv,usedots/media/nvme0n1/TimeMachine &quot;TimeMachine&quot; options:tm/media/nvme0n1/NAS &quot;NAS&quot;# By default all users have access to their home directories.#~/ &quot;Home Directory&quot; 重点就是第三行末尾的 options:tm 标记这一句让对应的目录对 TimeMachine 可见。 最后，我们重启对应的服务： 12sudo service netatalk restartsudo service avahi-daemon restart Mac端设置在Mac终端中执行这条命令让tm发现网络备份位置： 1defaults write com.apple.systempreferences TMShowUnsupportedNetworkVolumes 1 这下你就应该已经能够在 tm 配置中发现你的网络位置了！ 给服务器添加 windows 共享win 使用的共享协议叫做 samba，协议的名字叫 smb，mac其实能够支持smb，这样的话我们就可以让 tm 走 afp，另外来一个目录专门跑 smb，用来 mac 和 win 共享文件了。 使用如下命令来安装 samba： 123sudo apt-get install sambasudo apt-get install smbclient # Linux客户端测试用 备份原配置文件: 1sudo cp /etc/samba/smb.conf /etc/samba/smb.conf.bak 编辑配置文件： vim /etc/samba/smb.conf，在末尾追加如下内容： 123456[share] path = /home/share browseable = yes writable = yes comment = smb share test public = no //避免匿名登录 这个share就是之后的地址了，这里等于做了个地址映射。然后为 samba 创建一个用户，这个用户必须是已经存在的用户： 1sudo smbpasswd -a smbuser 创建的密码就是你要登录 samba 的密码，别记错了。最后重启服务： 1sudo service smbd restart 之后windows上连接到服务器就只需要在网络映射配置中加上\\\\192.168.1.253\\share，再输入对应密码，就可以像访问本地磁盘一样访问服务器上的磁盘了。","link":"/2019/07/26/Linux%E6%90%AD%E5%BB%BATimeMachine%E5%A4%87%E4%BB%BD%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"Linux文件系统架构","text":"本文将介绍类Unix系统中一系列文件目录存放的基本原则与标准。这篇向导旨在为系统的交互性、系统的管理工具、开发工具、脚本提供支持，使其在所有系统中更加统一。本文参考 1.介绍这篇标准主要是为了帮助软件预测将要安装的目录和路径，以及帮助用户定位已安装的文件路径。本文为文件系统的每个区域提供指导原则，同时也会列举不被包括在这个原则中的一些情况及一些历史冲突案例。 2.文件系统这篇标准假定操作系统是底层是兼容文件系统层次结构标准(Filesystem Hierarchy Standard, FHS)，并且遵循大多数UNIX文件系统的基本安全标准。 文件系统的设计中明确两个重要的区别：可分享与不可分享、静态与动态。大体上文件将基于这两个区别来决定它应该存放于哪个目录。 可分享：存储在一台主机中的文件可以被其他主机使用； 不可分享：即不可分享的文件； 静态：包括二进制文件、库文件、文档文件和其他在没有管理员干预下无法改动的文件； 动态：即非静态的。 相关说明： 可分享文件可以被其他主机使用，然而并不是所用文件系统层次架构中的文件都是可分享的，即系统都是有一些本地存储包括在不可分享文件中，如果一个文件系统所需要的文件都存储在另一台主机中，通过挂载在本机中挂载几个目录将使得访问这些文件变得极为方便。 静态文件与动态文件必须要做出隔离，因为静态文件不像是动态文件，它可以已只读的形式被存储在媒介上，并且不需要像动态文件一样定期的进行备份。 以下是遵循文件系统层次架构标准的示例： Shareable Unshareable static /usr /etc /opt /boot variable /var/mail /var/run /var/spool/news /var/lock 3.文件系统根目录","link":"/2019/07/08/Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"},{"title":"Linux用户权限管理","text":"指令 添加用户 useradd -d /home/test test -m，创建用户test(自动生成目录)，该用户属于test用户组 useradd -d /home/a a -g test -m，创建用户a，属于test用户组 -d：指定用户登录系统时的主目录 -m：自动建立目录 -g：指定组名称 设置密码 passwd test 删除用户 userdel test删除test用户，但并不删除/home/test userdel -r test删除test用户与其目录 切换用户 su 查看当前用户组 cat /etc/group groupmod+三次tab键 组账号操作 添加组：groupadd 删除组：groupdel 查看组：cat /etc/group 修改用户所在组：usermod -g group_name user_name 查看用户组成员 groups group_name 为新用户添加sudo权限 sudo usermod -a -G adm user_name sudo usermod -a -G sudo user_name 实例： linux环境下创建新用户在使用docker中会遇到permission denied的问题，这是由于docker启动守护进程的时候，会默认赋予docker用户组的成员读写unix socket的权限，因此，将新用户加入到docker用户组中，问题就可以解决了： sudo usermod -a -G docker zjs 之后需要更新用户组newgrp docker 修改文件权限 字母法：chmod u/g/o/a +/-/= rwx file_name 所有者 含义 u user g group o other a all + - = 含义 + 增加权限 - 撤销权限 = 设定权限 r w x 含义 r read w write x excute 数字法： chomod 777 test/ -R -R表示级联授权 777：所有者用户/组内其他用户/其他组用户 = rwx/rwx/rwx 修改文件所有者 chown user_name file_name 修改文件所属组 chgrp group_name file_name 操作添加用户赋予权限： sudo vi /etc/sudoers 在root ALL=(ALL) ALL下添加一行test ALL=(ALL) ALL","link":"/2019/07/08/Linux%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"title":"[NOTE] Linux防火墙","text":"CentOS firewalldFirewalld is installed on CentOS 7 as default. Here comes some operations of it. Check firewall status: sudo firewall-cmd --state Disable firewalld: sudo systemctl disable firewalld(禁止开机启动) Stop firewalld: sudo systemctl stop firewalld Ubuntu 18.04 ufw check a current firewall status:sudo ufw status for more verbose:sudo ufw status verbose enable firewall:sudo ufw enable disable firewall:sudo ufw disable 基操： sudo ufw default deny incoming sudo ufw default allow outgoing sudo ufw allow ssh or sudo ufw allow 22 sudo ufw allow 2222 sudo ufw allow http or sudo ufw allow 80 sudo ufw allow https or sudo ufw allow 443 sudo ufw allow 6000:6003/tcp sudo ufw allow 6000:6003/udp","link":"/2019/07/08/Linux%E9%98%B2%E7%81%AB%E5%A2%99/"},{"title":"Poker2键盘说明书(防遗失)","text":"编程说明 按PMode（FN+右CTRL）进入编程模式（空格右灯闪烁） 按想要对其编程的建（空格右灯长亮） 键入编程内容然后按PN（空格右灯再次闪烁）\\ 重复步骤2和步骤3可编程其他键 按PMode（FN+右CTRL）退出编程模式（空格右灯熄灭） 备注： 支持FN层编程，在选键状态时可以对FN组合键（例如：FN+A）编程 在选键状态（步骤1）打开文书软件（比如.txt型文本文档）并按PN+任意键可自动分层显示其编程内容 可以加延时，每按15sm键（FN+F）一次延时15ms，每按0.1s键（FN+G）一次延时0.1s，每按0.5s键（FN+H）一次延时0.5s，连续多次延时只计一个按键但时间累加 每个键最多可以编程14个键在编程模式15秒内没按任何键会自动退出 功能表格","link":"/2019/07/05/Poker2%E9%94%AE%E7%9B%98%E8%AF%B4%E6%98%8E%E4%B9%A6-%E9%98%B2%E9%81%97%E5%A4%B1/"},{"title":"[Script] 脚本乱写I","text":"Shell脚本乱写（一）1. 自动新增用户并配置权限要实现： 读取参数：选定运行主机、用户名 新建用户到组 usreadd -G 为用户配置默认密码：centos中为用户配置默认密码可以使用passwd --stdin USERNAME，在脚本中可以使用echo &quot;PASSWORD&quot; ｜ passwd --stdin USERNAME，但在Ubuntu中passwd并不支持--stdin，此时可以使用echo USERNAME:PASSWORD | chpasswd 事先将用户组加入到/etc/sudoers中 用户首次登陆时提示需要修改密码，用户激活时限为2年 chage 123456789101112131415#!/bin/bash# Program:# Grand a new user with ROOT privileges.## History:# 2019/11/9 Fusidic First releaseecho \"Please input username\"read usernamepath='/root/bin/hosts'cat /root/bin/hosts | while read line;do echo $line ssh -n $line \"useradd ${username} -m -G AWG &amp;\" ssh -n $line \"echo \"${username}:nuaacs204\" | chpasswd &amp;\"# ssh -n $line \"chage -d 0 ${username} &amp;\"done 遇到的问题： while循环只执行一次，后添加了-n参数 新建用户修改权限失败passwd: Authentication token manipulation error passwd: password unchanged，这是由于有权限改/etc/passwd而无权限修改/etc/shadow 未解决：使用chage修改用户有效时间，以此达到让用户登陆账户立即强制改密码存在问题，改密码无效，可能是权限问题。","link":"/2019/11/11/Shell%E8%84%9A%E6%9C%AC%E4%B9%B1%E5%86%991/"},{"title":"[SpringCloud] 笔记(一)","text":"power by 楠哥教你学Java 单体应用存在的问题 随着业务的发展，开发变得越来越复杂。 修改、新增某个功能，需要对整个系统进行测试、重新部署。 一个模块出现问题，很可能导致整个系统崩溃。 多个开发团队同时对数据进行管理，容易产生安全漏洞。 各个模块使用同一种技术进行开发，各个模块很难根据实际情况选择更合适的技术框架，局限性很大。 模块内容过于复杂，如果员工离职，可能需要很长时间才能完成工作交接。 分布式、集群 集群：一台服务器无法负荷高并发的数据访问量，那么就设置十台服务器一起分担压力，十台不行就设置一百台（物理层面）。很多人干同一件事情，来分摊压力。 分布式：将一个复杂问题拆分成若干个简单的小问题，将一个大型的项目架构拆分成若干个微服务来协同完成。（软件设计层面）。将一个庞大的工作拆分成若干个小步骤，分别由不同的人完成这些小步骤，最终将所有的结果进行整合实现大的需求。 服务治理的核心又三部分组成：服务提供者、服务消费者、注册中心。 在分布式系统架构中，每个微服务在启动时，将自己的信息存储在注册中心，叫做服务注册。 服务消费者从注册中心获取服务提供者的网络信息，通过该信息调用服务，叫做服务发现。 Spring Cloud 的服务治理使用 Eureka 来实现，Eureka 是 Netflix 开源的基于 REST 的服务治理解决方案，Spring Cloud 集成了 Eureka，提供服务注册和服务发现的功能，可以和基于 Spring Boot 搭建的微服务应用轻松完成整合，开箱即用，Spring Cloud Eureka。 Spring Cloud Eureka Eureka Server，注册中心 Eureka Client，所有要进行注册的微服务通过 Eureka Client 连接到 Eureka Server，完成注册。 Eureka Server代码实现 创建父工程，pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.7.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 解决 JDK 9 以上没有 JAXB API 的问题 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-impl&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-core&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.activation&lt;/groupId&gt; &lt;artifactId&gt;activation&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.SR2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 在父工程下创建 Module，pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml，添加 Eureka Server 相关配置。 12345678server: port: 8761eureka: client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://localhost:8761/eureka/ 属性说明 server.port：当前 Eureka Server 服务端口。 eureka.client.register-with-eureka：是否将当前的 Eureka Server 服务作为客户端进行注册。 eureka.client.fetch-fegistry：是否获取其他 Eureka Server 服务的数据。 eureka.client.service-url.defaultZone：注册中心的访问地址。 创建启动类 12345678910111213package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class,args); }} 注解说明： @SpringBootApplication：声明该类是 Spring Boot 服务的入口。 @EnableEurekaServer：声明该类是一个 Eureka Server 微服务，提供服务注册和服务发现功能，即注册中心。 Eureka Client 代码实现 创建 Module ，pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml，添加 Eureka Client 相关配置 1234567891011server: port: 8010spring: application: name: providereureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true 属性说明： spring.application.name：当前服务注册在 Eureka Server 上的名称。 eureka.client.service-url.defaultZone：注册中心的访问地址。 eureka.instance.prefer-ip-address：是否将当前服务的 IP 注册到 Eureka Server。 创建启动类 1234567891011package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class,args); }} 实体类 1234567891011121314package com.southwind.entity;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class Student { private long id; private String name; private int age;} Repository 123456789101112package com.southwind.repository;import com.southwind.entity.Student;import java.util.Collection;public interface StudentRepository { public Collection&lt;Student&gt; findAll(); public Student findById(long id); public void saveOrUpdate(Student student); public void deleteById(long id);} RepositoryImpl 123456789101112131415161718192021222324252627282930313233343536373839404142package com.southwind.repository.impl;import com.southwind.entity.Student;import com.southwind.repository.StudentRepository;import org.springframework.stereotype.Repository;import java.util.Collection;import java.util.HashMap;import java.util.Map;@Repositorypublic class StudentRepositoryImpl implements StudentRepository { private static Map&lt;Long,Student&gt; studentMap; static { studentMap = new HashMap&lt;&gt;(); studentMap.put(1L,new Student(1L,\"张三\",22)); studentMap.put(2L,new Student(2L,\"李四\",23)); studentMap.put(3L,new Student(3L,\"王五\",24)); } @Override public Collection&lt;Student&gt; findAll() { return studentMap.values(); } @Override public Student findById(long id) { return studentMap.get(id); } @Override public void saveOrUpdate(Student student) { studentMap.put(student.getId(),student); } @Override public void deleteById(long id) { studentMap.remove(id); }} Handler 12345678910111213141516171819202122232425262728293031323334353637383940package com.southwind.controller;import com.southwind.entity.Student;import com.southwind.repository.StudentRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import java.util.Collection;@RestController@RequestMapping(\"/student\")public class StudentHandler { @Autowired private StudentRepository studentRepository; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll(){ return studentRepository.findAll(); } @GetMapping(\"/findById/{id}\") public Student findById(@PathVariable(\"id\") long id){ return studentRepository.findById(id); } @PostMapping(\"/save\") public void save(@RequestBody Student student){ studentRepository.saveOrUpdate(student); } @PutMapping(\"/update\") public void update(@RequestBody Student student){ studentRepository.saveOrUpdate(student); } @DeleteMapping(\"/deleteById/{id}\") public void deleteById(@PathVariable(\"id\") long id){ studentRepository.deleteById(id); }} RestTemplate 的使用 什么是 RestTemplate？ RestTemplate 是 Spring 框架提供的基于 REST 的服务组件，底层是对 HTTP 请求及响应进行了封装，提供了很多访问 RETS 服务的方法，可以简化代码开发。 如何使用 RestTemplate？ 1、创建 Maven 工程，pom.xml。 2、创建实体类 1234567891011121314package com.southwind.entity;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class Student { private long id; private String name; private int age;} 3、Handler 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.southwind.controller;import com.southwind.entity.Student;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import org.springframework.web.client.RestTemplate;import java.util.Collection;@RestController@RequestMapping(\"/rest\")public class RestHandler { @Autowired private RestTemplate restTemplate; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll(){ return restTemplate.getForEntity(\"http://localhost:8010/student/findAll\",Collection.class).getBody(); } @GetMapping(\"/findAll2\") public Collection&lt;Student&gt; findAll2(){ return restTemplate.getForObject(\"http://localhost:8010/student/findAll\",Collection.class); } @GetMapping(\"/findById/{id}\") public Student findById(@PathVariable(\"id\") long id){ return restTemplate.getForEntity(\"http://localhost:8010/student/findById/{id}\",Student.class,id).getBody(); } @GetMapping(\"/findById2/{id}\") public Student findById2(@PathVariable(\"id\") long id){ return restTemplate.getForObject(\"http://localhost:8010/student/findById/{id}\",Student.class,id); } @PostMapping(\"/save\") public void save(@RequestBody Student student){ restTemplate.postForEntity(\"http://localhost:8010/student/save\",student,null).getBody(); } @PostMapping(\"/save2\") public void save2(@RequestBody Student student){ restTemplate.postForObject(\"http://localhost:8010/student/save\",student,null); } @PutMapping(\"/update\") public void update(@RequestBody Student student){ restTemplate.put(\"http://localhost:8010/student/update\",student); } @DeleteMapping(\"/deleteById/{id}\") public void deleteById(@PathVariable(\"id\") long id){ restTemplate.delete(\"http://localhost:8010/student/deleteById/{id}\",id); }} 4、启动类 123456789101112131415161718package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class RestTemplateApplication { public static void main(String[] args) { SpringApplication.run(RestTemplateApplication.class,args); } @Bean public RestTemplate restTemplate(){ return new RestTemplate(); }} 服务消费者 consumer 创建 Maven 工程，pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 1234567891011server: port: 8020spring: application: name: consumereureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true 创建启动类 123456789101112131415161718package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class,args); } @Bean public RestTemplate restTemplate(){ return new RestTemplate(); }} Handler 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.southwind.controller;import com.southwind.entity.Student;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import org.springframework.web.client.RestTemplate;import java.util.Collection;@RestController@RequestMapping(\"/consumer\")public class ConsumerHandler { @Autowired private RestTemplate restTemplate; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll(){ return restTemplate.getForEntity(\"http://localhost:8010/student/findAll\",Collection.class).getBody(); } @GetMapping(\"/findAll2\") public Collection&lt;Student&gt; findAll2(){ return restTemplate.getForObject(\"http://localhost:8010/student/findAll\",Collection.class); } @GetMapping(\"/findById/{id}\") public Student findById(@PathVariable(\"id\") long id){ return restTemplate.getForEntity(\"http://localhost:8010/student/findById/{id}\",Student.class,id).getBody(); } @GetMapping(\"/findById2/{id}\") public Student findById2(@PathVariable(\"id\") long id){ return restTemplate.getForObject(\"http://localhost:8010/student/findById/{id}\",Student.class,id); } @PostMapping(\"/save\") public void save(@RequestBody Student student){ restTemplate.postForEntity(\"http://localhost:8010/student/save\",student,null).getBody(); } @PostMapping(\"/save2\") public void save2(@RequestBody Student student){ restTemplate.postForObject(\"http://localhost:8010/student/save\",student,null); } @PutMapping(\"/update\") public void update(@RequestBody Student student){ restTemplate.put(\"http://localhost:8010/student/update\",student); } @DeleteMapping(\"/deleteById/{id}\") public void deleteById(@PathVariable(\"id\") long id){ restTemplate.delete(\"http://localhost:8010/student/deleteById/{id}\",id); }} 服务网关Spring Cloud 集成了 Zuul 组件，实现服务网关。 什么是 Zuul？ Zuul 是 Netflix 提供的一个开源的 API 网关服务器，是客户端和网站后端所有请求的中间层，对外开放一个 API，将所有请求导入统一的入口，屏蔽了服务端的具体实现逻辑，Zuul 可以实现反向代理的功能，在网关内部实现动态路由、身份认证、IP 过滤、数据监控等。 创建 Maven 工程，pom.xml 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 123456789101112server: port: 8030spring: application: name: gatewayeureka: client: service-url: defaultZone: http://localhost:8761/eureka/zuul: routes: provider: /p/** 属性说明： zuul.routes.provider：给服务提供者 provider 设置映射 创建启动类 12345678910111213package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.cloud.netflix.zuul.EnableZuulProxy;@EnableZuulProxy@EnableAutoConfigurationpublic class ZuulApplication { public static void main(String[] args) { SpringApplication.run(ZuulApplication.class,args); }} 注解说明： @EnableZuulProxy：包含了 @EnableZuulServer，设置该类是网关的启动类。 @EnableAutoConfiguration：可以帮助 Spring Boot 应用将所有符合条件的 @Configuration 配置加载到当前 Spring Boot 创建并使用的 IoC 容器中。 Zuul 自带了负载均衡功能，修改 provider 的代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.southwind.controller;import com.southwind.entity.Student;import com.southwind.repository.StudentRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.*;import java.util.Collection;@RestController@RequestMapping(\"/student\")public class StudentHandler { @Autowired private StudentRepository studentRepository; @Value(\"${server.port}\") private String port; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll(){ return studentRepository.findAll(); } @GetMapping(\"/findById/{id}\") public Student findById(@PathVariable(\"id\") long id){ return studentRepository.findById(id); } @PostMapping(\"/save\") public void save(@RequestBody Student student){ studentRepository.saveOrUpdate(student); } @PutMapping(\"/update\") public void update(@RequestBody Student student){ studentRepository.saveOrUpdate(student); } @DeleteMapping(\"/deleteById/{id}\") public void deleteById(@PathVariable(\"id\") long id){ studentRepository.deleteById(id); } @GetMapping(\"/index\") public String index(){ return \"当前端口：\"+this.port; }} Ribbon 负载均衡 什么是 Ribbon？ Spring Cloud Ribbon 是一个负载均衡解决方案，Ribbon 是 Netflix 发布的负载均衡器，Spring Cloud Ribbon 是基于 Netflix Ribbon 实现的，是一个用于对 HTTP 请求进行控制的负载均衡客户端。 在注册中心对 Ribbon 进行注册之后，Ribbon 就可以基于某种负载均衡算法，如轮询、随机、加权轮询、加权随机等自动帮助服务消费者调用接口，开发者也可以根据具体需求自定义 Ribbon 负载均衡算法。实际开发中，Spring Cloud Ribbon 需要结合 Spring Cloud Eureka 来使用，Eureka Server 提供所有可以调用的服务提供者列表，Ribbon 基于特定的负载均衡算法从这些服务提供者中选择要调用的具体实例。 创建 Module，pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 1234567891011server: port: 8040spring: application: name: ribboneureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true 创建启动类 1234567891011121314151617181920package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class RibbonApplication { public static void main(String[] args) { SpringApplication.run(RibbonApplication.class,args); } @Bean @LoadBalanced public RestTemplate restTemplate(){ return new RestTemplate(); }} @LoadBalanced：声明一个基于 Ribbon 的负载均衡。 Handler 123456789101112131415161718192021222324252627package com.southwind.controller;import com.southwind.entity.Student;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;import java.util.Collection;@RestController@RequestMapping(\"/ribbon\")public class RibbonHandler { @Autowired private RestTemplate restTemplate; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll(){ return restTemplate.getForObject(\"http://provider/student/findAll\",Collection.class); } @GetMapping(\"/index\") public String index(){ return restTemplate.getForObject(\"http://provider/student/index\",String.class); }} Feign 什么是 Feign？ 与 Ribbon 一样，Feign 也是由 Netflix 提供的，Feign 是一个声明式、模版化的 Web Service 客户端，它简化了开发者编写 Web 服务客户端的操作，开发者可以通过简单的接口和注解来调用 HTTP API，Spring Cloud Feign，它整合了 Ribbon 和 Hystrix，具有可插拔、基于注解、负载均衡、服务熔断等一系列便捷功能。 相比较于 Ribbon + RestTemplate 的方式，Feign 大大简化了代码的开发，Feign 支持多种注解，包括 Feign 注解、JAX-RS 注解、Spring MVC 注解等，Spring Cloud 对 Feing 进行了优化，整合了 Ribbon 和 Eureka，从而让 Feign 的使用更加方便。 Ribbon 和 Feign 的区别 Ribbon 是一个通用的 HTTP 客户端工具，Feign 是基于 Ribbon 实现的。 Feign 的tedian 1、Feign 是一个声明式的 Web Service 客户端。 2、支持 Feign 注解、Spring MVC 注解、JAX-RS 注解。 3、Feign 基于 Ribbon 实现，使用起来更加简单。 4、Feign 集成了 Hystrix，具备服务熔断的功能。 创建 Module，pom.xml 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 1234567891011server: port: 8050spring: application: name: feigneureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true 创建启动类 12345678910111213package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableFeignClientspublic class FeignApplication { public static void main(String[] args) { SpringApplication.run(FeignApplication.class,args); }} 创建声明式接口 12345678910111213141516package com.southwind.feign;import com.southwind.entity.Student;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.Collection;@FeignClient(value = \"provider\")public interface FeignProviderClient { @GetMapping(\"/student/findAll\") public Collection&lt;Student&gt; findAll(); @GetMapping(\"/student/index\") public String index();} Handler 12345678910111213141516171819202122232425262728package com.southwind.controller;import com.southwind.entity.Student;import com.southwind.feign.FeignProviderClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.Collection;@RestController@RequestMapping(\"/feign\")public class FeignHandler { @Autowired private FeignProviderClient feignProviderClient; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll(){ return feignProviderClient.findAll(); } @GetMapping(\"/index\") public String index(){ return feignProviderClient.index(); }} 服务熔断，application.yml 添加熔断机制。 1234567891011121314server: port: 8050spring: application: name: feigneureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: truefeign: hystrix: enabled: true feign.hystrix.enabled：是否开启熔断器。 创建 FeignProviderClient 接口的实现类 FeignError，定义容错处理逻辑，通过 @Component 注解将 FeignError 实例注入 IoC 容器中。 1234567891011121314151617181920package com.southwind.feign.impl;import com.southwind.entity.Student;import com.southwind.feign.FeignProviderClient;import org.springframework.stereotype.Component;import java.util.Collection;@Componentpublic class FeignError implements FeignProviderClient { @Override public Collection&lt;Student&gt; findAll() { return null; } @Override public String index() { return \"服务器维护中......\"; }} 在 FeignProviderClient 定义处通过 @FeignClient 的 fallback 属性设置映射。 1234567891011121314151617package com.southwind.feign;import com.southwind.entity.Student;import com.southwind.feign.impl.FeignError;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.Collection;@FeignClient(value = \"provider\",fallback = FeignError.class)public interface FeignProviderClient { @GetMapping(\"/student/findAll\") public Collection&lt;Student&gt; findAll(); @GetMapping(\"/student/index\") public String index();} Hystrix 容错机制在不改变各个微服务调用关系的前提下，针对错误情况进行预先处理。 设计原则 1、服务隔离机制 2、服务降级机制 3、熔断机制 4、提供实时的监控和报警功能 5、提供实时的配置修改功能 Hystrix 数据监控需要结合 Spring Boot Actuator 来使用，Actuator 提供了对服务的健康健康、数据统计，可以通过 hystrix.stream 节点获取监控的请求数据，提供了可视化的监控界面。 创建 Maven，pom.xml 12345678910111213141516171819202122232425262728293031&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;version&gt;2.0.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 12345678910111213141516171819server: port: 8060spring: application: name: hystrixeureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: truefeign: hystrix: enabled: truemanagement: endpoints: web: exposure: include: 'hystrix.stream' 创建启动类 1234567891011121314151617package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;import org.springframework.cloud.netflix.hystrix.dashboard.EnableHystrixDashboard;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableFeignClients@EnableCircuitBreaker@EnableHystrixDashboardpublic class HystrixApplication { public static void main(String[] args) { SpringApplication.run(HystrixApplication.class,args); }} 注解说明： @EnableCircuitBreaker：声明启用数据监控 @EnableHystrixDashboard：声明启用可视化数据监控 Handler 123456789101112131415161718192021222324252627package com.southwind.controller;import com.southwind.entity.Student;import com.southwind.feign.FeignProviderClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.Collection;@RestController@RequestMapping(\"/hystrix\")public class HystrixHandler { @Autowired private FeignProviderClient feignProviderClient; @GetMapping(\"/findAll\") public Collection&lt;Student&gt; findAll(){ return feignProviderClient.findAll(); } @GetMapping(\"/index\") public String index(){ return feignProviderClient.index(); }} 启动成功之后，访问 http://localhost:8060/actuator/hystrix.stream 可以监控到请求数据， 访问 http://localhost:8060/hystrix，可以看到可视化的监控界面，输入要监控的地址节点即可看到该节点的可视化数据监控。 Spring Cloud 配置中心Spring Cloud Config，通过服务端可以为多个客户端提供配置服务。Spring Cloud Config 可以将配置文件存储在本地，也可以将配置文件存储在远程 Git 仓库，创建 Config Server，通过它管理所有的配置文件。 本地文件系统 创建 Maven 工程，pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 application.yml 123456789101112server: port: 8762spring: application: name: nativeconfigserver profiles: active: native cloud: config: server: native: search-locations: classpath:/shared 注解说明 profiles.active：配置文件的获取方式 cloud.config.server.native.search-locations：本地配置文件存放的路径 resources 路径下创建 shared 文件夹，并在此路径下创建 configclient-dev.yml。 123server: port: 8070foo: foo version 1 创建启动类 12345678910111213package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;@SpringBootApplication@EnableConfigServerpublic class NativeConfigServerApplication { public static void main(String[] args) { SpringApplication.run(NativeConfigServerApplication.class,args); }} 注解说明 @EnableConfigServer：声明配置中心。 创建客户端读取本地配置中心的配置文件 创建 Maven 工程，pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 bootstrap.yml，配置读取本地配置中心的相关信息。 123456789spring: application: name: configclient profiles: active: dev cloud: config: uri: http://localhost:8762 fail-fast: true 注解说明 cloud.config.uri：本地 Config Server 的访问路径 cloud.config.fail-fase：设置客户端优先判断 Config Server 获取是否正常。 通过spring.application.name 结合spring.profiles.active拼接目标配置文件名，configclient-dev.yml，去 Config Server 中查找该文件。 创建启动类 1234567891011package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class NativeConfigClientApplication { public static void main(String[] args) { SpringApplication.run(NativeConfigClientApplication.class,args); }} Handler 12345678910111213141516171819202122package com.southwind.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(\"/native\")public class NativeConfigHandler { @Value(\"${server.port}\") private String port; @Value(\"${foo}\") private String foo; @GetMapping(\"/index\") public String index(){ return this.port+\"-\"+this.foo; }} Spring Cloud Config 远程配置 创建配置文件，上传至 GitHub 123456789server: port: 8070eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/spring: application: name: configclient 创建 Config Server，新建 Maven 工程，pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 123456789101112131415161718server: port: 8888spring: application: name: configserver cloud: config: server: git: uri: https://github.com/southwind9801/aispringcloud.git searchPaths: config username: root password: root label: mastereureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 创建启动类 12345678910111213package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;@SpringBootApplication@EnableConfigServerpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class,args); }} 创建 Config Client 创建 Maven 工程，pom.xml 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建 bootstrap.yml 123456789101112spring: cloud: config: name: configclient label: master discovery: enabled: true service-id: configservereureka: client: service-url: defaultZone: http://localhost:8761/eureka/ 注解说明 spring.cloud.config.name：当前服务注册在 Eureka Server 上的名称，与远程仓库的配置文件名对应。 spring.cloud.config.label：Git Repository 的分支。 spring.cloud.config.discovery.enabled：是否开启 Config 服务发现支持。 spring.cloud.config.discovery.service-id：配置中心在 Eureka Server 上注册的名称。 创建启动类 1234567891011package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class,args); }} Handler 12345678910111213141516171819package com.southwind.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(\"/hello\")public class HelloHandler { @Value(\"${server.port}\") private String port; @GetMapping(\"/index\") public String index(){ return this.port; }} 服务跟踪Spring Cloud Zipkin Zipkin 是一个可以采集并且跟踪分布式系统中请求数据的组件，让开发者可以更加直观的监控到请求在各个微服务所耗费的时间等，Zipkin：Zipkin Server、Zipkin Client。 ####创建 Zipkin Server 创建 Maven 工程，pom.xml 12345678910111213141516&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt; &lt;version&gt;2.9.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt; &lt;version&gt;2.9.4&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 12server: port: 9090 创建启动类 12345678910111213package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import zipkin.server.internal.EnableZipkinServer;@SpringBootApplication@EnableZipkinServerpublic class ZipkinApplication { public static void main(String[] args) { SpringApplication.run(ZipkinApplication.class,args); }} 注解说明 @EnableZipkinServer：声明启动 Zipkin Server 创建 Zipkin Client 创建 Maven 工程，pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建配置文件 application.yml 1234567891011121314151617server: port: 8090spring: application: name: zipkinclient sleuth: web: client: enabled: true sampler: probability: 1.0 zipkin: base-url: http://localhost:9090/eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ 属性说明 spring.sleuth.web.client.enabled：设置开启请求跟踪 spring.sleuth.sampler.probability：设置采样比例，默认是 1.0 srping.zipkin.base-url：Zipkin Server 地址 创建启动类 1234567891011package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class ZipkinClientApplication { public static void main(String[] args) { SpringApplication.run(ZipkinClientApplication.class,args); }} Handler 12345678910111213141516171819package com.southwind.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(\"/zipkin\")public class ZipkinHandler { @Value(\"${server.port}\") private String port; @GetMapping(\"/index\") public String index(){ return this.port; }}","link":"/2019/10/27/SpringCloud%E7%AC%94%E8%AE%B0-%E4%B8%80/"},{"title":"[Kubernetes] Kubeadm Troubleshooting","text":"Troubleshooting for kubeadm. T1 前置准备问题Run kubeadm config images pull 12345678I1216 10:31:32.821965 25588 version.go:251] remote version is much newer: v1.17.0; falling back to: stable-1.16[init] Using Kubernetes version: v1.16.4[preflight] Running pre-flight checks [WARNING SystemVerification]: this Docker version is not on the list of validated versions: 19.03.5. Latest validated version: 18.09error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR Swap]: running with swap on is not supported. Please disable swap[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`To see the stack trace of this error execute with --v=5 or higher 依照顺序： kubeadm config print init-defaults &gt; init.default.yaml得到默认的初始配置，对生成的文件进行编辑，可以按需生成合适的配置。如： 将advertiseAddress: 1.2.3.4修改为本机地址 如果使用国内的docker镜像源，需要将imageRepository: k8s.gcr.io修改为对应的镜像源地址 定制镜像仓库地址：imageRepository: docker.io/dustise kubernetes版本：kubernetesVersion: v1.17.0 Pod地址范围： 12networking: podSubnet: \"192.168.0.0/16\" 修改docker版本 Disable swap sudo swapoff -a #关闭交换分区 sudo free -m # 查看交换分区状态 sudo chmod +w /etc/fstab # 修改fstab文件的权限 vi /etc/fstab # 将swap行注释掉，注意先备份，此步是为了永久关闭swap分区 T2 Dashboard无法访问碰到页面显示 1234567891011121314{\"kind\": \"Status\",\"apiVersion\": \"v1\",\"metadata\": {},\"status\": \"Failure\",\"message\": \"pods is forbidden: User \"system:anonymous\" cannot list pods in the namespace \"default\"\",\"reason\": \"Forbidden\",\"details\": {\"kind\": \"pods\"},\"code\": 403} 那么参考这个issue，在之前用来生成dashboard的recommend.yaml中加入 123456789101112131415161718192021222324252627---# ------------------- Gross Hack For anonymous auth through api proxy ------------------- ## Allows users to reach login page and other proxied dashboard URLskind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: kubernetes-dashboard-anonymousrules:- apiGroups: [\"\"] resources: [\"services/proxy\"] resourceNames: [\"https:kubernetes-dashboard:\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]- nonResourceURLs: [\"/ui\", \"/ui/*\", \"/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/*\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard-anonymousroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: kubernetes-dashboard-anonymoussubjects:- kind: User name: system:anonymous 通过命令重新启动dashboard：kubectl replace --force -f recommended.yaml T3 配置网络问题1.使用calico未发现正常网卡错误信息： 1:Readiness probe failed: caliconode is not ready: BIRD is not ready: BGP not established with 10.117.150.23 解决方法： 编辑calicol.yaml，添加 12- name: IP_AUTODETECTION_METHOD value: \"interface=enp09s\" # 实际接通其他集群的网卡 2.使用其他网络配置的残留由于此前操作有错误，需移除之前的网络配置，重新安装。 但是此前的网络配置未移除干净，会造成一些问题： ip link，例如此前使用过weave对应的网卡weave、calico对应的网卡tunl0，需要使用ip link delete {name}来进行移除。 更为有效的方法(针对weave)： 12sudo curl -L git.io/weave -o /usr/local/bin/weavesudo chmod a+x /usr/local/bin/weave then 1weave reset CNI的配置文件在使用kubeadm reset后并不会被删除:rm -rf /etc/cni/net.d T4 顽固的swap (UPDATE 2020/03/31)不知道出于什么原因，每次实验室服务器重启之后，交换分区都会被重新启用（/etc/fstab甚至都是disable的状态） 暂时的解决方法是，每次服务器不得不需要重启时，先停止所有容器（不太可能），重启后swapoff -a +systemctl restart kubelet，两套连招，暂且将就用用。","link":"/2019/12/23/TbSt4kubeadm/"},{"title":"[Debug] VMware中Ubuntu重启Freeze","text":"The issue is with Wayland. While Ubuntu defaults to an X11 session, for some reason they left it enabled for GDM. You can certainly replace GDM with LightDM, but an easier option would be to: 1sudo nano /etc/gdm3/custom.conf Then change the line: 1#WaylandEnable=false to 1WaylandEnable=false Press Ctrl+O and then Ctrl+X and reboot. [edit] If you don’t wish to reboot you can do sudo systemctl restart gdm which will restart your windows session (this assume ssh into the box to fix as above). Or you cannot use ssh to your ubuntu, just hold shift on start up, and select recovery mode, root shell, follow instructions above, and reboot.","link":"/2019/07/12/VMware%E4%B8%ADUbuntu%E9%87%8D%E5%90%AFFreeze/"},{"title":"[Debug] VMware重启后虚拟机无法联网问题解决","text":"Edit the file /etc/network/interfaces 123# The primary network interfaceauto ens33iface ens33 inet dhcp","link":"/2019/07/05/VMware%E9%87%8D%E5%90%AF%E5%90%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%97%A0%E6%B3%95%E8%81%94%E7%BD%91%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"title":"[NOTE] Vmvare静态地址相关问题","text":"VMware配置集群的过程中，集群机器重启之后往往会重新分配ip，解决如下。 CentOSyum install net-tools NAT模式 子网地址 子网掩码 网关地址 进入虚拟机vi /etc/sysconfig/network-scripts/ifcfg-eth0也可能是ens33 配置信息如下： 123456789101112DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;static&quot;HWADDR=&quot;00:0C:29:F4:7E:C9&quot;IPV6INIT=&quot;yes&quot;NM_CONTROLLED=&quot;yes&quot;ONBOOT=&quot;yes&quot;TYPE=&quot;Ethernet&quot;UUID=&quot;2a76c2f8-cd47-44af-936d-11559b3a498d&quot;IPADDR=&quot;192.168.73.100&quot;NETMASK=&quot;255.255.255.0&quot;GATEWAY=&quot;192.168.73.2&quot; 若无法连接外网，加入网关地址xxx.xxx.xxx.2，共享物理机网络，或用114.114.114.114 systemctl restart network.service Ubuntustep by step sudo vi /etc/network/interfaces edit the configurations 123456auto ens33iface ens33 inet staticaddress 192.168.81.137netmask 255.255.255.0gateway 192.168.81.2dns-nameservers 10.0.208.1 sudo ip addr flush ens33 sudo systemctl restart networking.service 或 sudo /etc/init.d/networking restart 坑: 网关为.2，有的博客写的是.1，实测不行 dns 114.114.114.114或42.120.21.30 不要开本地dhcp自动分发地址 配置自己网段DNS sudo vi /etc/resolv.conf 迷幻！ 暂时没啥好方法搞定这个，新建个resolv.conf在一个安全的目录，填上： 123nameserver 114.114.114.114nameserver 8.8.8.8nameserver 8.8.4.4 碰到问题了就直接cat ./resolv.conf &gt; /etc/resolv.conf 然后systemctl restart networking.service 就是这么暴力 解决方法 Ubuntu 18 LTS server /etc/netplan/50-cloud-init.yaml 123456789network: ethernets: ens33: addresses: [192.168.1.197/24] gateway4: 192.168.1.1 nameservers: addresses: [192.168.1.1] dhcp4: no optional: true netplan apply","link":"/2019/07/03/Vmvare%E9%9D%99%E6%80%81%E5%9C%B0%E5%9D%80%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/"},{"title":"[NOTE] ZSH安装","text":"习惯了Hyper+WSL+zsh的组合，在centos中也得安排上，备查。 Step 1: Install &amp; Configure ZSHCentOS 7： yum install zsh Ubuntu: apt install zsh Step 2: ZSH SettingsCentOS 7: chsh -s /bin/zsh root Ubuntu: which zsh Log in again and check the current shell by: echo $SHELL Step 3: Install &amp; Configutre Oh my zshCentOS 7: yum install wget git Ubuntu: apt install wget git Download the installer script and run it by: wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | zsh And this will meets a problem if the system is the simplified. It will be refused by githubusercontent.com for the lack of ca-certificates. And there are two ways to deal with it: wget --no-check-certificate https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | zsh or do it once: yum install ca-certificates -y or yum install ssl-cert After we have installed Oh my zsh in ~/.on-my-zsh, we just need to copy it in .zshrc and apply the configuration. cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc source ~/.zshrc Try this: sh -c &quot;$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot; Oh my zsh Theme Settings默认的就很好用了，有问题google","link":"/2019/07/05/ZSH%E5%AE%89%E8%A3%85/"},{"title":"[NOTE] Frp原理深入实践、Nginx容器实践","text":"近期将阿里云上的博客服务迁移到了本地机房服务器，同时oj平台的搭建也开始启动，目前多个服务通过不同端口访问的方式显得太过粗糙，本文将通过frp、Nginx、docker等工具以实现阿里云主机对多个本地服务的反向代理，对每个服务都分出对应的二级域名。 在frp的使用上，本文相较之前的文章更加深入，对frp的多个功能作出更多的探索。另外，也将初步地学习实践Nginx引擎。 一、相关说明本文涉及到的环境： Ubuntu Server 18LTS (local) CentOS 7.3 (Aliyun) frp 0.28.0 go 1.10.4 二、frp原理内网穿透的原理在前文中已有说明，但基于需求的变化，我们需要使用frp更多的特性，了解相关的原理有助于减少在实现过程中的错误。 第一步：配置无误的情况下，frp服务端和frp客户端先后启动，建立通信隧道，其中： frp服务端监听http 7071端口（此端口可自定义），接收此端口下所有外网用户请求，注意此处的7071端口要和通信隧道所用的端口7000作出区别 frp客户端代理本地想要暴露给外网的web服务端口，本文以80, 8080端口为例 第二步：通过配置nginx反向代理，将指向本台公网服务器的nuzar.top下的子域名，映射到服务器的7071端口，也就是frp监听的那个端口。 外网用户访问gitlab.nuzar.top、wordpress.nuzar.top下的子域名，例如 ： gitlab.nuzar.top wordpress.nuzar.top 等同于访问nuzar.top：7071，会触发frp服务端和客户端的互动，从而http请求由frp服务端传递到frp客户端 第三步：frp客户端收到http请求后，基于自定义配置，则做如下处理： 监听到http请求中的域名为 gitlab.nuzar.top，则将请求转发到我本地的8585web服务端口 监听到http请求中的域名为 wordpress.nuzar.top，则将请求转发到我本地的8686web服务端口 第四步：本地的web服务收到http请求后，对请求做处理，并完成响应 第五步：frp客户端将响应结果回传给frp的服务端。服务端最终将响应回传给外网用户 第六步：最终的实测效果为： 访问 gitlab.nuzar.top，等同于访问我本地的192.168.1.253:80 访问 wordpress.nuzar.top，等同于访问我本地的192.168.1.253:8080 三、Configuration话不多说，直接上配置信息，相关的属性会分别进行说明。 1.frps.ini 1234[common]bind_port = 7000vhost_http_port = 7071subdomain_host = nuzar.top bind_port为frp服务端与客户端之间通讯的端口，为事实上数据传输的端口； vhost_http_port为http服务的代理端口，代理所有发往7071端口的http请求，之后通过bind_port将包装后的请求发送给bing_port相连接的服务器； subdomain_host指定父域名，便于划分子网(但事实上最后还是通过nginx来划分的子网，一直到都弄完之后，才发现前面多打了个d，前面frp方案走不通，恐怕是这个的锅)。 为了便于调试，你也开启frp的dashboard界面，参照官网Dashboard，在frps.ini中加入: 12345[common]dashboard_port = 7500# dashboard's username and password are both optional，if not set, default is admin.dashboard_user = admindashboard_pwd = admin 如果你之前有通过systemctl将frps加入到系统服务中的话，那么此时通过systemctl restart frps就可以让新配置生效了。 dashboard的效果图如下： 通过dashboard面板，可以很容易的观察到自己的配置是否生效。 ​ 2.frpc.ini123456789101112131415161718192021222324252627282930313233[common]server_addr = REMOTE_IPADDRserver_port = 7000[http-OJ]type = tcplocal_ip = 192.168.1.252local_port = 8080remote_port = 28080[ssh]type = tcplocal_ip = 192.168.1.253local_port = 26remote_port = 6000[ssh-gitlab]type = tcplocal_ip = 192.168.1.253local_port = 26remote_port = 8082[http-gitlab]type = tcplocal_ip = 192.168.1.253local_port = 80remote_port = 6080[http-nextcloud]type = tcplocal_ip = 192.168.1.253local_port = 40080remote_port = 40080 frpc.ini配置文件，见名知义。需要注意的两点：1.配置文件中不要出现相同的名称，中括号中的名称只作代称，并不具有实际的意义；2.肯定有人会奇怪为什么明明是使用的http协议，但类型却标注的type = tcp，原因是官方并没有提供多web服务的穿透，在一些issue中有人发现使用tcp可以绕过单个web穿透的限制，最终达到理想的效果，具体的讨论可以前往#914 (comment). 3.nginx本文中nginx采用docker的方式进行部署，由于nginx在启动时会加载相关的配置文件，因此在部署前需要在相应路径(之后挂载到容器中)编写一些配置文件。 /root/nginx/nginx.conf 1234567891011121314151617181920user nginx;worker_processes auto;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events { worker_connections 2048;}http { include /etc/nginx/mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; client_max_body_size 10M; include /etc/nginx/conf.d/*.conf;} nginx.conf常规配置没什么好说的。 /root/nginx/conf.d/default.conf 12345678910111213141516171819202122server { listen 80; listen [::]:80; server_name nuzar.top; location / { proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_pass http://nuzar.top:8080; }}server { listen 80; listen [::]:80; server_name gitlab.nuzar.top; location / { proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_pass http://127.0.0.1:6080; }} nginx监听80端口，将对应的服务请求转发到对应的端口，由于目前我个人对于nginx也是个拿来即用的状态，了解不多。 四、添加域名解析如果你也是使用的阿里云的云服务，可以直接登录域名解析管理页面。 以本文中的gitlab.nuzar.top为例： 添加记录：A 主机记录：gitlab 解析路线：默认 记录值：SERVER_IP_ADDR 如果使用的其他厂商的主机，也有相应的操作可以实现。 五、部署nginx容器nginx部署的方式还是采用docker run，在部署时需要将宿主机的一些路径挂载到容器中的对应路径，因此，可以参考下我的文件树： 1234567|-- conf.crt|-- conf.d| `-- default.conf|-- html| `-- index.html|-- nginx`-- nginx.conf conf.crt用于存放证书，这个暂时不会用到； nginx.conf为nginx配置文件； default.conf为配置文件的补充文件，对于nginx主要的配置工作也是集中在这个文件之中； index.html顾名思义，一个普通的页面，之后用certbot来申请证书的时候需要用到这个页面。 12345678docker run -d -p 80:80 -p 443:443 \\-v $(pwd)/nginx/conf.d:/etc/nginx/conf.d:ro \\-v $(pwd)/nginx/conf.crt:/etc/nginx/conf.crt:ro \\-v $(pwd)/nginx/nginx.conf:/etc/nginx/nginx.conf:ro \\-v $(pwd)/logs/nginx:/var/log/nginx \\-v $(pwd)/nginx/html:/usr/share/nginx/html \\--restart=always --name=gateway --network=host \\nginx 需要注意的一点是，标注--network=host后，nginx容器才有能力代理主机的请求，否则nginx只在容器内部有效，host表示容器网络为主机模式； ro表示挂载的文件为只读状态，另外在docker社区中，文件级别的挂载好像是不太推荐的，但连官网上对nginx的示例也是如此，所以就先这样用了。 五、总结对于二级域名的配置，总的来说还是比较简单的，总的来说存在两套方案：一者是直接通过frp提供的subdomain进行配置，但前文也提到，由于后来才发现的一些错误，导致我过早地认为这套方案不适用；二是在frp实现内穿的基础之上，通过一个nginx引擎来完成一个类似反向代理的工作，这层nginx在现在看来有些多余，但出于熟悉nginx和之后加入https支持的目的，我将二级域名到指定端口的工作交由nginx来完成了。 另外，frp的功能远不止如此，目前项目比较活跃，加之也是由Golang编写，值得持续跟进。","link":"/2019/09/08/frp%E5%8E%9F%E7%90%86%E6%B7%B1%E5%85%A5%E5%AE%9E%E8%B7%B5%E3%80%81Nginx%E5%AE%B9%E5%99%A8%E5%AE%9E%E8%B7%B5/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2019/07/13/hello-world/"},{"title":"[Script] Hugo自动部署脚本更新","text":"之前使用的脚本基本可以完成hugo的自动编译和push，但我的笔记基本都放在了移动硬盘中，因此需要脚本对移动硬盘中的笔记进行扫描，增量地进行更新。 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/bin/bash# this is a script for hugo deployment# the occurrence of error will stop the scriptset -e# 检查/h/backup/notes/文件夹的新文件，并加入hugo中path='/h/backup/notes/'files=$(ls $path)# 对notes文件夹中的笔记进行遍历，获取文件名for filename in $filesdo echo \"------------------------------------------------------\" echo $filename # 若存在新增的文件，添加到hugo中 if [ ! -f \"./content/post/${filename}\" ] then echo \"add ${filename} to hugo\" hugo new post/${filename} # 因hugo生成的文件有必要的头，所以追加内容进去 cat ${path}${filename} &gt;&gt; ./content/post/${filename} else echo \"${filename} exists\" fidone# 删除打包文件rm -rf publichugo -t mainroad# 进入打包文件夹cd public# git operationsgit initgit add -Amsg=\"building sit 'data'\"# $#检查执行命令时所带参数个数是否为1,参数即为commitif [ $# -eq 1 ] then msg=\"$1\"figit commit -m \"$msg\"git push -f git@github.com:fusidic/fusidic.github.io.git mastercd ..","link":"/2019/07/05/hugo%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%E8%84%9A%E6%9C%AC%E6%9B%B4%E6%96%B0/"},{"title":"[Leetcode] Q5最长回文串","text":"边界问题 Q5: Longest Palindromic SubstringGiven a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000. Example 1: 123Input: &quot;babad&quot;Output: &quot;bab&quot;Note: &quot;aba&quot; is also a valid answer. Example 2: 12Input: &quot;cbbd&quot;Output: &quot;bb&quot; 最暴力的手段当然就是把所有的子串全部列出来，并逐个判断是否符合“palindrome”回文数的标准，光是想一想就觉得很麻烦。 此时有一个更符合直觉的想法：将字符串倒过来，这样就将“寻找最大回文串”转变成了“寻找公共子串”的问题，当然二者还是有一些小小的区别的，且看后文。 &nbsp;&nbsp; 解法1：倒序+最大公共子串此时不妨以babad为例，以字符串origin_str和倒序字符串reverse_str构建一个二维数组(脑力不够，纸笔来凑)： 每当出现字符相等的情况：array[i][j] = array[i-1][j-1] + 1 字符不想等的情况：array[i][j] = 0 此时数组中记录的最大数值，即为最长的公共子串的长度。 当然还有几个细节需要考虑： 存在maxLen = arr[i][j]显示出长度，同时[i][j]也可以指明“坐标”，通过偏移量直接用切片获取目标字符串； 边界情况： i==0或j==0的情况下，直接将符合字符相等情况的位置标记 1 字符出和逆序字符串可能存在“错位相等”的情况，以标记最大长度的点，判断“倒序后的坐标”和“原坐标”是否相符 &nbsp;&nbsp; 代码部分： 1234567891011121314151617181920212223242526272829303132func longestPalindrome(s string) string { reverse := leetutils.Reverse(s) maxLen := 0 index := 0 l := len(s) mtx := make([][]int, l) for i := 0; i &lt; l; i++ { // 初始化，默认值都为0 mtx[i] = make([]int, l) for j := 0; j &lt; l; j++ { // 字符相同 if s[i] == reverse[j] { // 边界处理 if i == 0 || j == 0 { mtx[i][j] = 1 } else { mtx[i][j] = mtx[i-1][j-1] + 1 } } // 更新maxLen if mtx[i][j] &gt; maxLen { // 判断末尾元素在s和reverse中是否是同一个元素 if (l - 1 - j + mtx[i][j] - 1) == i { maxLen = mtx[i][j] index = i - maxLen + 1 } } } } return s[index : index+maxLen]} 最后更新maxLen的判断，也可以使用另外一种方法：对比“目标子串”是否回文（感觉会引来更多的边界） 这种思路总的来说还是比较自然且简单的，主要的麻烦集中在几个边界问题的处理上。当然因为思路比较简单，导致不管是时间复杂度O(n^2) 还是空间复杂度O(n^2)都是比较高的。 解法2：中心扩展中心扩展其实也很好理解，回文串肯定是对称的，在一次遍历中，对字符向两边进行扩展，碰到左右相同时就继续，不同时退出。 边界问题： 回文串的长度“奇数/偶数”需要分别考虑 扩展“碰壁”时的处理 &nbsp;&nbsp; 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142func longestPalindrome(s string) string { i := 0 l := \"\" temp := \"\" for i &lt; len(s) { // 奇数 temp = getPalindrome(s, i, i) if len(l) &lt; len(temp) { l = temp } // 判断是否会越界 if i+1 &lt; len(s) { // 偶数 temp = getPalindrome(s, i, i+1) if len(l) &lt; len(temp) { l = temp } } i++ } return l}// getPalindrome 向两边延伸找到最大回文串func getPalindrome(s string, left int, right int) string { for left &gt;= 0 &amp;&amp; right &lt; len(s) { if s[left] == s[right] { left-- right++ } else { // 左右不相同，回退 left++ right-- break } } // 碰到字符串边界的处理 if left &lt; 0 || right &gt;= len(s) { return s[left+1 : right] } return s[left : right+1]} 结合上面的图片和代码中的注释，还是很好理解的，在字符串问题解题过程中经常遇到的就是“越界”，因此在写代码的时候要时刻注意判断。 中心扩展法的时间复杂度是O(n^2)，空间复杂度是O(1)，就提交的情况来看，性能会远高于第一个算法。 &nbsp;&nbsp; 解法3：Manacher’s AlgorithmManacher算法理论上可以将算法的时间复杂度降到O(n)，事实上就是在“中心扩展”算法基础上进一步优化，减少了计算“回文串”的次数。 预处理：插入#为了解决奇数偶数处理逻辑不一样的问题，这里有个巧妙的方法：在每个字符间插入#，并在开头结尾分别插入^# #$，这时你会发现字符串的长度一定是一个奇数。这样在进行中心扩展的时候，处理的永远是奇数长度的字符串了。 求P[i]对每个位置为i的点，以其为对称中心，左右对称点的个数即为P[i]（包括#，后文我们称P[i]为回文半径），如下图： 上图中的C(center)，便是计算的中心，如果将C从头到尾遍历一次，那就是“中心扩展”算法了，Manacher的核心就是跳过不必要的C，以此提高计算的效率。 以上图为例，C为对称中心，对称半径为5，那么可以判定处于T[6-5 : 6+5]即T[1 : 11]内的所有对称点(i与i_mirror)都具有相同的属性. i从C的临近出逐渐远离，P[i]的作用是预先确定回文半径，因此我们至少可以判定i所指的P[i]至少为3，当i处开始中心扩展时，就可以从3开始，节省了时间。 ​ 依然很重要的边界问题 : P[i]受到P[i_mirror]与边界R的限制，为其中的较小值，原因是当i+P[i_mirror]可能会超出边界R，超出边界时，就需要更新中心C与边界R； 在i向右侧展开时，依然要对每个点进行“中心展开”，但由于P[i_mirror]可以一定程度避免重复计算； ​ 提取目标回文串可以发现i减去P [ i ]，再除以 2，就是原字符串的开头下标了，所以利用最大的P[i]与其位置i，就可以从原字符串中提取出目标回文串。 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func longestPalindrome3(s string) string { origin := s s = pretreatment(s) len := len(s) // p[] 存储各个点上的中心扩展(回文)值 p := make([]int, len) var center, bound, maxLen, centerIndex int p[0] = 0 p[1] = 0 center = 1 // 对right点 确定p[right] for right := 1; right &lt; len-1; right++ { left := 2*center - right // 超出边界 if right &gt; bound { p[right] = 0 } else { // 取left，bound-i (到边界的距离)，p[left] (镜像位置) p[right] = int(math.Min(float64(bound-right), float64(p[left]))) } // 对正在处理的right点，尝试中心扩展 for s[right+1+p[right]] == s[right-1-p[right]] { p[right]++ } // 超出界限, 更新 center 和 bound if (right + p[right]) &gt; bound { center = right bound = right + p[right] } } for i := 1; i &lt; len-1; i++ { if p[i] &gt; maxLen { maxLen = p[i] centerIndex = i } } startIndex := (centerIndex - maxLen) / 2 return origin[startIndex : startIndex+maxLen]}func pretreatment(s string) string { len := len(s) if len == 0 { return \"^$\" } cue := []rune(\"^#$\") var res []rune runes := []rune(s) res = append(res, cue[0]) for i := 0; i &lt; len; i++ { res = append(res, cue[1], runes[i]) } res = append(res, cue[1], cue[2]) return string(res)}","link":"/2020/04/03/leetcodeQ5/"},{"title":"[Python] 变量作用域相关","text":"python作用域首先先要明确的一点是python的变量作用域分为：loca, nonlocal, global, builtin 变量的查找顺序是由内到外的。 1234567891011121314151617# 块级作用域if 1 == 1： name = 'zjs' print(name)for i in range(10): age = i print(age)# 局部作用域def func(): name = 'zjs' print(name) 作用域链话不多说，直接上终极版 12345678910name = 'zjs'def f1(): print(name) def f2(): name = 'eric' f1() f2() 最终的输出是’zjs’ 要明确的一点是，函数在未执行之前，作用域就已经形成了","link":"/2019/07/05/python%E5%8F%98%E9%87%8F%E4%BD%9C%E7%94%A8%E5%9F%9F%E7%9B%B8%E5%85%B3/"},{"title":"[NOTE] ssh免密登陆配置","text":"第n次忘记 生成公钥ssh-keygen -t rsa scp -p id_rsa.pub hadoop@slave1:~/.ssh/id_rsa_master.pub 检查是否存在touch authorized_keys，并chmod 600 authorized_keys cat ~/.ssh/id_rsa_master.pub &gt;&gt; authorized_keyJ","link":"/2019/07/05/ssh%E5%85%8D%E5%AF%86%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AE/"},{"title":"[Golang] 简单并发telnet服务器","text":"一个小demo，通过goroutine简单高效地实现并发的操作。 goroutine类似Python、C#中的coroutine，都可以使函数在独立的环境中运行，与之不同的是，goroutine某种程度上来说更为强大一些，它允许并行执行，可以通过channel进行进程间的通信。 当然，其他的区别也有很多，但不在本文讨论范围之内，之后会将这方面的知识归纳总结一次。 1.程序分析程序中需要实现一个简单的telnet服务器，对地址端口进行监听，并将传送来的信息“完璧归赵”。 主方法中主要负责开启server(address string, exitChan chan int)线程，exitChan通道中在没有传来server信息之前，会一直阻塞主方法。 server()中对指定地址端口持续监听(出现问题向exitChan中传入非正常退出的信号)，当有请求传来时，Accept并开启一个处理会话的线程handleSession(conn net.Conn, exitChan)，handlerSession()主要对传来的信息进行解析：字节码转为字符串，并判断前缀是否有指令，根据传来的信息不同，执行不同的响应。 该程序的主要处理过程如图所示： 1.1 server.go123456789101112131415161718192021222324package mainimport ( \"fmt\" \"net\")func server(address string, exitChan chan int) { l, err := net.Listen(\"tcp\", address) if err != nil { fmt.Println(err.Error()) exitChan &lt;- 1 } fmt.Println(\"listen:\" + address) defer l.Close() for { conn, err := l.Accept() if err != nil { fmt.Printf(err.Error()) continue } go handleSession(conn, exitChan) }} 注意使用defer，将监听关闭，否则会报错。 1.2 session.go12345678910111213141516171819202122232425262728293031package mainimport ( \"bufio\" \"fmt\" \"net\" \"strings\")func handleSession(conn net.Conn, exitChan chan int) { fmt.Println(\"Session started:\") reader := bufio.NewReader(conn) for { str, err := reader.ReadString('\\n') if err == nil { str = strings.TrimSpace(str) if !processTelnetCommand(str, exitChan) { conn.Close() break } // Echo with the same string conn.Write([]byte(str + \"\\r\\n\")) } else { // Error fmt.Println(\"Session closed by mistake\") fmt.Println(err.Error()) conn.Close() break } }} 主要注意网络请求的处理方法、步骤。 1.3 telnet.go12345678910111213141516171819package mainimport ( \"fmt\" \"strings\")func processTelnetCommand(str string, exitChan chan int) bool { if strings.HasPrefix(str, \"@close\") { fmt.Println(\"Session closed\") return false } else if strings.HasPrefix(str, \"@shutdown\") { fmt.Printf(\"Server shutdown\") exitChan &lt;- 0 return false } fmt.Println(str) return true} 1.4 main.go12345678910package mainimport \"os\"func main() { exitChan := make(chan int) go server(\"192.168.1.4:60001\", exitChan) code := &lt;-exitChan os.Exit(code)} exitChan的使用。","link":"/2020/03/13/telnet-server/"},{"title":"[水] 个人博客的意义","text":"之前一直在思考一个问题：作为一个小白，既不能在技术深度上有所建树，也无法在知识范围上超越旁人，那么我写博客的意义到底是什么呢？ 一些说法恰好前日在v2ex上看到一个提问，提问者也大概是遇到了跟我差不多的问题，底下的回答也算是让我了解了其他人的一些想法。 其中有个说法很有意思：大部分个人博客都夭折在了“如何使用xx搭建一个博客平台”上，好一点的话，30篇左右的文章差不多也是大多数个人博客的终点了。数了数自己博客文章的数量，大概是还没有活过早夭期。 也不好夸下海口自己的个人博客能活多久，能有多少产出，因为这又涉及到了另一个比较有代表性的问题：文章是否有价值。 有些人习惯将流量作为衡量博客网站价值的标准之一，我也不是太理解他们的一些想法，可能是某种“站长思维”吧。就我目前的水平而言，我的博客中大多数的文章都是记录的自己在实践过程中遇到的问题以及相应的解决方案，有些问题具有特异性，有些问题千篇一律，因此我也是不太希望我的博客被访客们看到，颇有种鲍鱼之肆的鄙薄之感。 就现阶段而言，我还是比较赞同一些人的意见：不管是成为博客还是笔记，在我写就之初，其实针对的只是我一个人，既作为锻炼自己语言组织能力的一种方法，同时也是以后遇到相同问题的一个速查与备忘。 一些展望 上文也提到了，博客的目标用户就是我自己，所以在一些文章的表述中多有略写，有几次分享给同学看的时候，往往都会被说写得不是很明白，甚至有时候我回头自己看的时候，也需要经过一番回忆。希望之后的文章能将语言组织的更好，同时在必要的地方能多些笔墨。 之前也看过一些优秀的博客，且不论前辈的技术水平足以形成碾压之势，在其他方面也颇有些逼格。如我所见到的几位清华的博主，博客中犹喜欢用英文甚至繁体中文，还有些在摄影方面有所长的，在旅游方面颇有些经历的，他们的博客都令我心向往之。所以，不管是作为一个技术博客还是记录生活的平台，希望之后都能形成我自己的风格，变得有意思一些。 在文章深度方面，希望不仅仅只是些”复现“他人博客的文章。","link":"/2019/08/15/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%9A%84%E6%84%8F%E4%B9%89/"},{"title":"[NOTE] 内网穿透","text":"在开了一台具有公网IP的云主机之后，利用代理服务器来实现本地服务器内网穿透的计划终于可以开始了。 ngrok实现内网穿透一、相关原理1.正向代理 正向代理中，client的目的地址是目标服务器，但由于种种原因，与目标服务器之间连接慢或者无连接，因此，使用了一个中间媒介——代理服务器来承担一个中介的功能。 2.反向代理 反向代理与正向代理不同，Client的目的地址就是Proxy服务器，所有的请求都是发给Proxy，有Proxy分配给它之后的服务器执行任务，并返回结果。反向代理主要特点： 保护和隐藏原始资源服务器 加密和SSL加速 负载均衡 缓存静态内容 压缩 减速上传 安全 外网发布 3.内网穿透Ngrok事实上是一个隧道，即建立安全通道从公共端点到本地运行的网络服务，同时捕捉检查和重播所有流量的反向代理。 简单来说，他可以代理你本地的数据，并将其转发到外网，流程如下： 123451. 本地内网主机和服务器A构建一条连接2. 用户访问服务器A3. 服务器A联系本地内网主机获取内容4. 服务器A将获取到的内容发送给用户5. 通过上面的流程，就实现了用户访问到了我们内网的内容。 更直观点，借用frp文档中的这张图来说明。 二、环境与源码 相关依赖 1sudo apt-get install build-essential golang mercurial git Ngrok源码 123git clone https://github.com/inconshreveable/ngrok.git ngrok## 建议请使用下面的地址，修复了无法访问的包地址git clone https://github.com/tutumcloud/ngrok.git ngrok 如一定要使用上面的官方地址，需要修改 src/ngrok/log/logger.go 中的源代码，将 log &quot;code.google.com/p/log4go&quot; 修改为 log &quot;github.com/alecthomas/log4go&quot; 否则编译时会报错 build fails: 'package code.google.com/p/log4go: unable to detect version control system for code.google.com/ path' 三、生成TLS证书以我们的域名nuzar.top为例，由于暂时没有通过备案，无法设置二级域名，因此暂先使用一级域名。 生成TLS的命令如下： 1234567NGROK_DOMAIN=\"nuzar.top\"openssl genrsa -out rootCA.key 2048openssl req -x509 -new -nodes -key rootCA.key -subj \"/CN=$NGROK_DOMAIN\" -days 3650 -out rootCA.pemopenssl genrsa -out device.key 2048openssl req -new -key device.key -subj \"/CN=$NGROK_DOMAIN\" -out device.csropenssl x509 -req -in device.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out device.crt -days 3650 将官方ngrok.com的证书替换为刚刚生成的私有证书，当然你也可以购买一个SSL证书，这个地方似乎可以用阿里云提供的nuzar.pem证书，但由于是初次搭建内网穿透的服务，先已稳为主。 123cp rootCA.pem assets/client/tls/ngrokroot.crtcp device.crt assets/server/tls/snakeoil.crt cp device.key assets/server/tls/snakeoil.key 四、编译服务端与客户端程序 设置Golang编译目录和参数 12export GOPATH=/goexport CGO_ENABLED=0 第二条命令是为了可以在 docker 环境下运行的需要，否则会报错 Unable to run a go program inside docker /bin/sh: ./ngrokd: not found 编译ngrok服务端和客户端 1234567891011121314151617181920212223# Linux 32 位系统 ngrok 编译命令export GOOS=linux GOARCH=386make release-server release-client# Linux 64 位系统 ngrok 编译命令export GOOS=linux GOARCH=amd64make release-server release-client# Windows 32 位系统 ngrok 编译命令export GOOS=windows GOARCH=386make release-server release-client# Windows 64 位系统 ngrok 编译命令export GOOS=windows GOARCH=amd64make release-server release-client# macOS 32 位系统 ngrok 编译命令export GOOS=darwin GOARCH=386make release-server release-client# macOS 64 位系统 ngrok 编译命令export GOOS=darwin GOARCH=amd64make release-server release-client 五、运行ngrokd服务端编译完成之后可以在 bin 目录下看到 ngrokd（服务端）和 ngrok（客户端），运行服务端时需要将 assets/server/tls/snakeoil.crt 和 assets/server/tls/snakeoil.key ngrokd服务端启动： 1./ngrokd -tlsKey=snakeoil.key -tlsCrt=snakeoil.crt -domain=\"nuzar.top\" -httpAddr=\":80\" -httpsAddr=\":443\" -tunnelAddr=\":4443\" 这行命令中，指定了相关证书、域名，之后的80、443端口指的是ngrokd会监听这些端口的信息，如果收到信息，就会转给相应的协议地址进行处理，4443端口用于服务端和客户端保持隧道连接。 六、运行ngrok客户端在客户端通过scp命令从服务端中拉取客户端的可执行程序，并编写一个ngrok.cfg文件 12server_addr: \"nuzar.top:4443\"trust_host_root_certs: false 这里注意server_addr一定要和之前生成TLS证书步骤中的地址保持一致，否则服务端会报tls: bad certificate证书错误。 七、小结遗憾的是，经过一个白天的努力，我确认所有步骤都正确的情况下，依然会在服务端显示证书有问题，相关问题这篇博客都说的很清楚，我也都已经一一确认过。并且由于ngrok1.x版本的开发人员已经停止维护，ngrok2.x版本为闭源软件，决定采用另一套方案。 frp实现内网穿透首先说明，frp是由国人开发的，有非常好的中文文档支持，项目目前处于项目开发的初期，可靠性上面可能存在一些问题，但是在ngrok方案迷之出错的情况下，还是值得一试的。 frp配置十分简单，从这找到适合你机器的最新版本，同样的，frp也是分服务端和客户端，但是在你下载的文件中，已经包含了可执行的服务端和客户端程序，十分友好。 解压下载的.tar.gz包，可以看到一堆文件中包含四个文件frpc frpc.ini frps frps.ini，这四个文件分别是客户端和服务端的程序及其配置文件，也就是说，如果你正好是个强迫症的话，你完全可以在服务端只留下frps frps.ini这两个文件，客户端同理。 使用最简化的配置： 123# frps.ini[common]bind_port = 7000 启动frps: ./frps -c ./frps.ini 1234567891011# frpc.ini[common]server_addr = x.x.x.xserver_port = 7000[ssh]type = tcplocal_ip = 127.0.0.1local_port = 22remote_port = 6000# 即可通过x.x.x.x:6000来访问127.0.0.1:22 启动frpc: ./frpc -c ./frpc.ini 当遇到端口占用的问题时，通过netstat -tunlp可以查看占用端口的程序的pid，一定要在确定自己要做什么的情况下，kill -9 {PID} 配置多个内网主机错误的多客户端配置使用一台阿里云的公网服务器，我们可以配置很多内网机器的 frp 内网穿透，公网服务器上只需要按照上述的配置一次即可，但是内网机器的配置稍有不同，如果使用了一样的配置则后添加的内网机器是无法连接上公网服务器的。这里假设另一台内网机器2的 frpc.ini 配置如下，来说明会遇到的问题： 123456789[common]server_addr = xxx.xxx.xxx.xxx &lt;==这里还是按照上面的假设，公网服务器的ip为xxx.xxx.xxx.xxxserver_port = 7000[ssh]type = tcp local_ip = 127.0.0.1local_port = 22remote_port = 6001 &lt;==remote_port设置为另一个值 两个内网主机的配置除了 remote_port 不一样之外，都是一样的。但是在内网机器2上运行 frpc 后，公网服务器的 nohup.out 中会记录一下的错误： [W] [control.go:332] [280d36891a6ae0c7] new proxy [ssh] error: proxy name [ssh] is already in use1后来发现，frp 中是通过 [ssh] 这个名字来区分不同客户端的，所以不同的客户端要配置成不同的名字。 正确的多客户端配置内网机器1和内网机器2的配置应该区分如下： 12345678910111213内网机器1：[ssh] &lt;==不同点type = tcp local_ip = 127.0.0.1local_port = 22remote_port = 6000 &lt;==不同点内网机器2：[ssh1] &lt;==不同点type = tcp local_ip = 127.0.0.1local_port = 22remote_port = 6001 &lt;==不同点 在两个内网机器上分别运行 frpc 客户端程序后，一般就可以通过以下的方法 ssh 登录： 123456内网机器1：ssh -p 6000 user_name1@server_addr内网机器2：ssh -p 6001 user_name2@server_addr 保护辣个frp1.使用nohup启动这是frps的后台启动（路径写你服务器上的绝对路径），如果要查看日志的话，就直接使用cat nohup.out，就可以查看了。 nohup /path/to/your/fprs -c-c /path/to/your/frps.ini 这是frpc的后台启动 nohup /path/to/your/fprc -c-c /path/to/your/frpc.ini 2.使用systemctl来控制启动1vim /lib/systemd/system/frps.service 写入： 123456789101112[Unit]Description=fraps serviceAfter=network.target syslog.targetWants=network.target[Service]Type=simple#启动服务的命令（此处写你的frps的实际安装目录）ExecStart=/your/path/frps -c /your/path/frps.ini[Install]WantedBy=multi-user.target 启动frps：systemctl start frps 设置开机自启：systemctl enable frps 如果要重启应用，可以这样，sudo systemctl restart frps 如果要停止应用，可以输入，sudo systemctl stop frps 如果要查看应用的日志，可以输入，sudo systemctl status frps 3.使用supervisor来控制这个貌似只在ubuntu上好使，CentOS上使用须谨慎 sudo apt install supervisor 创建 supervisor frps 配置文件,在 /etc/supervisor/conf.d 创建 frp.conf 123program:frp]command = /your/path/frps -c /your/path/frps.iniautostart = true 1234# 重启supervisorsudo systemctl restart supervisor# 查看supervisor运行状态sudo supervisorctl status 客户端也是一样。","link":"/2019/08/03/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"title":"[NOTE] 区块链漫谈","text":"谈到区块链技术，有个绕不过的东西，那就是比特币。比特币被称为“分布式的账单”，这是区别于银行而言的。传统货币中是有银行这个中心存在的，银行通过印发钞票、增减债券、修改准备金等金融手段调控货币，使其稳定。银行作为一个受信任的第三方，保有交易双方的交易信息，也就是其账本。 而中本聪提出比特币白皮书的提出是有一个背景的，那就是08年的金融危机，金融危机后来被认为是银行、评级机构对信用的滥用导致的。这也引发了人们的担忧：当有一天，银行变得“不靠谱”的时候，我们手上的货币还能靠谱吗？ 比特币的原理上述细节可能不是比特币诞生的直接原因，但它一定是原因之一。 白皮书从一开始就给了比特币一个定义”A Peer-to-Peer Electronic Cash System”，因此比特币的设计中，是不存在“中心”这个概念的，我们且先不太其实现的具体原理，先解决下面的两个问题： 没有“中心”，那么账本由谁来记呢？——可以是每个人 账本保存在哪呢？——每个人都会保存一个账本的副本，即区块链 1.账本的记录在白皮书中，所有的交易信息都是保存在区块链上的，当有新的交易信息需要记录时，便会将所有新产生的交易信息记录到一个新的块上，将这个块接到链的后端。 这个时候我们得明确一点，bitcoin中是不存在余额这个概念的，要是有天我想数数我有多少钱，那真得好好数数了——从链头开始，查看所有自己的收入和支出，最后得到的结果，就是自己的“余额”。这么一说来，保存一份账本也是很有必要的了（具体原因后面会说明）。 这两个问题是解决了，但同时引来了更多的问题。 2.为什么要记账？对人来说，记账不是一件轻松的活，而对于计算机来说，记账是要消耗它的算力、电力的，那么假若你是个比特币的用户，你为什么要费心力给别人的交易“记账”呢？ 因为有奖励！ 奖励分为两个部分：交易额一定比例的手续费；打包奖励。 手续费：“既然都是革命性的货币了，怎么还收手续费？”——手续费远低于银行 打包奖励： 打包是什么？——交易信息会以广播的形式发出，对于一个用户(计算机)来说，它会尝试将它所收到的交易信息都整合到一起，并尝试“打包”，接到链的末端。 奖励金额：白皮书中约定，10分钟打包一次，每个打包者奖励50BTC，每四年奖励减半（这是为了约束最后的BTC的总数接近一个定值：210,000,000） 问题又来了，打包有奖励，那岂不是“人人喊打”？ 3.打包的约束——工作量证明(Proof of Work, PoW)显然，包是只能一个人打的，这样才能保证区块链正常运行下去。因此所有分布式节点都需要达成一个共识，即当一个节点收到了其他节点打包完成的信息的时候，这个节点就会放弃当前的打包操作，转而去打下一个包。 但这样依然很难避免这样一种情况：多个节点”同时“打好了包（此处同时不一定是同一时刻，由于网络延迟的原因，很可能一个节点完成打包操作后，才收到其他节点早已完成打包的信息）。 为了尽量避免这种情况的发生，中本聪的做法是将打包这个过程拉长，这样做确实能有效的降低重复打包的现象，具体做法是： 我们将：1.记录前块信息的“头部”；2.记录交易信息的“账单”；3.时间戳；4.一串随机数 组合成一个块，对这个块进行两次SHA256的哈希运算，最终的到一个256位的hash值。 按照约定，如果这个256位的hash值的前n位为0，那么我们就会认可这个块可以接在链上，即具备了打包资格。由于sha256的不可逆性，所有节点只能通过修改随机数的值，一个一个去尝试，看得到的结果是否能满足条件（根据时间戳的不同，各节点开始计算的值也不同），这个过程，也被称为挖矿。 前面我们也提到，白皮书中计划是每10分钟打一个包，那么如何实现呢？ 对于256位的hash值来说，我们可以认为每一位上出现0的几率是50%，那么hash值的前n位为0的几率就是1/(2^n)，假设算力恒定，显然n越大，计算出符合条件的结果的时间就越长。那么回到现实情况，参与BTC运算的算力一直在增长，我们就可以增加n的大小，使每个包的产出时间在概率上恒定于10分钟。 如果你还没有充分理解的话，我们一起来做道计算题： 123假设一共有2w台矿机参与运算，每台矿机的算力为14Tbps，此时要控制为10分钟打包一次，需要将n设置为多少？20000*14*10^12*600=1.68e20 约为 2^67 尽管有PoW算法的保障，但仍然不能排除同时打包的情况的发生。同时打包的两个节点，会分别向周围的节点分发自己的那个包，这个时候，宏观上就会发生区块链链路分叉的情况，面对这种情况，我们又该如何处理呢？请继续看下文。 ##区块链中的安全机制 在BTC中，不管是将交易信息广播给其他节点，还是将打包的块分发，都需要处理一个问题：如何防伪？怎样确保信息传输的过程中没有收到篡改？ 解决这个问题的方法是：电子签名 1.电子签名计算机网络中电子签名的应用范围十分广泛，相信你对电子签名已经有了一定的认知了，所以先略过。 2.溯源前文已经提到，用户拥有比特币的数量不是按照余额来计算，所以当要验证用户是否有能力支付对应金额的比特币时，其他用户就需要“查账”，包括：打包收益、交易支出、交易收入。一旦发现该用户并不具备支付能力时，这个交易信息就会被驳回，不会被分布式中的节点所承认。 3.双重支付问题在溯源问题中我们提到，节点接收交易信息的时候并不是无脑接受的，它会校验交易是否合法。 那么考虑这样一种情况，A只剩下5 BTC，此时它同时向B和C转帐5 BTC，由于B和C分别在不同的地方，它们对交易的校验都是通过的，这就是双重支付问题。 此时，B和C处会存在一个竞争，由于交易信息会被分别广播到B和C周边的节点，此时那边的节点先完成打包的计算，那么该处对应的交易才完成，另外一个尚未完成的交易将会被废弃。 4.最长链原则继续双重支付中的问题，若是B和C两处的节点同时完成打包操作呢？ 此时，两边不同版本的区块链版本分别向全网扩散，此时从宏观上来看，区块链就发生了分支的现象，此时参与运算的节点们会分为三派，一派我们称为A分支，另一派我们称为C分支，那还剩一派呢？它们还没来得及接受A或C的分支。 那么如何解决这种冲突呢？节点们此时会分别在B和C中继续打包，优先打出下一个包的分支同样也会将它们的链广播出去，当某个节点接收到的链与它自己的链处于两个不同分支的时候，它会选择信任更长的那条链，并将继续在更长的那条链上运算下去，而这就是所谓的最长链原则。 为什么节点们会选择更长的那条链呢？ 结合之前双重支付的问题，一旦一条支链被废弃，那么这条支链上所有的打包收益也将被废弃。节点们自然不会愿意做无用功，所以在计算下一个块的时候，它们会选择更长的那条链，接在后面进行计算。 5.防篡改先给结论，比特币防篡改的机制其实很简单，就是基于PoW算法的算力约束。也就是说，当某一方想要恶意篡改区块链之中的交易信息的时候，他需要拥有超过全网50%的算力。50%从何而来呢？许多文章对这个地方都语焉不详，其实这个依然是基于最长链原则的。 假如用户A想要篡改某个块之后的内容，他需要做的事情，是在该链之后创建出一条链，并使这条链的长度最终超过“主链”，成为新的主链。 这样，其他用户也将认可这条“伪造的链路”，并在其后进行运算。 但比特币社区到目前并没有实际发生过51%攻击的事件，一是由于其用户数量庞大，算力规模巨大导致的；二是由于在有绝对算力优势的情况下，在主链后面进行打包会是一个更有价值的行为。 共识层算法改进在一个分布式的系统中，最为关键核心的问题是同步，也就是数据的一致性，诚然PoW算法的确在一个强分布式的系统(我自己的称谓never mind)中为同步数据提供了一个很好的解决方法，但是它带来的消耗是在太高了。 一直到2019年的7月份，参与比特币运算的总算力已经达到了10^20bps的数量级了，这背后所代表的财力、物力的消耗非常恐怖。 1.消耗改进：PoS(Proof of Stake)PoS算法中提出了Stake这样一个概念用来取代算力(Work)，Stake可以是持币的数量、持币的价值甚至是持币的时间。所持有的资产将作为保证金参与打包的竞争，这个有点像股份制的公司，所持有的股份越多，分红越多。 对于产生恶意行为的用户，他的保证金将被没收。 PoS算法一定程度上解决了PoW算法中消耗过大的问题，但PoS算法同样也存在着自己的缺陷： 无权益问题：被废弃分支的奖励依然会被认可 被动中心化：按保证金分红，富者越富 早期危险：早期币值低，只需要付出可接受的代价就能超过51%的币值 2.性能改进：更高效的拓扑结构由于区块链单链的限制，导致打包操作只能串行地处理，这样效率过低，且会带来性能浪费（打包失败者的运算将被浪费）， Parallel execution of blockchain transactions 中提出了一种更高效的DAG结构。 除此之外，关于共识层算法也有很多的相关研究，如委托股权证明(Delegated Proof of Stake, DPoS)，活跃度证明(Proof of Activity, PoA)，消耗证明(Proof of Burn, PoB)等。 块空间不足问题我们知道，在很长一段时间，区块链的大小都是限制为1M的。其实最早中本聪创建比特币时，是没有区块大小限制的，但由于一个数据结构的限制，区块最大能达到33M，而不是现在的1M。但最早的时候比特币很便宜，只要花很少的钱，比如几美元，就可以发出非常多的垃圾交易，恶意地把区块数据撑大，撑满你的硬盘。所以中本聪加了一个1M区块限制，中本聪加的这个限制是临时的，并给出了未来扩容的安排。 预期设计的更大的区块限制可以分阶段执行： 当 区块高度(blocknumber) &gt; 115000 时 区块上限(maxblocksize)=更大的限制 随着用户数量的增多，交易频次的增长，在2017年，区块的大小已经不能满足需求了，但此时区块链的扩容却没有中本聪的计划走下去，这其中曲折也很有意思。 最早的比特币是由中本聪开发的，中本聪隐退后，比特币的开发维护任务由中本聪传给了加文（Gavin），加文（Gavin）觉得自己独裁不好，又把代码权限分权给了其它4名开发，后来又有其它开发加入，发展成现在的Core开发团队。 但后来，Core开发团队内部关于要不要按中本聪的计划，移走1M限制，产生了分歧。多数开发人员觉得不应该移除这个限制，部分觉得应该移除这个限制。 矛盾激化的结果，就是Gavin，Jeff等支持移除1M限制的开发人员，被赶出Core团队，被删除了代码权限。然后这些开发人员，包括一些新的，支持移除1M限制的开发人员，建立了XT、Classic、BU等开发团队。 我们说的这些开发团队的关系，很类似于一个国家里多政党的关系，互相竞争，并且说服用户选举他们作为执政党。也就是说就比特币的扩容，其实很早之前，比特币的核心开发团队就已经在争议了，也经过了比较激烈的人事斗争。我们理解其实这些核心开发者也是为了比特币的发展好。 双方的观点Core：不希望移除1M限制 这是个硬分叉，Core认为这样的硬分叉有分裂比特币的风险 首先科普下什么是硬分叉和软分叉 硬分叉是一个和软分叉相对应的概念，当比特币系统升级时，如果这个升级是向前兼容的，用户不需要升级自己的钱包也能继续用下去，这个升级就叫软分叉。 对应的，如果用户需要升级钱包才能继续用下去，这个升级就叫硬分叉。（这不是一个严格的定义，但是比较容易理解的定义） 硬分叉的风险在于，如果有用户没升级自己的钱包，那他就留在了旧版本的比特币上，他会发现自己的比特币，和别人升级了钱包的比特币不一样，是不兼容的，一个是旧版比特币，一个是新版比特币，如果有用户坚持在旧版上不升级，就产生了两个比特币，系统就会产生混乱，这是Core认为的第一个风险。 Core认为如果移除这个1M的限制，以后的区块会越来越大，2,4,8,16，太大区块会导致普通人的电脑无法运行完整版的钱包，这种完整版的钱包称为全节点。Core认为如果个人不能运行全节点，而只有公司和机构能运行全节点，会导致比特币的中心化。 Core认为我们现在有一些比中本聪更先进的技术方案，通过第二层网络（比如闪电网络）对比特币的交易进行分层，大部分低价值交易走第二层网络，只有少数的高价值结算交易走主链这个第一层网络。 闪电网络闪电网络是怎么运行的呢？它类似于牌局里的记账员。比如说有几个人在打牌，他们并不会每打一圈就我给你五块钱，你给我十块钱，而是会先记账，等打完很多圈以后，再一起算账，只付一次钱。 闪电网络类似于这种思路，比如说有人要经常向交易所充值和提现，那他就可以用闪电网络，和交易所之间打开一个结算通道，他向交易所充10BTC，并不是充到交易所的地址上，而是充到这个结算通道中，然后比如提现1BTC也不是提现到他的地址，而是和交易所把通道里的钱重新划分一下，本来10个比特币都是交易所的，现在1个比特币归他，9个比特币归交易所，这样他可以和交易所发生很多笔充值提现，却不打币到地址。就和打了很多圈牌都记账，不实际转钱一样，直到他需要关闭这个结算通道时，他再和交易所结算清账目，把属于自己的币提到自己地址。 如果有两个用户都和交易所建立和结算通道，那他们就可以以交易所为中间人进行转账，交易所会帮助他们结算相应的金额。 这就是闪电网络，闪电网络在主链第一层网络的基础上，建立了一个第二层网络，大部分交易都走第二层网络，而不进入第一层网络。有点类似于一个高架桥和地面道路的关系。 扩容派1.闪电网络架构上虽然存在优势，但中本聪架构已经被市场证明稳定运行了8年，金融系统应该保持稳定，没有特别需要，不应修改现在的架构。 从金融系统的角度考虑，搞第二层网络可以，但要保证第一层网络可以用，不能把第一层网络限制住1M，否则会产生灾难性后果。科技史上发生过一次非常类似的灾难：摩托罗拉的铱星系统。摩托罗拉的技术人员认为地面基站太Low了，说我们要搞个绝对牛逼高大上的卫星通讯网络，结果铱星系统开发了几年，烧掉了摩托罗拉的50亿美元（1997年的美元）后，仅仅运营了3个月就倒闭了，并且直接拖死了摩托罗拉。技术上看起来先进的架构未必比傻大黑粗的架构好。 2.第二层网络存在中心化隐患（具体解释），闪电网络的关键节点有点类似于支付宝（但不能偷钱和造假币），运营闪电网络的公司，可能被政府监管，关闭。 3.通过白皮书第7章删除历史数据等方式，大区块不会导致节点门槛提高。技术发展超过交易发展，20年内摩尔定律（每年CPU+60%）+尼尔森定律（每年带宽+50%），现在的网络和硬件可以承受20M的区块，足够10年使用。 两派的核心分歧扩容派认为应该重点关注比特币的使用人数，只有更多的人使用，才能保护比特币，这种保护是多个方面的，既是因为PoW共识机制，同样当更多的人能从区块链的系统中获益后，他们才会自发地拥护和发展区块链。 另外适当的中心化也是可以接受的，例如中本聪认为个人用轻钱包即可，没有必要用全节点。 同时这派的观点也涉及到了比特币的终极目的：作为法币的竞争货币，这个理论是哈耶克提出来的，哈耶克是1974年诺贝尔经济学奖得主，他认为政府不可能抑制住滥发法币的冲动，最好的办法就是竞争。商品的竞争能产生更好的商品，货币也应该竞争，货币的竞争也能产生更好的，币值稳定的货币。在法币过分通胀时，比特币作为法币的竞争货币，保护人民不受法币剥削，并通过竞争，抑制法币的通胀。 Core派则认为比特币的终极目的是实现一个终极自由的货币，能够保护个人的财产安全，从这点上看，和扩容派似乎有点殊途同归，但是，Core派则显得更为极端： Core派不是很关心比特币的交易拥堵或用户发展，出世派关心比特币是否符合自己心目中“终极自由货币”的标准，认为“终极自由货币”，是吸引用户来用的最高吸引力。 且，Core派不能接受一点中心化，认为要保证人人都可以运行全节点，并希望进一步增强比特币的相关属性，例如完全匿名性。 双方的妥协与彻底分裂香港共识：双方的最后一次妥协，双方同意妥协到 隔离见证+硬分叉2M，矿业不运行Classic（简单2M方案） 对扩容派来说，2M可以缓解目前拥堵的交易。对Core来说，2M不算太大（隔离见证实际也达到2M），所以他们并不反对隔离见证和能增加用户的LN，但扩容派反对Core路线图的第一步：软分叉隔离见证。 Core主要的几个开发回去后遭到其他人的反对（因为这是个妥协的方案），连相应代码都未开发，香港共识流产。 那么之后呢？ 扩容方转而支持BU一劳永逸解决区块大小的方案(BU：51%的矿池投票决定区块大小)——Core反对：扩容是矿业企图控制比特币，这将破坏比特币的开发（如闪电网络没有隔离见证只能非常不优雅地运行）——扩容反对Core的反对：Core的多名开发都受BlockStream公司雇佣，BS为了推行闪电网络，利用Core的出世倾向，锁死主链到1M（Core早期并没有1M那么极端，是不极端的Core开发都被踢出去了）。 反复吵架之下，一方面是区块拥堵加剧，另一方面是其他货币如ETH的高速发展。 以比特币为代表的区块链技术仍在曲折前进，区块链先天具有跨界的优势，在金融、物流、零售等方面都具有很多优点。文章到这已经接近尾声，但区块链的故事还在继续书写…","link":"/2019/10/28/%E5%8C%BA%E5%9D%97%E9%93%BE%E6%BC%AB%E8%B0%88/"},{"title":"[NOTE] 安装hadoop相关注意事项","text":"linux在启动过程中通过读取/etc/profile文件中内容完成相关环境的载入，而ssh登陆远程主机的时候并不会加载/etc/profile中的配置文件。 因此jdk安装完成后需要两次配置，一为配置/etc/profile中的环境变量，二将hadoop启动脚本中调用的HADOOP_HOME改为绝对路径的形式。 一、操作系统环境 依赖软件ssh、jdk jdk安装: rpm -i jdk-xxxx.rpm通过rpm安装jdk，会发现一个有趣的现象，使用whereis java时，系统会给出java安装在/usr/bin/java，但事实上，/usr/bin/java引出了一个指向/usr/java的软链接，而在/usr/java中，存在两个软链接，default指向latest，latest指向jdk1.x.x_xxx-xxx，且，通过rpm安装的java环境是不全的，java/bin目录下只有少数指令我们可以直接调取，而如jps一般的指令并未添加到系统的环境变量中； 解决：sudo vi /etc/profile文末添加export JAVA_HOME=/usr/java/jdk1.x.x_xxx-xxx，并在系统路径中增加PATH = $PATH:$JAVA_HOME/bin source /etc/profile 环境配置 java_home(/etc/profile) 免密 时间同步 hosts、hostname 二、hadoop部署 /opt/hadoop/ (/opt目录专门用于放第三方源的软件，注意/与/usr/local的区别) /etc/profile文件中加入export HADOOP_HOME=/opt/hadoop、PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 启动脚本修改 $HADOOP_HOME/etc/hadoop/hadoop-env.sh $HADOOP_HOME/etc/hadoop/mapred-env.sh $HADOOP_HOME/etc/hadoop/yarn-env.sh 配置文件修改 配置文件形式如下，property中包含name:value对，之后的内容中将只会说明需要配置的name:value。 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; etc/hadoop/core-site.xml Parameter Value Notes fs.defaultFS NameNode URI hdfs://host:port/ io.file.buffer.size 131072 Size of read/write buffer used in SequenceFiles. hadoop.tmp.dir /tmp/hadoop-${user.name} Linux内核在必要时会删除/tmp目录下文件，同时hdfs-site.xml中的dfs.namenode.name.dir与dfs.datanode.data.dir也使用了$hadoop.tmp.dir的参数，这会造成数据的丢失，因此必须修改。改为/var/hadoop/local ​ etc/hadoop/hdfs-site.xml configurations for NameNode: Parameter Value Notes dfs.namenode.name.dir NN对命名空间及日志文件进行持久化的地址。 If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy. dfs.hosts / dfs.hosts.exclude List of permitted/excluded DataNodes. If necessary, use these files to control the list of allowable datanodes. dfs.blocksize 268435456 HDFS blocksize of 256MB for large file-systems. dfs.namenode.handler.count 100 More NameNode server threads to handle RPCs from large number of DataNodes. configurations for SNN: | Parameter | Value | Notes | | ------------------------------------ | ------------- | ----------------------------------------------------- | | dfs.namedoe.secondary.http-address | 0.0.0.0:50090 | The secondary namenode http server address and port. | | dfs.namenode.secondary.https-address | 0.0.0.0:50091 | The secondary namenode HTTPS server address and port. | + configurations for DN: | Parameter | Value | Notes | | ----------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | | `dfs.datanode.data.dir` | Comma separated list of paths on the local filesystem of a `DataNode` where it should store its blocks. | If this is a comma-delimited list of directories, then data will be stored in all named directories, typically on different devices. | | | | |​ etc/hadoop/yarn-site.xml` etc/hadoop/mapred-site.xml 角色在哪里启动？ 启动 hdfs namenode -format此处遇到一个问题，hdfs格式化失败，猜测是还未修改hadoop用户权限，暂且先用root用户，修改用户权限看这一篇 start-dfs.sh 此处遇到一个问题，外网无法通过master:50070访问hadoop的管理页面，猜测是防火墙没关，关闭防火墙看这一篇 3.集群 NN SNN DN master * slave1 * * slave2 * slave3 * 修改hadoop.tmp.dir=/var/hadoop/cluster 并修改core-site.xml slaves hdfs-site.xml中相应的配置 scp -r /opt/hadoop/ hadoop@slave1:/opt/ 若碰到scp permission denied 的情况，可使用chmod 777 /opt/hadoop对使用权限进行修改 12","link":"/2019/07/08/%E5%AE%89%E8%A3%85hadoop%E7%9B%B8%E5%85%B3%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"},{"title":"[Docker] 基于Docker的NextCloud私有云盘搭建","text":"毫无含量的水博客。 1.准备工作 安装Docker，假定CentOS: 1yum install -y docker 设置Docker自启 12systemctl start dockersystemctl enable docker 准备相关镜像 12docker pull docker.io/nextclouddocker pull docker.io/mariadb 2.运行容器 数据库容器 123456docker run -d --name db_nextcloud \\-v /var/www/nextcloud/mysqldb:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=ROOT_PWD \\-e MYSQL_DATABASE=nextcloud \\-e MYSQL_USER=nextcloud \\-e MYSQL_PASSWORD=YOUR_PWD mariadb nextcloud容器 3.网页配置 好的，水完了。 看来还没完 4.将本地端口映射到云端 修改frpc.ini 1vim FRP_PATH/frpc.ini 添加12345[http-nextcloud]type = tcplocal_ip = 192.168.1.101local_port = 40080remote_port = 40080 之后就可以在远程主机 remote_ipaddr:40080上看到页面了 5.域名加入到信任列表如果按照本文的步骤，那么到了这个地方你应该会碰到一个问题：通过域名访问云盘时，NextCloud页面会提示请求域名未加入到信任列表。按照页面给出的提示，这个问题应该很好解决： 1vim /var/www/nextcloud/config/config.php 在trusted_domains下添加： 123456'trusted_domains' =&gt; array ( 0 =&gt; '192.168.1.253:40080', 1 =&gt; 'YOUR_REMOTE_ADDR', 2 =&gt; 'YOUR_DOMAINS',)","link":"/2019/09/25/%E5%9F%BA%E4%BA%8EDocker%E7%9A%84NextCloud%E7%A7%81%E6%9C%89%E4%BA%91%E7%9B%98%E6%90%AD%E5%BB%BA/"},{"title":"[Golang] 自动健康上报","text":"Charles http.Client mailx crontab Charles Golang 1.14 CentOS 7 健康上报APP 1. Charles1.1 基本配置本身的功能还是很多的，由于健康信息上报在手机APP中，无法正常通过浏览器来分析请求信息，所以此处用Charles进行抓包。 Charles为收费软件，自行决定下载源，安装完成后： 系统代理端口：菜单栏Proxy - Proxy Settings - Proxies - HTTP Proxy设置为8888(默认值)； 确保手机和电脑在同一局域网下； 手机修改Wi-Fi配置，一般在“无线网络选项”或“高级选项”中，可以设置HTTP代理，将其设置为PC_ADDR: 8888，此时手机的所有流量都会通过电脑的8888端口，由Charles截获； 包乱码问题： 以上仅针对http请求，而我们需要截获的APP请求是通过HTTPS进行的，因此要求电脑端和手机端都有相同的证书，便于伪装(我猜的) 菜单栏：Help - SSL Proxing - Install Charles Root Certificate 手机打开网址http://www.charlesproxy.com/getssl，获取电脑上的证书 菜单栏：Proxy - SSL Proxying Settings - SSL Proxying，Location Include中添加*:443，即匹配任意站点的HTTPS请求 1.2 抓包完成配置之后，抓包是很简单的，手机打开相应页面，电脑截获请求，由于这个APP用的是WebView，甚至可以直接将请求的网址提取出来，利用Chrome浏览器进行分析。 根据相关信息找到服务器的地址，在uc/wap/路径中，找到了目标login，我们关注的主要在Contents中，上下两部分分别是Request与Response。 至此，手机可以丢到一旁了。关于Charles使用的详细信息，可以参考这篇文章. 1.3 分析在信息上报的流程中，通常我们需要完成两步操作“登陆-提交信息”，尽管我们知道提及信息对应的路径ncov/wap/default/save，但是直接访问这个地址会被重定向到登陆页面，因此我们需要登陆获取Cookies。 伪造请求：请求中需要包括与Request中相同的Headers，使我们的data可以顺利的被服务器认可、读取并返回需要的response。 读取返回：response通常为返回的HTML或者关于操作成功/失败的status，按照Response - Header中可能存在的Content-Encoding类型对返回值进行解码，并通过正则表达式提取出文本中我们需要的内容。 绕过合法性校验：通过分析网页的源码，针对所处地理位置、身体状况、是否已提交等信息的校验几乎都是在前端完成的，这也为我们之后的工作提供了便利。 定位信息：定位是通过请求百度地图的API完成的，源码中就包含相应的token。但使用API定位收到的限制比较大：1.最终部署服务器的位置；2.大公司API可能存在的一些安全限制。不过网页js中就包含了“上次提交”的信息oldInfo，可以直接针对上次信息作出提取，修改几个值就可以作为新的信息进行提交了。 2. 伪装请求基于上述的分析，我们可以将程序分成三个步骤： 首先向POST uc/wap/login/check发送信息，成功登陆并获取cookies； GET /ncov/wap/default/index向信息上报页面请求信息，并且对所需信息进行匹配； 之后绕过信息上报的页面，直接将包装好的信息通过POST /ncov/wap/default/index/save。 2.1 Golang的几种请求方式2.1.1 GET123func Get(url string) (resp *Response, err error) { return DefaultClient.Get(url)} Get请求可以直接用http.Get(url string)方法进行，如下： 123456789101112func httpGet() { resp, err := http.Get(\"https://example.com\") if err != nil { // handle error } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) //请求数据进行读取 if err != nil { // handle error } fmt.Println(string(body))} 2.1.2 POSThttp.Post()接收string类型的url与请求头bodyType，最后一个参数接收io.Reader类型的主体内容，可以通过strings.NewReader()进行转换 123func Post(url string, bodyType string, body io.Reader) (resp *Response, err error) { return DefaultClient.Post(url, bodyType, body)} 例： 12345678910111213func httpPost() {resp, err := http.Post(\"https://example.com\",\"application/x-www-form-urlencoded\",strings.NewReader(\"name=abc\")) if err != nil { fmt.Println(err) } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil { // handle error } fmt.Println(string(body))} http.PostForm()支持表单的请求： 1234567func httpPostForm() { form := url.Value{} form.Add(\"name\", \"张三\") form.Add(\"password\", \"zhangsanNB\") resp, err := http.PostForm(\"https://example.com\", form) ...} 2.1.3 复杂请求对于一些复杂的请求，可以用http.NewRequest()和&amp;http.Client{}进行构建。 事实上，http.Get() http.Post() http.PostForm()都是对http.Client{}的封装，在执行请求的时候，都是用了client.Do()方法，因此要设置更详细的请求信息，可以直接首先对http.Client{}进行初始化： 12345jar, _ := cookiejar.New(nil)client := &amp;http.Client{ Jar: jar, Timeout: 10 * time.Second,} cookiejar为保存cookie的容器，Timeout用于设置超时时间。对于client我们需要详细设置其Headers 1234567891011121314req.Header.Set(\"Host\", \"example.com\")req.Header.Set(\"Connection\", \"keep-alive\")req.Header.Set(\"Content-Control\", \"max-age=0\")req.Header.Set(\"DNT\", \"1\")req.Header.Set(\"Upgrade-Insecure-Requests\", \"1\")req.Header.Set(\"User-Agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\")req.Header.Set(\"Sec-Fetch-Dest\", \"document\")req.Header.Set(\"Accept\", \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\")req.Header.Set(\"Sec-Fetch-Site\", \"same-origin\")req.Header.Set(\"Sec-Fetch-Mode\", \"navigate\")req.Header.Set(\"Sec-Fetch-User\", \"?1\")req.Header.Set(\"Referer\", \"https://example.com/uc/wap/login?redirect=https%3A%2F%2Fexample.com%2Fncov%2Fwap%2Fdefault%2Findex\")req.Header.Set(\"Accept-Encoding\", \"gzip, deflate, br\")req.Header.Set(\"Accept-Language\", \"zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7\") 这一步的内容取决于你捕获的包的请求头。之后我们需要自己定义一个请求http.NewRequest() 12345678910111213// GETresp, err := client.Get(\"https://example.com\")if err != nil { logs.Warn(err.Error())}defer resp.Body.Close()// POSTreq, _ := http.Newrequest(\"POST\", \"https://example.com/\", \"data\")resp, _ := client.Do(req) //篇幅有限，err省略// or// resp, _ := client.Post(\"https://example.com/\", \"data\", nil)defer resp.Body.Close() 注意及时关闭resp.Body，防止资源占用导致的阻塞。 ​ 2.2 内容提取通过http.Client.Get(&quot;https://example.com/ncov/wap/default/index&quot;)可以获取页面信息，当然由于在headers中设定了Accept-Encoding: gzip，此处需要对response.Body进行解码操作，否则看到的是一堆乱码： 1234567891011//解决Content乱码问题var reader io.ReadCloserswitch response.Header.Get(\"Content-Encoding\") {case \"gzip\": reader, err = gzip.NewReader(response.Body) defer reader.Close()default: reader = response.Body}byte, err := ioutil.ReadAll(reader)str := string(byte) 截取内容中的一段。 123456789101112131415161718192021# ----HTML ABOVE------ #var vm = new Vue({ el: '.form-detail2', data: { realname: \"张三\", number: 'SZ111111111', date: '2020-03-25', info: $.extend({ ... }, def, { szgj: '', szcs: '' }), oldInfo: {\"id\":2368048,\"uid\":236939,\"date\":\"20200324\",...,\"sflznjcjwfh\":\"0\"}, tipMsg: '', ajaxLock: false, showFxyy: false, sfzgn: 1, hasFlag: '1', }} 简单粗暴一点，直接用正则表达式匹配我们需要的信息oldInfo realname number 123456789func GetInfo(str string) (string, error) { matched, err := regexp.MatchString(\".*oldInfo:.*\", str) infoRegexp := regexp.MustCompile(`.*oldInfo:\\s(\\{.*\\})`) params := infoRegexp.FindStringSubmatch(str) if matched { return params[1], nil } return \"\", err} ​ 2.3 数据序列化json显然oldInfo为一段json文本，通过GetInfo(str string) (string, err)我们得到了一段string，将其转为map[string]interface{}便于对其中的值进行修改。 1234567891011121314str := ReadString(username)var data map[string]interface{}// var info map[string]string// 由于部分值并不是string类型，所以用interface{}进行读取if err := json.Unmarshal([]byte(str), &amp;data); err != nil { return err}// some procedures ...byte, _ := json.Marshal(data)str := string(byte)// 将数据持久化f, _ := os.Open(path)l, _ := os.WriteString(str) // l为写入的字节数f.Close() 这里有个不好处理的地方：由于返回的json文件中，存在整型和字符串类型的value，而在将数据封装到请求包的过程中，需要将json存到url.Values{}中，这是一个map[string][]string类型的对象，为了避免麻烦，在上述过程中，直接讲部分整型通过strconv.Itoa(int)转成了字符类型。 3. 部署为了实现整个上报过程的自动化，需要将程序放在服务器上，并定期运行。 3.1 构建多平台可执行程序针对不同平台使用env GOOS=target-OS GOARCH=target-architecture go build path -o build-name，常用的target-OS和target-architecture如下：| GOOS - Target Operating System | GOARCH - Target Platform || :——————————: | :————————: || android | arm || darwin | amd64 || darwin | arm || darwin | arm64 || linux | amd64 || windows | amd64 | 当然，你也可以使用自动交叉编译的脚本来完成这个工作。 3.2 邮件提醒目前主流邮箱都可以开启pop3或smtp的服务，用于在第三方上收发邮件，诸如qq、outlook、163(垃圾，别用)、gmail等都可以在设置界面找到相应的选项，开启后，服务商都会给你一段授权码(不是密码)，用于身份识别。具体步骤如下: 开启smtp授权 服务器上mkdir /root/.certs 配置证书： 123456789echo -n | openssl s_client -connect smtp.qq.com:465 | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' &gt; ~/.certs/qq.crtcertutil -A -n \"GeoTrust Global CA\" -t \"C,,\" -d ~/.certs -i ~/.certs/qq.crt certutil -A -n \"GeoTrust SSL CA\" -t \"C,,\" -d ~/.certs -i ~/.certs/qq.crt certutil -L -d /root/.certs certutil -A -n \"GeoTrust SSL CA - G3\" -t \"Pu,Pu,Pu\" -d ~/.certs/ -i ~/.certs/qq.crt 安装mailx 12yum -y install sendmailyum -y install mailx 配置发件人信息:vim /etc/mail.rc 12345set from=example@qq.comset smtp=smtp.qq.comset smtp-auth-user=example@qq.comset smtp-auth-password=AUTHORITY_CODEset smtp-auth=login 发送邮件：cat response.log | mail -s 'title' yourmail@gmail.com或mail -s 'title' yourmail@gmail.com &lt; test.txt 3.3 定时执行任务 安装crontab 12yum install -y vixie-cronyum install -y crontabs 配置 1service crond start 定时运行 1crontab -e 出现一个文本文件，按照以下格式： 12* * * * * command分 时 日 月 周 设置为： 130 6 * * * {$PATH}/report.sh 4. 总结 程序结构混杂； golang http包源码可以看一下； 源码.","link":"/2020/03/27/%E6%90%9E%E4%BA%8B/"},{"title":"[DB] 并发控制","text":"并发控制simultaneous concurrency并发控制概述事务是并发控制地基本单位，为了保证事务地隔离性和一致性，DBMS需要对并发操作进行正确的调度。 并发操作带来的数据不一致性包括丢失数据、不可重复读、读脏数据。 丢失数据lost update：两个事务读入同一数据并修改，一个提交的结果破坏了另一个提交的结果，导致修改被丢失。 不可重复读non-repeatable read：指事务T1读取数据后，事务T2执行更新操作，使T无法再现前一次读取结果。具体分三种： T1读某一数据后，T2修改，T1再读，得到不同值。 T1读某一数据后，T2删除，T1再读，数据消失。 T1读某一数据后，T2插入，T1再读，多了数据。 后两种不可重复读有时也被称为幻影(phamtom row)现象。 读脏数据dirty read：T1修改某一数据并写回磁盘，T2读该数据，T1 rollback，T2读到的数据与数据库中的数据不一致。 并发控制的主要技术：封锁(locking)，时间戳(timestamp)，乐观控制法(optimistic scheduler)，多版本并发控制(multi-version concurrency control,MVCC) 封锁事务对某个数据进行加锁，在其释放前，其他食物不能更新此数据对象。 基本的封锁类型有两种： 排他锁(写锁)-X锁，释放前只允许自己读写，且禁止其他事务加任何类型的锁。 共享锁(读锁)-S锁 ，释放前自己也只能读，其他事务可以读，可以加同样的S锁。 封锁协议locking protocol封锁协议：规定合适申请X锁或S锁、持锁时间、何时释放等。 一级封锁协议：事务T在修改数据R之前必须先对其加X锁，直到事务结束才释放。事务结束包括COMMIT, ROLLBACK。 一级封锁协议中，如果仅仅是读数据而不是对其进行修改，是不需要加锁的，所以它**不能保证 可重复读 和 不读脏数据。 二级封锁协议：在一级封锁协议的基础上，增加事务T在读取数据R之前必须先对其加S锁，读完后即可释放S锁。 由于读完即可释放S锁，所以他不能保证 可重复读。 三级封锁协议：在一级封锁协议的基础上增加 事务T在读取数据R之前必须先对其加S锁，直到该事务结束之后才释放。 可解决不可重复读、读脏数据问题。 三级协议的主要区别在于什么操作需要申请封锁，以及合适释放锁。 活锁和死锁活锁 ：T1封锁数据R，T2请求封锁R，后T3也请求封锁R，T1释放R后首先批准了T3的请求，也就是说T2被插队了，如果T2一直被插队，那么称之为活锁。 解决方法：先来先服务。 死锁 ：循环等待。 死锁的预防： 一次封锁法：要求每个事务必须一次将所有要使用的数据全部加锁，否则就不能继续执行。 缺陷：1.扩大封锁范围，降低并发度；2.很难事先确定需要封锁的数据对象。 顺序封锁法：预先对数据对象规定一个封锁顺序，所有事务都按照这个顺序实施封锁。 缺陷：1.数据库系统中封锁的数据对象极多，并且不断变化，要维护这样的资源的封锁顺序非常困难，成本很高；2.很难事先确定要封锁那些对象，一次也就很难按规定的顺序去施加封锁。 死锁的诊断与解除 ： 超时法：如果一个事务的等待时间超过了规定的时限，就认为发生了死锁。 等待图法：用一个有向图G=(T, U)表示事务的情况，动态地反映所有事务地等待情况，周期性生成事务等待图，并进行检测，如果发现图中存在回路，则表示系统中出现了死锁。 解除死锁：选择一个处理死锁代价最小的事务，将其撤销，释放此事务持有地所有锁。 并发调度地可串行性可串行化调度：多个事务地并发执行是正确的，当且仅当其结果与按某一次序串行执行这些事务地结果相同时，称这种调度策略为可串行化serializable的。 可串行性是并发实物正确调度的准则。 冲突化可串行调度冲突操作是指不同事务对同一数据的读写操作和写写操作。而其他操作是不冲突操作。 通过交换两个事务不冲突操作的次序得到另一个调度Sc‘，如果Sc’是串行的，则称调度Sc为冲突可串行化的调度。因此可以用这种方法来判断一个调度是否是冲突可串行化的。 冲突可串行化调度是可串行化调度的充分条件，不是必要条件。 两段锁协议 TwoPhase Locking所谓2PL协议是指所有事务必须分两个阶段对数据项加锁和解锁： 在对任何数据进行读、写操作之前，首先要申请并获得对该数据的封锁 在释放一个锁之后，事务不再申请和获得任何其他封锁 事务分为两个阶段，第一阶段是获得封锁，也成为扩展阶段，此阶段可以申请获得任何数据项上的任何类型的锁，但是不能释放任何锁；第二阶段是释放封锁，也称为收缩阶段，该阶段事务可以释放任何数据项上的任何类型的锁，但是不能再申请任何锁。 若并发执行的所有事务均遵循两段锁协议，则对这些事务的任何并发调度都是可串行化的。 严格两段锁协议：除要求满足两段锁协议规定外，还要求事务的排它锁必须在事务提交之后释放 强两段锁协议：除要求满足两段锁协议规定外，还要求事务的所有锁都必须在事务提交之后释放 事务遵守两段锁协议是可串行化调度的充分条件，而不是必要条件。 封锁的粒度 Granularity封锁对象的大小称为封锁的粒度，封锁粒度与系统的并发度和并发控制的开销密切相关。 封锁的粒度越大，数据库所能封锁的单元就越少，并发度越小，系统开销越小。 多粒度封锁：一个系统中同时支持多种封锁粒度供不同的事务选择。 引入多粒度树的概念，三级粒度树(数据库，关系，元组)，四级粒度树(数据库，数据分区，数据文件，数据记录)。多粒度封锁协议允许多粒度树中的每个结点被独立的加锁。对一个结点加锁意味着这个结点的所有后裔结点也被加以同样类型的锁。 显式封锁：应事务要求直接加到数据对象上的锁。 隐式封锁：该数据对象没有被独立加锁，而是由于其上级结点加锁而使该数据对象加上了锁。 一般地，对于某个数据对象加锁，系统要检查该数据对象上有无显式封锁与之冲突，还要检查上级结点传下来的隐式封锁是否冲突，以及传给下级结点的封锁是否冲突，这样的检查方法效率很低，因此引入意向锁。 意向锁意向锁：如果对一个结点加意向锁，则说明该结点的下层结点正在被加锁；对任一结点加锁时，必须先对它的上层结点加意向锁。 三种常用的意向锁，意向共享锁(Intent Share Lock，IS锁)，意向排他锁(Intent Exclusive Lock, IX锁)，意向共享排他锁(Share Intent Exclusive Lock, SIX锁) IS锁：如果对一个数据对象加IS锁，表示它的后裔结点拟加S锁。 例如，事务T1要对R1中某个元组加S锁，则要首先对关系R1和数据库加IS锁 IX锁：如果对一个数据对象加IX锁，表示它的后裔结点拟加X锁。 SIX锁：如果对一个对象加SIX锁，表示对它加S锁，再加IX锁，即SIX=S+IX。 课后题： 正确的调度-&gt;可串行化的调度-&gt;遵守两阶段封锁的调度-&gt;串行调度","link":"/2019/07/05/%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/"},{"title":"[DB] 数据库恢复技术","text":"数据库恢复技术事务在讨论数据库恢复计数之前先要明确事务的基本概念和事务的性质。 事务：用户定义的一个数据库操作序列，这些操作要么全做要么全不做，是一个不可分割的工作单位。在SQL中，定义事务的语句有3条： BEGIN TRANSACTION COMMIT ROLLBACK 特性：ACID——原子性Atomisticy、一致性Consistency、隔离性Isolation、持续性Durability。 故障的种类 事务内部的故障：事务没有打到预期的终点(COMMIT或者显示的ROLLBACK)，因此，数据可可能出于不正确的状态。事务内部更多的故障是非预期的，是不能由应用程序处理的。 系统故障：系统故障是指造成系统停止运转的任何时间，是的系统要重新启动。如：CPU故障、操作系统故障、DBMS代码错误、系统断电等。发生系统故障时，一些尚未完成的事务结果可能已送入物理数据库，从而造成数据库可能出于不正确的状态。 恢复子系统必须在系统重新启动时让所有非正常中值的事务回滚，还需要重做REDO所有已提交的事务，以将数据库真正恢复到一致状态。 介质故障：系统故障常被成为软故障(soft crash) ，介质故障成为硬故障(hard crash) 。硬故障指外存故障，如磁盘损坏、磁头碰撞、瞬时强磁场干扰等。发生几率小，但破坏性巨大。 计算机病毒 恢复的基本原理：冗余。也就是说数据库中任何一部分被破坏或不正确的数据可与根据存储在系统别处的冗余数据来重建。 恢复的实现技术恢复机制关键问题：如何建立冗余数据，如何利用这些冗余数据实施数据库恢复。 建立冗余数据最常用的技术时数据转储和登记日志文件logging(通常二法并用)。 数据转储转储即数据库管理员定期地将整个数据库复制到磁盘、磁带或其他存储介质上保存起来的过程。这些备用数据成为后备副本backup。转储是十分耗费时间和资源的，不能频繁进行，应根据数据库使用情况确定一个适当的转储周期。 静态转储：系统中午运行事务时进行的转储操作。 即转储操作开始的时刻，数据库出游一致性状态，而转储期间不允许对数据库的任何存取、修改活动。缺点：降低数据库的可用性。 动态转储：转储期间允许对数据库进行存取或修改。缺点：转储结束时backup上的数据并不能保证正确有效，可能已经是过时的数据了。 解决方法：将转储期间各事务对数据库的修改活动登记下来，建立日志文件log file。 转储还分为海量转储和增量转储两种方式。 海量转储：每次转储全部数据库 增量转储：每次只转储上一次转储后更新过的数据。 登记日志文件Logging日志文件的格式和内容 日志文件：用来记录事务对数据库的更新操作的文件。分为已记录为单位的日志文件和以数据块为单位的日志文件。 日志文件中需要登记的内容： 各个事务的开始(BEGIN TRANSACTION)标记 各个事务的结束(COMMIT或ROLLBACK)标记 各个事务的所有更新操作 日志文件的作用： 事务故障恢复和系统故障恢复必须用日志文件 在动态转储方式中必须建立日志文件，backup和log file结合起来才能有效地恢复数据库 静态转储方式中也可以建立日志文件，主要用于数据库恢复后将已完成地事务进行重做处理，对故障发生时尚未完成的事务进行撤销处理 为保证数据库是可恢复的，登记日志文件时必须遵循两条原则： 登记的次序严格按并发事务执行的时间次序 必须先写日志文件，然后再写数据库。 恢复策略事务故障的恢复 ：事务在运行至正常终止点前被终止，恢复子系统应利用日志文件撤销UNDO此事务一堆数据库进行的修改。由系统自动完成 ，对用户是透明的，步骤为： 反向扫描日志文件，查找该事物的更新操作。 对该事物的更新操作执行逆操作 继续反向扫描日志文件，查该事务的其他操作，并作同样处理。 repeat until begining 系统故障的恢复 ，成因有两个：1.未完成事务对数据库的更新已写入数据库；2.已提交事务对数据库的更新还留在缓冲区。该恢复由系统在重新启动时自动完成，不需要用户干预。 恢复步骤： 正向扫描日志文件，找出在故障发生前已经提交的事务(有BEGIN TRANSACTION 和 COMMIT)，标记记入重做队列(REDO LIST)，同时找出故障发生时尚未完成的事务(只有BEGIN TRANSACTION无COMMIT)，标记记入撤销队列(UNDO LIST) 对UNDO LIST中的各个事务UNDO——反向扫描日志文件，对每个要撤销事务的更新操作执行逆操作。 对REDO-LIST进行REDO——正向扫描日志文件，依次REDO。 介质故障的恢复 ，恢复方法：重装数据库，重做已完成的事务。(装入最新backup，装入相应的日志文件副本) 具有检查点的恢复技术在日志文件中增加一个新的记录——检查点checkpoint记录，增加一个重新开始文件，并让恢复子系统在登录日志文件期间动态地维护日志。 checkpoints记录内容: 建立检查点时刻所有正在执行的事务清单 这些事务最近一个日志记录的地址 动态维护日志文件的方法是，周期性地执行建立检查点、保存数据库状态地操作。 使用检查点方法可以改善恢复效率。","link":"/2019/07/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/"},{"title":"[DB] 数据库系统概论","text":"数据库系统概论 数据：数据库中存储的基本单位 数据库：是长期存储在计算机内、有组织的、可共享的大量数据的集合。具有较小的冗余度、较高的数据独立性、易扩展性。基本特点：永久存储、有组织、可共享。 数据库管理系统：是位于用户与操作系统之间的一层数据管理软件。主要功能： 数据定义功能 数据组织、存储和管理 数据操纵功能 数据库的事务管理和运行管理 数据库的建立和维护 其他功能 数据库系统DBS：指在计算机系统中引入数据库后的系统，有数据库、DBMS、应用系统、数据库管理员(DBA)组成。 数据库系统的特点： 数据结构化 数据的共享性高，冗余度低，易扩充 数据独立性高 数据由DBMS统一管理和控制 数据管理的三个阶段：人工管理阶段——文件系统阶段——数据库系统阶段 录音思路1.如何组织数据——数据模型、规范化理论 2.如何存取数据——数据定义与操作语言 3.哪些人可以操作哪些数据——安全性相关 4.很多人在操作统一数据时如何避免发生冲突——并发控制 5.故障后怎么办——数据恢复 数据模型：概念模型、逻辑模型 分两个模型的原因：逻辑模型 为了方便把 概念模型 存放到计算机中，事实上二者是同一概念。 数据模型的组成要素：数据结构、数据操作、数据的完整性约束条件 概念模型：实体 属性 码 域 实体性 实体集 联系 常用的逻辑数据模型： 层次模型 网状模型 关系模型 面向对象模型 对象关系模型 E-R图 —————- P19 实体-矩形 属性-椭圆 关系-菱形。 关系模型：关系(Relation)、元组(Tuple)、属性(Attribute)、码(Key)、域(Domain)、分量。 关系的完整性约束条件：实体完整性、参照完整性、用户定义完整性。 优点：数学基础、概念单一(都是二维表)、存取路径对用户透明。 缺点；效率、优化会增加开发难度。 数据库系统结构数据库的三级模式： 外模式：子/用户模式，数据库用户看见和使用的局部数据的逻辑结构和特征的描述。 模式：逻辑模式，数据中全体数据的逻辑结构和特征的描述。 内模式：存储模式，数据物理结构和存储方式的描述。 数据库的二级映像： 外模式/模式映像 模式/内模式映像——定义了数据全局逻辑结构和存储结构之间对应关系。 关系数据库看书做题就行 候选码：关系中能唯一标识一个元组的值。 主属性：候选码中的属性。 关系的三种类型：基本类型(基本表)、查询表、视图表。 注： 连接操作中，可能会丢失一些值，为了保留这些值而留出空值叫做外连接 要看除运算 SQL特点： 综合统一 高度非过程化 面向集合的操作方式 以同一种语法结构提供多种使用方式 修改基本表： ALTER TABLE &lt;表明&gt; 例： ​ ALTER TABLE Student ADD S_entrance DATE; ​ ALTER TABLE Student ALTER COLUMN Sage INT; ​ ALTER TABLE Course ADD UNIQUE(Cname); 查询中的字符匹配： 例： ​ SELECT Sname, Sno, Ssex FROM Student WHERE Sname LIKE ‘刘%’; ​ 匹配所有姓刘的同学 ​ SELECT Sname FROM Student WHERE Sname LIKE ‘欧阳__’; ​ 匹配 欧阳X having ORDER BY ASC(升序) DESC(降序) 缺省情况为升序 数据库安全性计算机系统安全性： 技术安全 管理安全 政策法律 用户表示与鉴别Identification &amp; Authentication —— 最外层安全保护措施 用户表示User Identification 口令Password 存取控制： 定义用户权限，并将用户权限登记到数据字典中 合法权限检查 自主存取控制(Discretionary Access Control, DAC) C1级别 用户对于不同的数据库对象由不同的存取权限，不同的用户对同一对象也有不同的权限，用户可将其拥有的存取权限授权给其他用户 强制存取控制(Mandatory Access Control, MAC) B1级别 每一个数据库对象被标以一定的密级，每一个用户也被授予某一级别的许可证。 Discretionary Access Control授权与回收： GRANT GRANT SELECT ON TABLE Student TO U1; REVOKE 回收权限，形式与上面类似 数据库角色——权限的集合，用于简化授权 1.角色的创建 ​ CREATE ROLE 2.给角色授权 ​ 略 3.将一个角色授予其他用户 ​ 略 4.角色权限的收回 Mandatory Access Control在MAC中DBMS所管理的全部实体被分为主体和客体两大类。 主体：系统中的活动实体，既包括DBMS所管理的实际用户，也包括代表用户的各进程。 客体：系统中的被动实体，包括文件、基本表、索引、视图，受主题操纵。 对于主体和客体，DBMS为它们每个实例指派一个敏感度标记(Label)。分为绝密Top Secret、机密Secret、可信Confidential、公开Public，主体的敏感度标记称为许可证级别，客体的敏感度标记为密级。 规则： 仅当主体的许可证级别大于或等于客体的密级，可读； 仅当主题的许可证级别等于客体的密级，可写。 原因：禁止了拥有高许可证级别的主体更新低密度的数据对象，造成敏感数据的泄露。 数据库完整性实体完整性、参照完整性、用户自定义的完整性 DBMS为维护数据库的完整性，必须能够； 1.提供定义完整性约束条件的机制 2.提供完整性检查的方法 3.违约处理 实体完整性的定义：列级约束条件、表级约束条件 实体完整性检查和违约处理：检查主码值是否唯一；检查主码的各属性是否为空 参照完整性定义：FOREIGN KEY，对外码的取值做一个约束：空值或存在值。 用户自定义完整性：1.NOT NULL; 2.UNIQUE; 3.CHECK; 关系数据库理论函数依赖(Functional Dependency,FD)：属性间类似数学中的函数y=f(x)的依赖关系，被称为函数依赖。记作X→Y。 非平凡函数依赖：X→Y，但Y不是X的子集。 平凡函数依赖：X→Y，Y是X的子集。 完全函数依赖：X→Y，并且对于X的任何一个真子集X‘，都有Y不函数依赖于X’。 部分函数依赖：X→Y，Y不 完全函数依赖 于X。u’s 传递函数依赖：X→Y, Y→Z, 且Y不→X。 主属性(Prime Attribute)：任何候选码中的属性。 非主属性(Nonprime Attribute)：不包含在任何码中的属性。也称非码属性(Non-key Attribute)。 第一范式(1NF)：每一个分量必须是不可分的数据项。 第二范式(2NF)：1NF的基础下，每一个非主属性完全依赖于码 规范化(normalization)：一个低一级范式的关系模式，通过模式分解可以转化为若干个高一级范式的关系模式的集合。 第三范式(3NF)：每一个非主属性 既不部份依赖于码，也不传递依赖于码。 BCNF：关系模式R&lt;U,F&gt;∈1NF，若X→Y且Y不是X子集时，X必含有码。即，每一个决定因素都含有码。 一个满足BCNF的关系模式： 所有非主属性对于每一个码都是完全函数依赖 所有的主属性对每一个不包含它的码，也是完全函数依赖 没有任何属性完全函数依赖于飞马的任何一组属性 BCNF修正了3NF主属性内部部分函数依赖 多值依赖(Multivalued Dependency,MVD) 模式分解 分解具有无损连接性(Lossless Join)——通过自然运算可复原 分解要“保持函数依赖”(Preserve functional dependenct) 分解既要保持函数依赖，又要具有无损连接性。 —————————————————19分钟两类考题——————————————————– 关系查询处理和查询优化DBMS查询处理分为4个阶段：查询分析、查询检查、查询优化、查询执行。 计算题：P268 数据库设计数据库设计重点： 概念设计-&gt;逻辑设计 ， 每一阶段目的是什么。 数据库设计方法：新奥尔良方法、基于E-R模型的数据库设计方法、3NF的设计方法、ODL方法、UML方法 数据库设计的基本步骤： 准备工作：1.系统分析人员、数据库设计人员；2.用户代表和数据库管理员；3.应用开发人员 需求分析 需求分析任务：信息要求、处理要求、安全性与完整性要求 需求分析方法：跟班作业、开调查会、请专人介绍、询问、设计调查表、查阅记录 数据字典：机型详细的数据收集和数据分析所获得的主要结果 数据项：不可再分的数据单位 数据结构：反映数据之间的组合关系 数据流：数据结构在系统内传输的路径 数据存储：数据结构停留或保存的地方 处理过程：处理过程的具体处理逻辑一般用判定表或判定书来描述 小结：充分考虑可能的扩充和改变，使设计易于更改，系统易于扩充；强调用户参与。 概念结构设计 特点： 能真实充分反映现实世界 易于理解 易于更改 易于向关系、网状、层次等数据模型转 四类方法：(常用：自顶向下需求分析，自底向上设计概念结构) 自顶向下 自底向上 逐步扩张 混合策略 视图的集成：多个E-R一次继承(难度较大)；逐步继承 合并冲突： 属性冲突：属性值的类型、取值范围、取值集合、单位不同。 命名冲突：同名异义，异名同义。 结构冲突： 同一对象在不同应用中具有不同的抽象，如职工在某一局部应用中为实体，另一为属性 同一实体在不同E-R图中所包含的属性个数和属性排列次序不完全相同 实体间的联系在不同的分E-R图中为不同的类型 逻辑结构设计 物理结构设计 数据库实施 数据库运行与维护","link":"/2019/07/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%AE%BA/"},{"title":"[NOTE] 服务器使用本机(PC)代理","text":"在使用实验室服务器过程中，有时不得不从外网上拉取相关仓库，诸如git clone奇慢无比，还总是失败，本想着过段时间申请一个ac86u之类的，改成路由器代理，突然想到本机其实也可以暂代这个功能的。 For Win为了解决这个问题，网上大概有三种方法： 1.修改hosts，直接指向github.com，但实测效果很差； 2.码云中转，太麻烦了，而且碰上级联依赖的就很头大； 3.ssr局域网开放端口代理，由于局域网中本机ip为192.168.1.205，将代理服务挂到1080端口，如下 git config --global http.proxy 192.168.1.205:1080 git config --global https.proxy 192.168.1.205:1080 当然，这样一配置，所有的git操作都要经过代理，所以还是调整一下： 1234567# remove the config setting beforegit config --global --unset http.proxygit config --global --unset https.proxy# only for githubgit config --global http.https://github.com.proxy 192.168.1.205:1080git config --global https.https://github.com.proxy 192.168.1.205:1080 For Mac1export https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7891","link":"/2019/07/21/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8%E6%9C%AC%E6%9C%BA-PC-%E4%BB%A3%E7%90%86/"},{"title":"[Tips] 终端10X工作法","text":"此篇文章转载legendtkl的博客终端10X工作法，我一直很喜欢terminal使用中带来的一些小tricks，这篇文章刚好列举了一些代表性的，之后我会在这篇文章的基础上，将我比较常用的记录并放到顶部，也算是方便查找。 另外也非常感谢legendtkl的文章合抱之木，生于毫末，也算是我开始写博客的原因之一。 以下为正文内容。 在 github 上面有一个 700 多人 star 的 repo 叫做 Bash-Oneliner，介绍了很多实用并且可以有效提高工作效率的命令，我们来了解一下。原文直达：Bash-Oneliner 。注：去除了部分看上去没啥用的命令，可以原文查看所有内容。 1. Terminal注：下面介绍的是在 Linux 下的 terminal 的行为，在 Mac 下面会略有差异，尽量补全 Ctrl 相关12345678910111213141516Ctrl + n : 类似向下方向键Ctrl + p : 类似向上方向键Ctrl + r : 反向搜索 terminal 的历史命令Ctrl + s : 停止该 terminalCtrl + q : 在 Ctrl + s 后面重新恢复该 terminalCtrl + a : 移动光标到行的开始处。(这个很有用)Ctrl + e : 移动光标到行的结尾处。(同上)Ctrl + d : 如果当前的 terminal 的命令行有输入，那么 Ctrl + d 会删除光标处的数字。否则会退出当前的 terminalCtrl + k : 删除从当前光标开始到结尾的所有的字符Ctrl + x + backspace: 删除从当前光标到行开始的所有的字符Ctrl + t : 交换当前光标下的字符和其前面的字符的位置。Esc + t 交换光标前面的两个单词。(这个很有意思)Ctrl + w : 剪切光标之前的单词。Ctrl + y 粘贴该单词Ctrl + u : 剪切光标之前的所有字符。Ctrl + y 粘贴刚刚剪切的字符Ctrl + _ : 撤销前面的操作。(可以连续操作多次)Ctrl + l : 类似 clear。(类似 Mac 终端下的 Command + k)Ctrl + x + Ctrl + e : 唤起 $EDITOR 环境变量设置的编辑器程序，在需要输入多行的情况下比较有用。(试验了一下如果之前没有设置，$EDITOR 的默认值是 emacs。你可以将其设置为 vim，即 export EDITOR=vim。当然也可以将这个环境变量设置为其他的应用程序去实现一些有趣的功能，这个测试过了) 改变字符大小写123Esc + u : 将当前光标开始到单词结尾的字符都转换成大写。(这里的单词指的是光标所在的位置前后以空格分隔形成的单词)Esc + l : 将当前光标开始到单词结尾的字符都转换成小写Esc + c : 将光标所在位置的字符转换成大写 执行历史命令12!53 : 执行 history 中的 53 号命令!! : 执行上一条命令 替换上一条命令，并替换一些参数12345678# 上一条命令：echo 'aaa'^aaa^bbb# 此时将上一条命令替换为 echo 'bbb'，输出 bbb# 需要注意的是，这样只会替换第一次 aaa，如果要替换所有的 aaa，需要像下面这样使用^aaa^bbb^:&amp;# 或者!!:gs/aaa/bbb/ 前缀匹配执行历史命令1234!cat# 或者!c# 执行历史命令中最近一条满足前缀是 c 或者 cat 的命令 文件名使用正则1234567891011# ? 表示一个单独的任意字符/b?n/?at # 匹配上 /bin/cat# * 表示多个任意字符/etc/pa*wd # 匹配上 /etc/passwd# '[]' 表示一个字符范围ls -al [a-z]* # 列出所有以字母开头的文件# '{}' 文件名匹配多种模式ls {*.sh,*.py} # 列出所有的 .sh 和 .py 文件 环境变量123456789101112131415$0, $1, $2, $3, ... ： 在执行 shell 的时候传参使用，$0 表示 shell 名字，$1,$2,$3依次表示后面的参数$# : 参数的个数$? : 最近的一个终端 foreground 命令的退出状态$- : 当前 shell 设置的选项，可以通过 echo $- 查看$$ : 当前 shell 进程的 pid$! : 最近的一个终端后台命令的 pid$DESKTOP_SESSION : 当前的展示管理器。(可能说的是 xWindow)$EDITOR : 编辑器，可以通过上面提到的快捷键唤醒$LANG : 语言设置$PATH : 这个不用说了$PWD : 当前目录$SHELL : 当前的 shell$USER : 当前的 username$HOSTNAME : 当前的 hostname 2. Grepgrep 的种类12345grep = grep -G # 支持基本的正则表达式fgrep = grep -F # 查找文件里符合条件的字符串egrep = grep -E # 支持扩展的正则表达式pgrep = grep -P # 兼容 Perl 的正则表达式语法rgrep = grep -r # 递归 grep 统计空行个数1grep -c &quot;^$&quot; grep 并且只返回数字123grep -o '[0-9]*'#或者grep -oP '\\d' grep 含有特定数字的数字12345grep ‘[0-9]\\{3\\}’# orgrep -E ‘[0-9]{3}’# orgrep -P ‘\\d{3}’ 查找 IP 地址123grep -Eo '[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}'# orgrep -Po '\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}' 查找单词12345678# return also 3 lines after matchgrep -A 3 'bbo'# return also 3 lines before matchgrep -B 3 'bbo'# return also 3 lines before and after matchgrep -C 3 'bbo' 查找特定字符开头的单词1grep -o 'S.*' 提取两个特定单词之间的文本1grep -o -P '(?&lt;=w1).*(?=w2)' 查找不包含某个单词的文件内容1grep -v bbo filename 查找不是以特定字符开头的文件内容1grep -v '^#' file.txt 查找含有空格的内容12bbo=&quot;some strings&quot;grep &quot;$boo&quot; filename 查找第一个 match 文件内容1grep -m 1 bbo filename 查找并返回满足条件的文件内容条数1grep -c bbo filename 统计单词在文件中出现的次数1grep -o bbo filename |wc -l 大小写敏感的查找1grep -i &quot;bbo&quot; filename 匹配结果着色1grep --color bbo filename 查找目录下的所有文件123grep -R bbo /path/to/directory# orgrep -r bbo /path/to/directory 查找目录下的所有文件，不输出文件内容1grep -rh bbo /path/to/directory 查找目录下的所有文件，只输出匹配的文件名1grep -rl bbo /path/to/directory OR 查找1grep 'A\\|B\\|C\\|D' AND 查找（比如 A and B）1grep 'A.*B' 正则查找（比如 ACB 或者 AEB）1grep 'A.B' 查找特定字符（比如 color 或者 colour）1grep ‘colou?r’ 查找多个文件的所有内容1grep -f fileA fileB 查找 tab1grep $'\\t' 从变量中查找1234$echo &quot;$long_str&quot;|grep -q &quot;$short_str&quot;if [ $? -eq 0 ]; then echo 'found'; fi#grep -q will output 0 if match found#remember to add space between []! 查找括号中间的字符串1grep -oP '\\(\\K[^\\)]+' 略过目录查找1grep -d skip 'bbo' /path/to/files/* 3. Sed移除文件第一行1sed 1d filename 移除文件的前 100 行1sed 1,100d filename 移除包含特定字符串的文件行注：这种方式并不会修改原文件，可以将输出重定向到新的文件保存 123sed &quot;/bbo/d&quot; filename# case insensitive:sed &quot;/bbo/Id&quot; filename 移除文件不满足第 n 个字符串不等于某个值的行1234# 第 5 个字符不等于 2sed -E '/^.{5}[^2]/d'#aaaa2aaa (you can stay)#aaaa1aaa (delete!) 修改原文件12# 删除包含 bbo 的行并直接保存文件sed -i &quot;/bbo/d&quot; filename 使用变量的时候使用双引号1234# e.g. add &gt;$i to the first line (to make a bioinformatics FASTA file)sed &quot;1i &gt;$i&quot;# notice the double quotes! in other examples, you can use a single quote, but here, no way!# '1i' means insert to first line 删除空行12345sed '/^\\s*$/d'# orsed '/^$/d' 删除最后一行1sed '$d' 删除文件的最后一个字符1sed -i '$ s/.$//' filename 向文件开头插入字符串（比如 “[“）1sed -i '1s/^/[/' file 向文件中特定行中插入字符串1sed -e '1isomething' -e '3isomething' 向文件结尾插入字符（比如 “]”）1sed '$s/$/]/' filename 向文件结尾插入新行1sed '$a\\' 向文件的每一行插入数据1sed -e 's/^/bbo/' file 向文件的每一行结尾插入数据1sed -e 's/$/\\}\\]/' filename 每 n 个字符插入换行符（比如每 4 个字符）1sed 's/.\\{4\\}/&amp;\\n/g' 连接多个文件1sed -s '$a,' *.json &gt; all.json 内容替换1sed 's/A/B/g' filename 基于正则的文件内容替换1sed &quot;s/aaa=.*/aaa=\\/my\\/new\\/path/g&quot; 筛选文件中以特定字符串开始行1sed -n '/^@S/p' ####打印文件中的多行 1sed -n 500,5000p filename 打印文件中特定行123sed -n '0~3p' filename# 打印 3 的倍数行 打印奇数行1sed -n '1~2p' filename 删除文件开头的空格和 tab12sed -e 's/^[ \\t]*//'# Notice a whitespace before '\\t'!! 只删除空格123sed 's/ *//'# notice a whitespace before '*'!! 移除文件结尾的逗号1sed 's/,$//g' 文件结尾添加一列（以 tab 分隔）12345sed &quot;s/$/\\t$i/&quot;# $i is the valuable you want to add# To add the filename to every last column of the filefor i in $(ls);do sed -i &quot;s/$/\\t$i/&quot; $i;done 打印特定的行1sed -n -e '123p' 删除文件的最后一个字符1sed '$ s/.$//' 指定位置插入字符1sed -r -e 's/^.{3}/&amp;#/' file 4. Awk设置 tab 为分隔符1awk -F $'\\t' 设置 tab 为输出内容的分隔符1awk -v OFS='\\t' 传递参数12a=bbo;b=obb;awk -v a=&quot;$a&quot; -v b=&quot;$b&quot; &quot;$1==a &amp;&amp; $10=b&quot; filename 输出文件行号以及每行的字符个数1awk '{print NR,length($0);}' filename 输出 column/field 的个数1awk '{print NF}' 判断是不是有逗号1awk '$1~/,/ {print}' 输出字符串出现 n 次之前的所有行1awk -v N=7 '{print}/bbo/&amp;&amp; --N&lt;=0 {exit}' 输出文件名和其最后一行1ls|xargs -n1 -I file awk '{s=$0};END{print FILENAME,s}' file 向指定的 column 插入字符串1awk 'BEGIN{OFS=&quot;\\t&quot;}$3=&quot;chr&quot;$3' 移除包含特定字符串的行1awk '!/bbo/' file 移除最后一个 column1awk 'NF{NF-=1};1' file 理解 NR 和 FNR 的作用1234567891011121314# For example there are two files:# fileA:# a# b# c# fileB:# d# eawk 'print FILENAME, NR,FNR,$0}' fileA fileB# fileA 1 1 a# fileA 2 2 b# fileA 3 3 c# fileB 4 1 d# fileB 5 2 e 5. Xargs设置 tab 为分隔符1xargs -d\\t 每行显示三个元素123echo 1 2 3 4 5 6| xargs -n 3# 1 2 3# 4 5 6 执行之前先询问123$ echo a b c |xargs -p -n 3$ echo a b c ?... #输入 y$ a b c find 文件并删除1find . -name &quot;*.html&quot;|xargs rm 删除文件名中含有空格的文件1find . -name &quot;*.c&quot; -print0|xargs -0 rm -rf 显示 limits1xargs --show-limits 移动文件123456find . -name &quot;*.bak&quot; -print 0|xargs -0 -I {} mv {} ~/old# orfind . -name &quot;*.bak&quot; -print 0|xargs -0 -I file mv file ~/oldls |head -100|xargs -I {} mv {} d1 并发执行1234time echo {1..5} |xargs -n 1 -P 5 sleep# a lot faster than:time echo {1..5} |xargs -n1 sleep 基于条件的文件拷贝1234find /dir/to/A -type f -name &quot;*.py&quot; -print 0| xargs -0 -r -I file cp -v -p file --target-directory=/path/to/B# v: verbose|# p: keep detail (e.g. owner) 和 sed 配合使用1ls |xargs -n1 -I file sed -i '/^Pos/d' filename 将文件名加入到文件的第一行1ls |sed 's/.txt//g'|xargs -n1 -I file sed -i -e '1 i\\&gt;file\\' file.txt 统计1ls |xargs -n1 wc -l 将输出整合到一行1ls -l| xargs 统计文件夹下面各个文件的行数和总的行数1ls|xargs wc -l 和 grep 联合使用1cat grep_list |xargs -I{} grep {} filename 和 sed 联合使用1grep -rl '192.168.1.111' /etc | xargs sed -i 's/192.168.1.111/192.168.2.111/g' 6. Find递归列出所有的子目录和文件1find . 列出当前目录下的所有文件1find . -type f 列出当前目录下的所有子目录1find . -type d 修改当前目录下的所有文件（将 ‘www’ 替换成 ‘w’）12345find . -name '*.php' -exec sed -i 's/www/w/g' {} \\;# if there are no subdirectoryreplace &quot;www&quot; &quot;w&quot; -- *# a space before * 删除大小小于 74 byte 的文件123find . -name &quot;*.mso&quot; -size -74c -delete# M for MB, etc","link":"/2020/01/02/%E7%BB%88%E7%AB%AF10X%E5%B7%A5%E4%BD%9C%E6%B3%95/"},{"title":"[Golang] 有限状态机FSM","text":"有限状态机(Finite State Machine)是一个非常有用的模型，理论上只要你考虑的状态足够多，就可以模拟世界上大部分事物。 1.有限状态机简单描述有限状态机，它有三个特征： 状态总数state是有限的任一时刻，只处在一种状态之中某种条件之下，会从一种状态转变到另一种状态 转变(transition)通常都是满足某个条件或是事件触发，执行动作，实现状态的迁移(也可以是保持原状态)。而“动作”是不稳定的，动作的触发往往是暂时的，使用状态的是为了使事务的边界更清晰，逻辑更加分明，同时保证稳定，在没有外部条件触发的情况下，一个状态会一直持续下去。 2.一个例子以电梯为例，简单考虑，电梯拥有三种状态：“开启”、“停止/关闭”、“移动”。显然为了安全起见，电梯在移动过程中需要保持电梯门关闭；而电梯门在开启状态下，可以再次开启电梯门以让其他人进入。电梯三种状态的转换如下图： 3.代码正好用golang来实现下一个简单的fsm。由状态接口State interface{}统一定义状态，状态管理机Statemanager来管理状态，二者实现了一个简单fsm的大部分功能。 3.1 状态接口state.go为了统一管理状态，需要使用接口定义状态。状态机从状态接口查询到用户的自定义状态应该具备的属性有： Name(): 对应State接口的名称； EnableSelfTransit(): 是否允许同状态转移； CanTransitTo(): 能否转移到指定状态。 12345678910111213141516171819package mainimport \"reflect\"type State interface { Name() string EnableSelfTransit() bool OnBegin() OnEnd() CanTransitTo(name string) bool}func GetStateName(s State) string { if s == nil { return \"none\" } // Use reflect to get the name of state (not the var name) return reflect.TypeOf(s).Elem().Name()} 需要说明GetStateName()方法，由于State在初始化时，可以理解为OpeningState State，除了缺省的属性外，其他属性都是空值，这其中就包括很关键的name，GetStateName()通过reflect直接获取实例的名称作为name。 3.2 状态信息info.go定义了结构体StateInfo，目的是为了在状态初始化时，将一些值赋为缺省值，避免在很多状态中重复编写很多代码。(当然，可以通过重写修改缺省的值) 12345678910111213141516171819202122232425262728type StateInfo struct { name string}func (s *StateInfo) Name() string { return s.name}func (s *StateInfo) setName(name string) { s.name = name}// Default infofunc (s *StateInfo) EnableSelfTransit() bool { // False by default return false}func (s *StateInfo) OnBegin() {}func (s *StateInfo) OnEnd() {}func (s *StateInfo) CanTransitTo(name string) bool { // True by default return true} 3.3 状态管理statemgr.goStateManager为fsm的核心，通过映射stateByName保存所有的状态，定义回调函数OnChange()提供状态转移的通知(也可以是其他功能)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package mainimport ( \"errors\")type StateManager struct { stateByName map[string]State // Callback while state gets changed OnChange func(from, to State) curr State}func (sm *StateManager) Get(name string) State { // In case get panic when 'name' do not exist if v, ok := sm.stateByName[name]; ok { return v } return nil}func (sm *StateManager) Add(s State) { name := GetStateName(s) // State does not have any interface of setName() // Though StateInfo gets one s.(interface{ // Actually this method is from StateInfo setName(name string) }).setName(name) // Check name duplication if sm.Get(name) != nil { panic(\"Duplicate state:\" + name) } sm.stateByName[name] = s}// Init StateManagerfunc NewStateManager() *StateManager { return &amp;StateManager{ stateByName: make(map[string]State), }}// Define errorsvar ErrStateNotFound = errors.New(\"state not found\")var ErrForbidSelfStateTransit = errors.New(\"forbid self transit\")var ErrCannotTransitToState = errors.New(\"cannot transit to state\")func (sm *StateManager) GetCurrState() State { return sm.curr}func (sm *StateManager) CanCurrTransitTo(name string) bool { if sm.curr == nil { return true } if sm.curr.Name() == name &amp;&amp; !sm.curr.EnableSelfTransit() { return false } return sm.curr.CanTransitTo(name)}func (sm *StateManager) Transit(name string) error { next := sm.stateByName[name] pre :=sm.curr if next == nil { return ErrStateNotFound } if pre != nil { // Maybe it's more secure to compare with string if GetStateName(pre) == name &amp;&amp; pre.EnableSelfTransit() { goto transitHere } if !pre.CanTransitTo(name) { return ErrCannotTransitToState } pre.OnEnd() }transitHere: sm.curr = next sm.curr.OnBegin() if sm.OnChange != nil { sm.OnChange(pre, sm.curr) } return nil} 在方法Add()中有个很有趣的操作： 123s.(interface{ setName(name string)}).setName(name) 由于在实例化各个状态的过程中，使用了StateInfo作为内嵌结构体，而在传到Add(s State)中时，结构体StateInfo包含了State接口中并未定义的方法setName()，因此需要通过一个类型转换，来调用setName()方法。很骚，学会了 3.4 主方法main.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package mainimport \"fmt\"type OpeningState struct { StateInfo}func (os *OpeningState) OnBegin() { fmt.Println(\"Elevator is opening\")}func (os *OpeningState) OnEnd() { fmt.Println(\"Elevator is closing\")}// Overwrite EnableSelfTransit()func (os *OpeningState) EnableSelfTransit() bool { return true}// Compete state transiting road-mapfunc (os *OpeningState) CanTransitTo(name string) bool { return name == \"StoppingState\"}type StoppingState struct { StateInfo}func (ss *StoppingState) OnBegin() { fmt.Println(\"Elevator is stopped\")}func (ss *StoppingState) OnEnd() { fmt.Println(\"Watch out, elevator is going to move\")}func (ss *StoppingState) CanTransitTo(name string) bool { return name != \"StoppingState\"}type RunningState struct { StateInfo}func (rs *RunningState) OnBegin() { fmt.Println(\"Elevator is moving\")}func (rs *RunningState) OnEnd() { fmt.Println(\"Elevator reaches target floor\")}func (rs *RunningState) CanTransitTo(name string) bool { return name == \"StoppingState\"}func transitAndReport(sm *StateManager, target string) { if err := sm.Transit(target); err != nil { fmt.Printf(\"FAILED transit from %s to %s\\nError: %s\\n\", GetStateName(sm.curr), target, err.Error()) }}func main() { sm := NewStateManager() sm.OnChange = func(from, to State) { fmt.Printf(\"%s -----&gt; %s\\n\", GetStateName(from), GetStateName(to)) } // Instantiate states and Add them to statemgr sm.Add(new(OpeningState)) sm.Add(new(StoppingState)) sm.Add(new(RunningState)) transitAndReport(sm, \"OpeningState\") transitAndReport(sm, \"OpeningState\") transitAndReport(sm, \"StoppingState\") transitAndReport(sm, \"RunningState\") transitAndReport(sm, \"StoppingState\") transitAndReport(sm, \"OpeningState\")} main.go中定义了三种不同的状态，将StateInfo内嵌以实现属性的默认值设置，对于需要修改的属性，重写了相应的方法。 输出： 12345678910111213141516Elevator is openingnone -----&gt; OpeningStateElevator is openingOpeningState -----&gt; OpeningStateElevator is closingElevator is stoppedOpeningState -----&gt; StoppingStateWatch out, elevator is going to moveElevator is movingStoppingState -----&gt; RunningStateElevator reaches target floorElevator is stoppedRunningState -----&gt; StoppingStateWatch out, elevator is going to moveElevator is openingStoppingState -----&gt; OpeningState 当然，一些错误转换主方法中没有测试，你也可以试试。 4 参考 https://new-tonywang.github.io/2020/02/12/FSM/ http://www.ruanyifeng.com/blog/2013/09/finite-state_machine_for_javascript.html https://www.zhihu.com/question/31845498","link":"/2020/03/08/%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BAFSM/"},{"title":"[NOTE] 网速网速！","text":"虽然华硕官改固件中有一个单线多拨的功能，但听说不太稳定，安全起见，使用官方双线双拨功能来增加带宽。 先说结果，双拨成功。在路由管理页面首页可以看到有两个WAN接入 测试速度TP-link路由器单拨测速： Asus-RT-AC86U双拨测速： 排除路由器之间的差异，AC86U可将两根WAN网速度跑满。 过程管理页面-外部网络-双线路 前面也提到过，双线双拨更稳定。开启双线路，使用LAN1口作为备用WAN口 内部网络，配置第二个WAN口，由于网线不够长，中间算是用TP-link路由器做了个桥接，所以External LAN口这并不需要拨号 获取本机MAC地址，注意两个WAN口MAC地址要做出区别，我的处理方法是在第二个WAN口MAC地址最后一位加了个一。 应用配置，成功","link":"/2019/08/06/%E7%BD%91%E9%80%9F%E7%BD%91%E9%80%9F/"},{"title":"[Debug] 踩过的坑-UbuntuDNS配置","text":"Ubuntu18.04重启之后会出现无法连接网络的问题，排查得问题出现在DNS上，然而中文社区对这个方法的解决都不甚令人满意，折腾了半个晚上，才发现This is pretty simple to fix though. 若已经连不上网了，先修改/etc/resolv.conf，添加nameserver 114.114.114.114或其他，不要restart network之类的，那样会导致文件被覆盖 sudo apt install resolvconf sudo vi /etc/resolvconf/resolve.conf.d/head # Make edits to /etc/**resolvconf**/**resolv**.**conf**.d/head. nameserver 8.8.4.4 nameserver 8.8.8.8. sudo service resolvconf restart","link":"/2019/07/10/%E8%B8%A9%E8%BF%87%E7%9A%84%E5%9D%91-UbuntuDNS%E9%85%8D%E7%BD%AE/"},{"title":"[NOTE] 阿里云镜像加速","text":"每次十分钟，快乐一万年 镜像加速器地址： https://0ghk1qyk.mirror.aliyuncs.com ubuntu12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'{ \"registry-mirrors\": [\"https://0ghk1qyk.mirror.aliyuncs.com\"]}EOFsudo systemctl daemon-reloadsudo systemctl restart docker CentOS12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'{ \"registry-mirrors\": [\"https://0ghk1qyk.mirror.aliyuncs.com\"]}EOFsudo systemctl daemon-reloadsudo systemctl restart docker MacDocker for Mac 针对安装了Docker Toolbox的用户，您可以参考以下配置步骤： 创建一台安装有Docker环境的Linux虚拟机，指定机器名称为default，同时配置Docker加速器地址。 1docker-machine create --engine-registry-mirror=https://0ghk1qyk.mirror.aliyuncs.com -d virtualbox default 查看机器的环境配置，并配置到本地，并通过Docker客户端访问Docker服务。 1docker-machine env defaulteval &quot;$(docker-machine env default)&quot;docker info 针对安装了Docker for Mac的用户，您可以参考以下配置步骤： 右键点击桌面顶栏的 docker 图标，选择 Preferences ，在 Daemon 标签（Docker 17.03 之前版本为 Advanced 标签）下的 Registry mirrors 列表中将https://0ghk1qyk.mirror.aliyuncs.com加到”registry-mirrors”的数组里，点击 Apply &amp; Restart按钮，等待Docker重启并应用配置的镜像加速器。","link":"/2019/08/08/%E9%98%BF%E9%87%8C%E4%BA%91%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/"}],"tags":[{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"hadoop","slug":"hadoop","link":"/tags/hadoop/"},{"name":"NOTE","slug":"NOTE","link":"/tags/NOTE/"},{"name":"golang","slug":"golang","link":"/tags/golang/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"hugo","slug":"hugo","link":"/tags/hugo/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"https","slug":"https","link":"/tags/https/"},{"name":"algorithm","slug":"algorithm","link":"/tags/algorithm/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/tags/Kubernetes/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"backup","slug":"backup","link":"/tags/backup/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Debug","slug":"Debug","link":"/tags/Debug/"},{"name":"VMware","slug":"VMware","link":"/tags/VMware/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"frp","slug":"frp","link":"/tags/frp/"},{"name":"leetcode","slug":"leetcode","link":"/tags/leetcode/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"database","slug":"database","link":"/tags/database/"},{"name":"FSM","slug":"FSM","link":"/tags/FSM/"}],"categories":[{"name":"Operations","slug":"Operations","link":"/categories/Operations/"},{"name":"Developments","slug":"Developments","link":"/categories/Developments/"},{"name":"Others","slug":"Others","link":"/categories/Others/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/categories/Spring-Cloud/"},{"name":"undefined","slug":"undefined","link":"/categories/undefined/"},{"name":"essay","slug":"essay","link":"/categories/essay/"},{"name":"tips","slug":"tips","link":"/categories/tips/"}]}